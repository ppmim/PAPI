PAPI DEVELOPER DIARY
====================

2011-10-24
----------


2011-10-25
----------
- Implemented in cube.c the next sky models:

     cube_median_min ( N )
     cube_mean_min ( N )
     cube_mean_min_w ( N )  weighted

 and modified the skyfilter.c routine in order to accept a new (optional)
 parameter 'skymodel' for the skyfiltering stage. The current accepted values
 for skymodel are:
     
     median : median/mean skymodel (normal or sparse fields)
     min : minimal sky model (for crowded fields)


- Al reducir la el DS de 13-Julio-2011-Matilde de O2k en el filtro Z
  (18:25:15+00:10:15) de 5 imágenes, observo que hay una reflejo que parece
  originado fuera del campo; le pregunto a Matilde, y buscando en 
http://archive.stsci.edu/cgi-bin/dss_form comprobamos que se debe a una
  estrella muy brillante que hay cerca del campo, y aunque no cae en el
  detector, lo que estamos viendo probablemente sean los arcos de difracción
  que genera la luz de la estrella en la óptica del telescopio/instrumento y
  que son vistos por el detector.
  
  Según Matilde, a priori, no sabe o no cree que eso se pueda eliminar
  facilmente, así que no habrá que preocuparse de momento por eso. 

  De todas formas, yo creo que con los skyflats(superflats) debería de haberse
  eliminado, no ?? pues están observando la misma zona del cielo...pero noooo,
  pues están cayendo sobre distintos píxeles, por lo que no hay nada que
  hacer, no ?? de todas formas tendría que ver si con alguna técnica de
  fringing removal se podría hacer algo ....

- Modificado genLogsheet para que pueda mostrar un subconjuto de filas y que
  además se pueda omitir la cabecera; todo esto con el objetivo de poder crear
  ficheros que puedan leer datasimy.py y createSeq.py



2011-10-26
----------

- Me suscribo a 3 listas de python, una de ellas en español ! para intentar
  estar un poco más actualizado del mundo Python. 

- Me pongo a buscar el bug que encontré al ejecutar el Test#23;
  Encotrado BUG sintáctico, estaba en ClFits.isScience()
 
- Me encuentro con otro/s bug/s a la hora de agrupar los datos:

     1) los master creados tienen un PAT_NEXP != N, y PAT_EXPN=1, con lo cual
     son confundidos/mezclados con los datos agrupados, provocando además que
     se queden fuera algunos ficheros que tendrían que ser agrupados.
     Para solucionar esto hago lo siguiente:

     	  - modifico las rutinas de creación de master para que actualicen el
                 valor de PAT_NEXP=1
	  - modifico en dataset.GetSeqFilesB() para que no tenga en cuenta a
                 la hora de agrupar los ficheros de tipo MASTER_XXXXX
		      

     2) En las rutinas de creación de masters, no se actualiza la keyword
     IMAGETYP, con lo cual PAPITYPE dice una cosa y IMAGETYP dice otro. Aunque
     PAPITYPE tiene prioridad, lo arreglo para que ambas digan lo mismo,
     aunque lo correcto sería eliminar IMAGETYP....

  
- Me surge la duda siguiente: ¿ qué debe tener más prioridad, un master dado
  de forma externa o uno creado por el propio pipeline como resultado de la
  reducción de la secuencia correspondiente ?
  Yo creo que debería tener prioridad el que reciba de forma externa ...pero
  tampoco lo tengo muy claro. Ahora el problema está en como implementar esa
  prioridad ....
  Se me ocurre, que vamos a tomar aquel que sea más reciente, mirando para
  ello la MJD --> usando el índice -1 de Python es sencillo.
  Para ello modifico RS.getCalibFor() de forma que devuelva el último elemento
  de la lista de master encontrados, que se supone será el más reciente.

- Modificación en el QL para que si no se ha activado la checkBox del outDir,
  se añadan las salidas generadas durante el procesamiento de los distintos
  datasets, básicamente para posibilitar que un science-DS pueda usar los
  master de calibración que hayan podido encontrarse y creado anteriormente.
  Para ello se modificó : MainGUI::checkLastTask()

- 
 
- Realizo los test #23-#30; destaco el test 30 que incluye a datos según el
  formato de GEIRS, que tienen que ser "convertidos" a 4 x (simple FITS) que
  puedan luego ser procesados por PAPI. Parece que de momento la cosa va bien,
  aunque aún queda por comprobar con datos reales si la astrometría de las
  nuevas imágenes creadas al partir el fichero original de GEIRS es correcta o
  no....

2011-10-27
----------


- Ejecutando el test #31, que fue bien, me doy cuenta de que por ejemplo, si
  para reducir una secuencia necesita alguna calibración con MJD posterior, la
  ordenación y ejecución de la reducción de secuencias no funcionaria, pues no
  la habría reducido todavía cuando es necesitada por una secuencia en
  cuestión. Es decir, sin en el test #31, los darks son posteriores a los
  twflats, da un ERROR diciendo que no encuentra el master dark necesario y
  que por tanto no puede crear el master TWFlat.

  Una posible solución que se me ocurre: que la ordenación de secuencias a
  procesar siga el criterio siguiente:

  	   	1- ordenar por MJD
		2- ordenar por DARK, DOME_FLATS, TW_FLATS, SCIENCE

  Para implementar esta solución añadi la funcion RS:reorder_sequences(), que
  hace justamente eso. La probé con el test #32 y funcionó correctamente. No
  obstante, llamo a esta función de reordenación a la hora de la reducción del
  RS, pero no cuando se muestra en la consola las Seqs encuentradas, más que
  nada para poder verlas ordenadas temporalmente.

  Obviamente, esto no es válido para el QL, pues en el QL se reducen las
  imágenes según van llegando...aunque pensandolo bien, también se podría usar
  cuando el usuario selecciona manualmente una sequencia de SCI y quiere que
  esté disponibles las calibraciones posteriores. Pero pensandolo mejor, es
  preferible que el usuario tenga que marcar/seleccionar todos aquellos
  ficheros que quiera tener en cuenta para la reducción o bien, indique
  explicitamente qué masterDark,masterFlat quiere usar.

- A raiz del tema de la ordenación de las sequencias y los problemas que puede
  dar en el QL si para reducir un SkyFlat no se han reducido aún los dark
  correspondientes, hago una modificación en QL para que avise también cuando
  no pueda reducir una secuencia, pues hasta ahora sólo avisava por la
  consola; ahora también muestra el mensaje en el Log de la GUI.
  Esto se puede probar con el test #32.


 
2011-11-02
----------

- Instalación de MV con openSuSE-11.1-64bit. Me dió bastantes problemas,
  entre:
	* primero de todo, al intentar instalar un SO guest de 64 bit,
  VirtualBox me avisa que tengo que habilitar en el BIOS del host principal el
  modo VT-x/AMD-v; no lo encontré en mi bios (DELL 390), pero había algo de
  virtualización y lo activé. A partir de ahí, VB me dejó instalar el SO 64bit.
	* me avisa de que el display del host es de 32 bit, pero que el guest
  está configurado con 16 bit--> eso no pasa nada, simplemente que para
  mejorar las prestaciones gráficas hay que instalar las GuestAdditions.
  	* Se me quedaba colgado al inicio de la instalación, y no sabía de qué
  podia ser; en un principio pensaba que era debido al mensaje de los 32/16
  bits del display, así que probé en modo texto (y seguia dicho mensaje), y
  fué cuando me di cuenta de que daba un error por el famoso ACPI. Para
  intentar solucionar esto desactivé en la definición de la máquina virtual la
  opción de ACPI. Con esto, ya me dejó instalar sin problemas.
  	* bueno, también se me quedó un par de veces colgada la instalación
por que no podía leer el DVD (incluso tampoco lo podia leer elwindowsXP), 
así que limpié varias veces el DVD hasta que volvió a leerlo sin problemas 
y pude instalar el openSuSE11.164bit.


 
- Implementación de apply_dark_flat=2
- Encontrado problema al ejecutar calTwFlat.py

2011-11-03
----------

- Encontrado y solucionado bug en calTwFlat.py --> el problema estaba en el
  parámetro input del mscred.flatcombine() que no estaba bien formado por el
  tema de la barra doble "//" que no acepta IRAF en los pathnames.

- Tras implementar el modo apply_dark_flat=2, hice las pruebas
  correspondientes y me dí cuenta de que tenía un error a la hora de crear el
  fichero stack1.pap en la llamada a coaddStackImages(). Tras solucinar dicho
  bug, todo parecía ir bien, aunque el test con datos de ALHAMBRA demostró que
  el FF después del skysubtraction (apply_dark_flat=2) es "como" (o sin el
  como) deshacer el skysubtraction, cosa que ya había comprobado en día
  anteriores y que coincide con lo que me decía Wei-Hao (SIMPLE).
  Por eso, realmente no le veo sentido a implementar dicho modo
  (apply_dark_flat=2), pero bueno, por si acaso...ya está implementado.

- Repito el test anterior (#32) con red_mode='science'


2011-11-04
==========

- Termino de instalar todo el software de PAPI en la Maquina Virtual (MV) de
  openSuSE que he creado eleborar el documento de instalación. 
  Al instalar la VBoxAdditions, me da un aviso de que parace que ya están
  instaladas en el SO guest, y que es mejor que no las re-instale, pero como
  tengo algunos problemas con el ratón y no tengo el FS para el mount.vboxfs
  para poder compartir carpetas con entre el host y el guest, pues no hago
  caso al aviso y dedido instalarlas. Después de un rato, re-compilando
  algunos módulos para el kernel y tal, pues todo parece terminar bien y
  funcionar correctamente. Veremos ....:-D

- Consigo finalmente instalar el binario (64bit) de SCAMPv1.7 y su dichosa
  dependencia de la libraria libplplot9; finalmente encuentro el RPM
  libplplot9-5.7.1-1.2.x86_64.rpm que se instala sin problemas.

2011-11-07
==========

- Videoconf PANIC: en cuanto al SW, aunque AGS dice que no está preparado y
  que prefiere postponer el viaje, JF insiste y dice que no se puede mover,
  así que finalmente iremos en el semana 47 como estaba previsto.
    

- Muevo el RS::reorder_sequences() al método  RS::getSequences  
  y ahora reoder_sequences() sólo se ejecuta si queremos reducir todo el DS,
  pero si hemos especificado una secuencia específica, no se reordenan pues no
  hace falta; con esto nos evitamos el problema de la altereación del número
  de secuencia mostrado según el ordernamiento MJD y el que le correspondería
  según el ordenamiento DARK, FLAT, SCIENCE, etc que hacer reorder_sequences.
  
  Es decir, NO hay problema de identificación del número de secuencia al
  especificar una secuencia a reducir en lugar de todo el DS.



2011-11-09
==========
- Defino algunos test para empezar las pruebas con AGS

- Asisto reunión convocada por Julio sobre HEXA

- Repito el test 18 con el Set HAWK-I-5, y obtengo un stitch final muy mal;
  miro los cuandrantes individiales Q0N y ninguno tiene la astrometría bien.
  Depurando, me doy cuenta de que SCAMP se queja (linea roja), y por eso no
  hace bien la astrometría con GSC-2.3.
  Cambio a 2MASS, y ahora la astrometría es buena !!! por qué ?? será que
  habré cambiado algún parámetro (NSIG en skyfilter, DETECT_THRESH, ...) ?
  La imagen final de los cuatro cuadrantes (stiched) está más o menos bien,
  con poca marca de la noise-cross-shape central.

- Inicio de pruebas integración OT-QL:


  
2011-11-10
==========

- Continuo pruebas de QL y depurando.
- Implemento eval_focus_serie.py, que basandose en checkQuality.py, calcula el
  mejor foco de una serie de foco. Lo pruebo con el ejemplo  de O2k que me
  pasó Ulli y funciona bien !!! Para el caso de PANIC, debería funcionar
  también sobre las imágnes 4kx4k, a pesar de la cruceta, pues SExtractor es
  robusto a eso...lo mejor sería simularlo y probarlo. 

- Por la tarde, hacemos algunas pruebas AGS y yo con el OT y el QL (ver
  documento manuscrito). Encontramos varios BUGS tanto en OT como QL.
  
  En OT: básicamente que no enumera bien las secuencias con el instrument
  iterator
  En QL: que no avisa de que un conjunto de ficheros no tiene ninguna
  secuencia, dando una exception "TypeError". (lo solucioné al día siguiente).

 


2011-11-11
==========

- Encuetro el bug del día anterior.
- Encuentro otro bug en eval_focus_serie, pues en los nuevos ficheros de PANIC
  el kw de foco telescopio se llama T_FOCUS en lugar de T-FOCUS. Modifico
  convenientemente la rutina.

- Comienzo diseño de DEMO PAPI/QL (papi_demo.txt)

- Tarde: AGS y yo continuamos con las pruebas de OT-QL:

  Basicamente hicimos un recorrido por el documento "WhatWeNeed.doc" de JF, y
  los principales fallos/problemas encontrados fueron:

      1) domeflats no tiene el orden on/off correcto, pues mezcla con los
      filtros. Lo correcto para una secuencia de 1-N sería
      on-on-on-off-off-off y seguir con el siguiente filtro.

      2) skyflats : no los podemos probar, pues no los tiene completamente
      implementados, pues el OT no tiene simulado el incremento artificial del
      número de cuentas.

      3) focur series: no implementado en OT, pero le doy el .prg y la idea de
      cómo hay que hacerlo. Intentará implementarlo para HD.

      4) simple exposure: no funciona ese caso particular

      5) nodding pattern: no implementado, pero le paso el sky_pointing.prg y
      cómo lo podría implementar. No cree que pueda tenerlo para HD.

      6) Pause: no está en OT, pero cree que lo podrá implementar, no es muy
      dificil.

  En cuanto al QL, no encontré errores, sólo lo siguientes comentarios:

      1) ver que nodding pattern puede contemplar PAPI ( y el OT) según las
      sugerencias de Ulli.

      2) ver que hace el QL/PAPI cuando encuentra dos PAT_EXPN=1 en una
      secuencia ????


2011-11-14
==========

- Pruebas O2k objetos extenso, secuencia T-S-T-T-S-T-T-....(NGC5866). 
  Encuentro&Soluciono BUG en skyfilter_general, en la funcion que lee el IMAGETYP, pues
  no contenplaba bien los NULL.

- Reduciendo la serie anterior, SExtractor da el mensaje :


WARNING: Pixel stack overflow at position 


que según E.Bertin es debido a :

"""
Hi.
Given the fairly large size of your image, different memory settings (and/or aperture settings) can lead to a different number of sources. This may seem like a bug but it isn't (in principle!). The reason is that the SExtractor engine was originally written at a time when computer memory was scarse (a good workstation had ~16MB of memory back then, and SExtractor was meant to work with 1.8 GB Schmidt plate scans). Hence memory usage had to be kept under strict control, which explains the buffer limit settings. These limits may be reached if your image is populated with many and/or very large objects and/or if some measurements require large apertures. In that case, SExtractor has to make choices: change the order in which objects are extracted and/or measured, change details about the cleaning of spurious sources around bright sources, and, for the most critical cases, give up on extracting and/or deblending and/or measuring objects. Obviously, decisions of statistical significance are accompanied by a proper flagging of the detections involved (see the SExtractor documentation). Most of the time, this will concern bright, saturated stars or large image artifacts (halos, bad columns, satellite trails, etc.). It may however affect "normal" sources if inappropriate detection parameters are used: exceedingly low detection thresholds and/or unsuitable background mapping parameters (the detection algorithm has to percolate through the background noise and deblend large "empty" areas), exceedly high deblending contrast in very crowded fields...
In suspicious cases, I would recommend checking SEGMENTATION check-images and
source FLAGS to verify that SExtractor is operating in the intended regime.

"""

Ese mismo warning ya lo he visto en otras ocasiones, pero nunca le he hecho
caso. Habría que ver como afecta a la reducción....



- DUDA en eval_focus_serie.py habría que ordenar los frames por MJD
  antes de evaluarlos ???
  Realmente el orden va a dar igual, pues para el ajuste no afecta para nada.

- DUDA a resolver : en eval_focus_serie.py habría que hacerles algún tipo de
  procesamiento (Dark, Flat, Sky....) antes de evaluar el FWHM ?
  Pues en teoria se obtendrían mejores resultados...habría que hacer algunas
  pruebas.

- BUG resuelto: faltaba en db.getFilterFiles() en el primer select un "order
  by MJD"

- Pruebas OT-QL:

  * domeflat : sigue el problema de la numeración de secuencias
  * single exposure + telescope interator : no contemplado
  * single exposute + cycles = 2 : no enumera bien las secuencias
  * skyflats : no terminados de implementar
  

2011-11-15
==========

- Añadido nuevo tipo de agrupamiento --> "none" , que hace que no se agrupe y
  que simplemente considere todos los ficheros como pertenecientes a un mismo
  grupo.

- Añadida al config file skysub.skymodel y modificada la función
  RS::skyfilter() para que admita dicho parámetro.
  
- Hago el primer esquema del proceso de reducción de PAPI; queda pasarlo a
  limpio.

2011-11-16
==========

- Bug resuelto en QL: había un bug en la creación del QTimer cuando se
  especifica un directorio a "monitorizar" que afectaba a mainGUI.py

2011-11-20 al 25
================

- Pruebas SW de integración en HD. (ver documentos de notas)
 
2011-11-29
==========
- Inicio funcion read_GEIRS_fitsLog() para mejorar la lectura de los ficheros de
log de GEIRS, tanto

    * ~/GEIRS/log/save_CA2.2m.log
    * ~/tmp/fitsfiles.corrected
    
2011-12-12
==========

- Teleconf PANIC: JF me comenta que no tiene inconveniente en enviarme la carta
de consentimiento para la ayuda de movilidad, pero me pregunta que fechas tendría
previsto para ir. Yo lo contesto que en principio Verano, pero que aún o se cuando
estaría el dinero y tal. JF piensa que es muy tarde, pues el piensa en poder 
hacer algo para GEIRS.
Y sobre el SW, pues que el OT le parece demasiado complicado, y que quizás sería
mejor hablar con CA (Ana Guijarro). 
También comenta que van a contratar una persona para que ayude a CS con el SW.

- Recibo llamada de Jens para hablarme del nuevo CCD-SW para Twin. Por lo visto
el software de bajo nivel lo harían en HD, a modo de librería similar a la que 
hicieron para CAFOS-upgrade, y la GUI sería para hacerla nosotros, más la GUI
de control del instrumento Twin, para sincronizar las dos CCDs etc ...
Le digo a Jens que tenemos que consularlo con Matilde & Julio.


- Modifico QL para que se pueda seleccionar desde el botón Input/Source dir tanto
un directorio como los ficheros de log de GEIRS (save_CA2.2mlog y fitsfiles.corrected).
Tengo que probar bien si funcionar en cualquier versión de SuSE, pues me pareció 
que en el portatil no funcionaba bien.


2011-12-13
==========

- Pruebo el qphot de forma interactiva para ir seleccionando y visualizando los
valores fotometrícos de los objetos en la imagen reducida y aunque al principio
me costó entender el manejo, luego es muy potente y útil. Además, si tenemos 
activado el radplot=yes, es muy interesante. Podemos decirle además el ZPOINT
que queremos que use para el cálculo de la fotometría.


2011-12-14
==========

- Implemento rutina 'plot_cpu_mem_stats.py' para sacar las gráficas de CPU y 
memoria de los test hechos en Heidelberg.

- Instalo sphinx + pygments (con easy_install) para empezar a documentar PAPI

- Comienzo con primeras pruebas.


2011-12-15
==========

- Continuo probando Sphinx, pues parece muy interesante para usar en la documentación
de PAPI. Sin embargo, de cara a documentar el codigo fuente (python) de PAPI
me encuentro con el problema de que hasta ahora el codigo fuente de PAPI lo 
estaba documentando en las docstring siguiendo la sintaxis de epytext/javadoc, 
pero resulta que Sphinx usa las docstring del formato reST(reStructuredText);
según he buscado en google, no parece que haya una forma fácil para pasar de
epytext a reST.

La sintaxis de reST para las docstring de python es la siguiente:
 
 -http://epydoc.sourceforge.net/manual-fields.html#epydoc-fields

 -http://mundogeek.net/archivos/2008/07/07/documentacion-en-python/#more-1582


También me doy cuenta de que en las docstrings del codigo python no podemos usar
todos los metatags de reST, pues al importar los modulos en sphinx se queja;sin
embargo, veo que la documentación de Numpy si los usa, pero para ello hay que 
instalar una extensión a sphinx propia de Numpy para que se genera la documentación
como en Numpy ( ver  https://github.com/numpy/numpy/tree/master/doc/sphinxext)

2012-01-09
==========
- Incorporación después de vacaciones !
- Matilde me dice que han estado observando con O2k para su proyecto. Quedamos
en que me bajaré los datos y iré mirando como reducirlos, al menos hasta la
sustracción de cielo, pues a partir de ahí continuará LEMON.


2012-01-10
==========
- Comienzo la implementación para que PAPI se detenga en después de la sustracción
de cielo y devuelta la lista de ficheros pre-reducidos para pasarle a LEMON.

- En las primeras pruebas de la reducción de datos de Matilde, me doy con 
problemas como:

    1) Hay un objeto extenso (nebulosa) y no han observado en modo "T-S-T-S-...",
    por lo que PAPI no puede reducir bien las imágenes por la nebulosa.
    1) las secuencias de Ks tiene dos iteraciones sobre un patrón de dithering
    de 5 posiciones, con lo cual el algorimo estimación de cielo no funciona 
    bien y hace sobrecorrección.
    2) los parametros del calculo del gainmap son muy severos (0.7,13), por lo
    que los relajo a (0.5, 1.5)
    
- Hablo con Matilde de estos primeros problemas y me dice que no me preocupe, 
que primero ella estudiará cual es le mejor método para la sustracción de cielo.

2012-02-22
==========
- Modificación en applyDarkFlat, calTwFlat y ReductionSet para usar 
MASTER_DARK_MODEL de forma que se pueda escalar correctamente, pues como se hacia
antes con un MASTER_DARK normal, no estaba bien, pues se estaba escalando también
el BIAS intrinseco de los DARK.

- Modifico también la rutina calDarkModel para que se grabe en el header alguna
información mas sobre el DARK_MODEL.

2012-02-24
==========

- Implementacion metodo dxtalk.py (O2k y PANIC)

2012-02-25
==========

- Lanzamiento de PAPI (modo lemon) con todos los datos de Matilde de 
O2k (Enero-Febrero 2012)

2012-02-27
==========
- Revision resultados reducción de PAPI
- Implementacion de nueva opcion en PAPI para que permita usar ficheros de
calibracion maestros (master dark, flat ...) de un repositorio (directorio)
externo, de forma que si al reducir un DS no dispone de los correspondiente masters,
pueda usar los que haya en dicho repositorio.


2012-02-28
==========
- Dudas sobre los valores obtenidos en el dark model. Pregunto a Clemens, Vianak 
y Rene Fassbinder sobre el tema para ver si me sacan de la duda.


2012-03-02
==========
- Rene Fassbinder me responde aclarandome finalmente donde estaba mi error con 
la estimación de dark model medio---> El valor de MEAN no es significativo !!!!
Está "contaminado" por los hot-pixels !!! 
De todas formas, el método de dark-model y la sustracción de dark correspondiente
hecha en las imágenes de Matilde creo que están bien !


2012-03-05
==========
- Estudio para ver como mejorar el dxtalk.py de forma que tenga en cuenta los 
outliers y estrellas brillantes al calcular la mediana.
Encuentro interesante el método : Standard Deviation Mask que trae Maxim/DL.

- Encontrado en http://www.astro.yale.edu/dokkum/lacosmic/ código Python para 
eliminar Cosmic-Rays (CR) de imágenes basado en http://arxiv.org/abs/astro-ph/0108003 
Lo pruebo con imágenes de O2k y parece que va bien, aunque tarda 2'20''.
Los CR en principio se "resuelven" en el IR al hacer el combine del stack, pero
en el modo Lemon quizás sea interesante tenerlo ????

2012-03-06
==========
- Continuo con el estudio y pruebas de rutina alternativa para iraf.imcombine,
pero sin éxito.

- Escribo en las listas de AstroPy y NumPy para pregunar acerca del tema.
Objengo respuestas, diciendo que el paquete stsci contempla dicha rutina, pero 
hay que instalar PyRAF !!!! entonces estamos en la misma. No obstante podría
ser un punto de partida para mi implementación.

  
2012-03-08
==========
- Modificación en PAPI para que detecte secuencia de Dark para DarkModel o 
Master dark tradicional. Esto implicó modificar un poco la funcion RS.checkData().

2012-03-09
==========
- Implementada nueva funcionalidad a QL para restar los 2 últimos SCI-frames
recibidos, mejor dicho, los 2 más nuevos (MJD) --> pushB_subtract_last2_slot()

- Añado opción remove_cosmic_ray al fichero de configuración 

2012-03-10
==========


2012-03-14
==========

- Videoconf: le envio las siguientes notas:

"""
-PAPI+LEMON reduced ~7000 O2k images (Z,J,H,Ks) of Matilde's project 
-PAPI : dark, flat, sky-subtraction and de-crosstalk (also ready for PANIC) - 
- LEMON: time series analysis - Photometric precision up to 0.015mag (constant star) 
  Attached figure: preliminary V and Ks band lightcurves of one star of the sample for which there is an shift between a visible and a near-infrared minimun. 
- Added to PANIC a module for cosmic rays removal (based on P. van Dokkum's L.A.Cosmic algorithm, http://www.astro.yale.edu/dokkum/lacosmic/) 
- Improvement in master dark model computation 

About the OT, no news; Antonio is in vacation. 
"""

Sale nuevamente el tema de los problemas de memoria en GEIRS, en los que está
aún trabajando CS, y que cree que son problemas en el kernel, pero que espera
poder resolverlos pronto.

2012-03-27
==========

 - Modificación en calDomeFlat, calTwFlat, calSuperFlat para solucionar/mejorar
 la normalization wrt chip 1, además de mejoras varias y documentacion en codigo
 - Encuentro el metodo (trick) para usar dome+sky flat de forma que aprovechemos
 las propiedades de ambos:
 
"""
A trick to combine domeFF and skyFF :

Often for a run you have dome flats with an accumulated number of
electrons in the millions, but a poor match in illumination and color to the dark
sky. You also have a limited number of twilight flats or dark-sky images that can
be combined to make a dark-sky flat, but the total counts per pixel in either set of
flats is not very high. A fairly standard procedure is to “median-smooth” dome
and twilight or dark-sky flat. A median smoothing replaces each pixel with the
median of the pixel values in a box of a given size on a side. The result is an image
that has been smoothed on the scale of the smoothing box size.
A procedure for taking advantage of the facts that the large-scale flat-field
variation of the dark-sky flat match that of the program frames and the dome flats
have very high S/N in each pixel goes as follows:
 
 (a) Median smooth the combined, dark-sky flat — this improves the S/N and
preserves the large-scale features of the flat.
 (b) Median smooth the combined dome flats using the same filter size as was
used for the dark-sky flat.
 (c) Divide the combined dome flat by it’s median smoothed-version. The result is
a frame that is flat on large scales but contains all the high spatial frequency
flat-field information.
 (d) Now multiply the smoothed dark-sky frame and the result of the division in
the previous step. You now have a flat-field with the low spatial frequency
properties of the dark-sky flat combined with the high S/N, high spatial
frequency properties of the dome flat.
"""

2012-03-28
==========
 - Modificación en calGainMap para hacer (opcionalmente) la normalization wrt 
 chip 1 para el caso de imágenes full-frame de PANIC (como las saca GEIRS).
 Aunque en principio la normalizacion ( si hay varios detectores, wrt chip1), 
 puede ser realizada al crear los master-flat, tambien está la opción de hacerla
 en calGainMap.
 Si por "error" se hicese en los dos casos (master flat y gainmap), no creo que 
 pasase nada. 
 
 - Una vez más me surge la duda de si aplicar el FF y luego usar el GM (gainmap)
 puede ser redundante y/o contraproducente. Después de ver donde se usa el GM
 en PAPI:
    1) skyfilter :
        1.a) como BPM
        1.b) crear el wmap (NCOMBINE*INT_TIME*gainmap*ImageVariance) 
        cuando usamos cube_mean() con mascara de objetos
        1.c) procedimiento IRDR::destripe() que no usamos de momento en PAPI
    2) dithercubemean:
        2.a) de nuevo, al crear el wmap, y en cube_mean()
 
 llego a la conclusión de que el gainmap es "cte" para todas la imagenes de un
 stack de dithering, y por tanto no debe ser determinante.
 Además, revisando la documentacion "IRDR Users Guide" veo que hacen igual,
 aplican FF, generan GM con el FF y luego usan el GM en skyfilter y dithercubemean.
 Por tanto, de momento podemos dejarlo así.
 
 - Encuentro un BUG(?) en mean.c, pues MINCLIP estaba a 1.5 en lugar de 5, que
 es el valor original. Debe ser que alguna de mis pruebas con el NSIG del
 cube.c, me confundí y modifiqué erroneamente el MINCLIP. 

 

2012-03-29
==========

 - Añadida option de 'median_smooth' a los FF (dome,tw,sky)
 - Implementado modulo para combinar domeFF y skyFF --> calCombineFF.py
 

2012-03-30
==========

  - Pruebas de los procedimientos modificados el día anterior, procurando que 
pase por todos los casos posibles.

  - Estudio de los modos de autenticacion de subversion 

2012-05-09
==========
   - Videoconf: no pude asistir por subir al OSN a instalar la CCD Excelon 
   en Albireo.
   Parace ser que lo unico destacable respecto al SW fue que JF pregunto para
   cuando la segunda integracion del SW.
   

2012-05-10
==========

   - Comienzo migracion de pprocess a multithreading (python >2.7)
   - Encuentro un problema pues lo metodos de clases no los soporta
   directamente Pool.apply_async(), hay que hacerlos "picklable".

2012-05-11
==========
   - Encuentro una solucion para el problema anterior:
   http://stackoverflow.com/questions/3288595/multiprocessing-using-pool-map-on-a-function-defined-in-a-class
   
   y parece que funciona. 
   
   
2012-05-12
==========
   - Lanzo PAPI con mutiprocessing.Pool y parece que funciona bien (data set
   de HAWK-I-3).
   
   - Ahora detecto un problema "aleatorio" (no ocurre siempre) en el multiprocessing:
   
   Exception in thread Thread-1 (most likely raised during interpreter shutdown):
Traceback (most recent call last):
  File "/gel/usr/mawal32/system/lib/python2.7/threading.py", line 530, in __bootstrap_inner
  File "/gel/usr/mawal32/system/lib/python2.7/threading.py", line 483, in run
  File "/gel/usr/mawal32/system/lib/python2.7/multiprocessing/pool.py", line 272, in _handle_workers
<type 'exceptions.TypeError'>: 'NoneType' object is not callable
   
y parece que esta reportado el bug, pero no consigo solucionarlo de momento:
   
   http://bugs.python.org/issue9207.

2012-05-14
==========
   - Añado al multiprocessing las llamadas:
   
        pool.close()
        pool.join() 
        
     para intentar solucionar el problema aparecido el dia anterior.
   - Lanzo PAPI varias veces y parece que funciona bien (data set HAWK-I-3).
   - En una de las veces que ejecute PAPI el 15-Mayo si fallo otra vez dando el
   mensaje de arriba (12-May), por lo que parece que con el close()+join()
   no se soluciona.
  
2012-05-15
==========
   - Pruebas en reduceSingleObj() con AstroWarp en el modo "quick":
     
       - con HAWK-I-3, y DETECT_THRESH=4, no es capaz de hacer astrometría ni crear el mosaico;
       con DETECT_THRESH=1.5, hace astrometría mal, y por tanto el mosaico final tambien está
       desformado.
       - con O2k-Matilde-2012-20120105-S-5, si lo hace bien (DETECT_THRESH=1.5)
       
   - Una prueba con O2k-Matilde-2012-20120105-S-6 falló, pues el gainmap era todo BPM !!!! ---> BUG ????
       
   - Reunion con MF para dudas de PAPI (ver comentarios abajo, sección DOUBTS FOR MATILDE)

2012-05-16
==========
    - Compruebo que haciendo :
      
      > aladin /tmp/reduced_SEQ.fits /tmp/reduced_SEQ_zp.xml 
      
      y haciendo click sobre una objeto no muestra los valores de catalogo leido 
      (/tmp/reduced_SEQ_zp.xml) y generado con SExtractor con el MAG_ZEROPOINT 
      calculado previamente con photometry.py
  
    - Le pregunto a VTerron si el ha tenido problemas con multiprocessing, parece
    que no ha tenido problemas; el usa Pool.map_asycn(), asi que voy yo a probar 
    con esa llamada para ver si así se soluciona.
    

2012-05-17y18
=============
    - Implementacion y pruebas del metodo collapse() para sumar cubos; aun pendiente
    la suma de ficheros independientes, pues aunque el suma de ficheros independientes
    esta implementada de momento, aun no se como "agrupar" los ficheros. Le pregunto
    a Clemens si podria usar el FRAMENUM y si me podria añadir algo para saber cuantos
    ficheros tiene una exposición (repeats). Me responde que en la nueva logica de los 
    FITS que tambien necesita Lucifer, y que para septiembre:

"""    
Will come with the new FITS-header-organisation at least until September
(needed also for Lucifer). Please just assume a dummy-keyword name, which you
might replace with  the correct on.
"""
    
    
2012-05-21
==========    
    - Me encuentro un problema a ejecutar PAPI en el portatil (suse11.1-64);
    el problema surge al importar el paquete cosmics, que a su vez importa un
    modulo de scipy que da problemas.
    Para intentar solucinarlo, actualizo numpy1.6.2, scipy0.10.1
    Pruebo la demo de cosmics y ahora ya no da problemas !!!  

   - Otro problema es que en el portatil tengo python2.5, y no tiene el paquete multiprocessing
    por defecto a partir de python2.6, por lo que me bajo el paquete independiente de 
    backport de multiprocessing para python 2.5. Se instala sin problemas y las pruebas de unidad
    se ejecutan sin problema.

2012-05-22
==========    
    - Escribo a Wei-Hao para preguntarle sobre el dxtalk_wircam
     Wei-Hao me responde:
      """
      How about a simple background subtraction in each stripe after
      the subtraction of the median?  Maybe this will solve the problem.
      """
    - Busco en THELI sobre el dxtalk, y aunque aparece en la documentacion no encuentro el código

2012-05-24
==========    
    - Haciendo pruebas con PAPI, me encuentro con el un error aleatorio, pues no siempre ocurre (50%), 
    y tanto con pprocess como con multiprocessing. El error se produce en la llamada iraf.mscred.mscarith(...)
    en calSuperFlat.py. Compruebo que los parametros de llamada de la función están bien; no se por qué puede ser ???
    Este error se produce tanto en openSuSE11.1-i586 (python2.6) como con suse11.4-x64 (python2.7)  

    [PAPI]: 2012-05-24 17:13:00,575 DEBUG    calSuperFlat:222: Normalization of master (O2k?) flat frame. (MODE=2857)
    [PAPI]: 2012-05-24 17:13:00,576 DEBUG    calSuperFlat:226: Normalization parametes---> (tmp1=/data/out/Q02/tmp_sf.fits,result=/data/out/Q02/superFlat.fits)
    [PAPI]: 2012-05-24 17:13:00,632 DEBUG    calSuperFlat:222: Normalization of master (O2k?) flat frame. (MODE=2857)
    [PAPI]: 2012-05-24 17:13:00,633 DEBUG    calSuperFlat:226: Normalization parametes---> (tmp1=/data/out/Q01/tmp_sf.fits,result=/data/out/Q01/superFlat.fits)
Killing IRAF task `delete'
Killing IRAF task `delete'
Exception OSError: (10, 'No child processes') in <bound method Subprocess.__del__ of <Subprocess '/iraf/iraf/bin.linux/x_system.e -c', at 15a6d40>> ignored
Exception OSError: (10, 'No child processes') in <bound method Subprocess.__del__ of <Subprocess '/iraf/iraf/bin.linux/x_system.e -c', at 15a6d40>> ignored
    [PAPI]: 2012-05-24 17:13:03,286 ERROR    reductionset:2085: [reduceSeq] Error while parallel data reduction ! --> Error running IRAF task delete
('IRAF task terminated abnormally\nERROR (601, "Parameter not a legal boolean (try \'yes\' or \'no\') (verify)\x07")\n', 10, 'No child processes')                                                   
    [PAPI]: 2012-05-24 17:13:03,286 ERROR    reductionset:1773: [reduceSet] Cannot reduce sequence : 
 ['/data/i_test/001/dark_seq_ind0072.fits', '/data/i_test/001/dark_seq_ind0073.fits', '/data/i_test/001/dark_seq_ind0074.fits', '/data/i_test/001/dark_seq_ind0075.fits', '/data/i_test/001/dark_seq_ind0076.fits']                                                                                                                                                                                       
 Error running IRAF task delete                                                                                                                                                                      
('IRAF task terminated abnormally\nERROR (601, "Parameter not a legal boolean (try \'yes\' or \'no\') (verify)\x07")\n', 10, 'No child processes')  



    SOLUCION: sustituyo la llamada a iraf.mscred.mscarith por las operaciones correspondientes en python !!!
    

2012-05-25
==========  
  - Elimino el chequeo de los FITS en la funcion mainGUI:new_file_func(), pues ahora es realizado
  en el clfits::recognize(). Lo pruebo y parece que va muy bien.
  Esto servira para todos los modos 'file' & 'dir' del datacollector.
  - Observo algo que parece una condición de carrera, y es que alguna vez puede ocurrir que aunque
  el chequeo del FITS sea correcto, GEIRS no haya aún añadido las keywords que le da el OT y entonces
  el QL no detecte bien el fichero pues no puede leer dichas keywords esenciales.
  
  - Se siguen produciendo errores de PyRAF de vez en cuando !!!!:
    
       [PAPI]: 2012-05-25 13:29:58,295 INFO     calSuperFlat:145: Combining images...(images are scaled to have the same median)
Killing IRAF task `combine'
Exception OSError: (10, 'No child processes') in <bound method Subprocess.__del__ of <Subprocess '/iraf/extern/mscred/bin.linux/x_combine.e -c', at 32692d8>> ignored
    [PAPI]: 2012-05-25 13:29:58,457 INFO     reductionset:2440: ##################################
    [PAPI]: 2012-05-25 13:29:58,457 ERROR    reductionset:2085: [reduceSeq] Error while parallel data reduction ! --> Error running IRAF task combine
('IRAF task terminated abnormally\nERROR (603, "Parameter not a legal number (project)\x07")\n', 10, 'No child processes')                                                                                                   
    [PAPI]: 2012-05-25 13:29:58,458 INFO     reductionset:2441: #### Starting Object Data Reduction #####
    [PAPI]: 2012-05-25 13:29:58,458 ERROR    reductionset:1773: [reduceSet] Cannot reduce sequence : 
 ['/home/panic/data/i_test/001/dark_seq_ind0217.fits', '/home/panic/data/i_test/001/dark_seq_ind0218.fits', '/home/panic/data/i_test/001/dark_seq_ind0219.fits', '/home/panic/data/i_test/001/dark_seq_ind0220.fits', '/home/panic/data/i_test/001/dark_seq_ind0221.fits']                                                                                                                                                                                
 Error running IRAF task combine                                                                                                                                                                                             
('IRAF task terminated abnormally\nERROR (603, "Parameter not a legal number (project)\x07")\n', 10, 'No child processes')


  Otro error:
    
    [PAPI]: 2012-05-25 13:33:26,592 ERROR    reductionset:1901: [reduceSeq] Some error while creating master DARK: [Errno 32] Broken pipe
    [PAPI]: 2012-05-25 13:33:26,592 ERROR    reductionset:1773: [reduceSet] Cannot reduce sequence : 
 ['/home/panic/data/i_test/001/dark_seq_ind0222.fits', '/home/panic/data/i_test/001/dark_seq_ind0223.fits', '/home/panic/data/i_test/001/dark_seq_ind0224.fits', '/home/panic/data/i_test/001/dark_seq_ind0225.fits', '/home/panic/data/i_test/001/dark_seq_ind0226.fits']                                                                                                                                                                                
 [Errno 32] Broken pipe                                                                                                                                                                                                      
    [PAPI]: 2012-05-25 13:33:26,592 DEBUG    reductionset:1774: [reduceSet] Procceding to next sequence...
Exception in thread Thread-10:
Traceback (most recent call last):
  File "/usr/lib64/python2.7/threading.py", line 530, in __bootstrap_inner
    self.run()
  File "/home/panic/DEVELOP/PIPELINE/PANIC/trunk/reduce/threadsmod.py", line 51, in run
    raise e
OSError: [Errno 32] Broken pipe


  - Hago una primera prueba/implementación en QL para usar Process+Queue en lugar de la clase ExecTaskThread que "pienso"
  que puede ser la causa de los errores de PyRAF descritos arriba.
  
  - Muevo algunos métodos relaccionados con FITS del módulo misc.utils al modulo clfits

2012-05-29
==========  
  - Reunion con Matilde (ver notas más abajo).
  - paper SPIE2012

2012-05-30
==========  

   - Modificacion en phometry para que genere al catalogo con el ZP estimado (sugerencia MF)
   

2012-06-11
==========  
   - Working on TaskRunner in QL and improvements in DataCollector 
   
2012-06-12
==========  
 - Sent to JF next notes for the videoconf:
   
    - Implemented support for FITS cubes (non integrated mode)
    - Implementing support for distinguished FITS-files (non integrated)
    - doing improvements on the parallel processing 
    - (of course) debugging and profiling 

  - Encuentro problemas serios en QL cuando se intenta reducir todo un DataSet
  de un directorio leido del tirón.
  Ese mismo error se produce tambien en PAPI cuando por ejemplo hacemos:
  
     > papi -s ~/DATA/i_test/001/ -S 8 9
     
     donde 8 es una secuencia de DARK 
           9 es una secuencia de SCI

    en cambio si 8 fuese una secuencia de SCI tambien, entoces no hay error !!!
    por que ???
    
    ---> TODO PARECE INDICAR QUE EL PROBLEMA ES POR LA CONCURRENCIA DE IRAF !!!!!!!
    
"""
Killing IRAF task `combine'
Exception OSError: (10, 'No child processes') in <bound method Subprocess.__del__ of <Subprocess '/iraf/extern/mscred/bin.linux/x_combine.e -c', at 208fea8>> ignored
    [PAPI]: 2012-06-12 18:56:03,092 ERROR    reductionset:2087: [reduceSeq] Error while parallel data reduction ! --> Error running IRAF task combine
('IRAF task terminated abnormally\nERROR (603, "Parameter not a legal number (project)\x07")\n', 10, 'No child processes')                                                                                                                                                     
    [PAPI]: 2012-06-12 18:56:03,092 ERROR    reductionset:1773: [reduceSet] Cannot reduce sequence : 
 ['/home/panic/data/i_test/001/dark_seq_ind0046.fits', '/home/panic/data/i_test/001/dark_seq_ind0047.fits', '/home/panic/data/i_test/001/dark_seq_ind0048.fits', '/home/panic/data/i_test/001/dark_seq_ind0049.fits', '/home/panic/data/i_test/001/dark_seq_ind0050.fits']     
 Error running IRAF task combine                                                                                                                                                                                                                                               
('IRAF task terminated abnormally\nERROR (603, "Parameter not a legal number (project)\x07")\n', 10, 'No child processes')                                                                                                                                                     
    [PAPI]: 2012-06-12 18:56:03,092 DEBUG    reductionset:1774: [reduceSet] Procceding to next sequence...
    [PAPI]: 2012-06-12 18:56:03,092 DEBUG    reductionset:1781: [reduceSet] All sequences processed.
    [PAPI]: 2012-06-12 18:56:03,093 DEBUG    reductionset:1782: [reduceSet] Files generated # 1 #: ***
    [PAPI]: 2012-06-12 18:56:03,093 DEBUG    reductionset:1783:             - /data/out/mDark_FVSjmi_2_2.fits
    [PAPI]: 2012-06-12 18:56:03,093 DEBUG    reductionset:1784:             Sequences failed  # 1 #: ***
    [PAPI]: 2012-06-12 18:56:03,093 INFO     reductionset:1371: Purging the output dir ...


Well done (I hope) -  Elapsed time(s): 10.733102!!!
List of images to combine ('@/data/out/Q01/files.txt'): XIO:  fatal IO error 11 (Resource temporarily unavailable) on X server ":0"
      after 24 requests (24 known processed) with 0 events remaining.

PANIC in `/iraf/extern/mscred/bin.linux/x_combine.e': Write to IPC with no reader
"""

2012-06-13
==========  

 * Pre-videoconf, videoconf y postvideoconf
  - JF pregunta sobre que es el profiling y que es LEMON
  - JF pregunta sobre la fecha para hacer la II-Sw-integration: CS está sin tiempo !!
  - Quedamos en preparar un TODO-list con las cosas del SW de PANIC que quedan pendientes
  con el objetivo de intentar determinar cuando podríamos tener la II-SI
  
 * Solucion a bug de PyRAF cuando llamamos al algún metodo en multiprocessing (ver notas del día 12-Jun-2012)
   Gracias V.Terrón (ejemplo pyraf_multiproc.py) , que el ya había pasado por el mismo problema, 
   encontramos que el "truco" está en crear el multiprocessing.pool antes de cualquier posible llamada a alguna rutina de PyRAF.
   En el ejemplo del 12-Jun, la al reducirse la secuencia de DARK con darkcombine y luego reducir 
   la secuencia de SCI con un Pool, entonces se corrompe el espacio de nombres de PyRAF o lo que sea
   y ya se produce el error. 
   Lo soluciono en reductionset.py declarando el Pool justo despues de la clase ReductionSet, pues si lo
   declaro antes, da otro error por que no conoce la clase RS.
   
 * Ahora queda probar que en el QL todo funciona bien tambien.
   Pues nada mas probar, me doy cuenta de que no funciona, pues el declarar
   variables globales (pool) en reductionset.py, luego el Process que creamos
   en el QL para procesar las secuencias (vía Queue) no puede acceder a dicho
   pool global; aunque no se queja de ningún error, proceso de reducción 
   se queda esperando forever en el result.get().
   
   Solución: ver 15-6-2012
   
2012-06-15
==========  
   
   * Por fin encuentro la solución la problema del interbloqueo por la variable
   global pool para evitar el bug de IRAF.
   La solucion (espero que definitiva!) es crear el pool local en RS.reduceSeq()
   de forma que lo usemos para todas la operaciones que requieran IRAF, de forma
   que siempre habremos creado el pool con todo su espacio de nombres correcto
   antes de llamar a IRAF (bug detectado por V.Terrón)
   
2012-06-19
==========  

 - Estudion y/o migracion de los métodos que usan ExecTaskThread en QL;
 Me encuentro con un dilema al migrarlo todo y hacer que todas las operaciones
 pasen por el TaskManager y su cola, pues podría interesar que mientras se esté 
 ejecutando la reducción de un DS "largo" se pueda interactura con el QL para 
 realizar otra operación de "corta" duración (subtract_last_2, divide, etc...).
 En dicho caso, habría que tener dos colas o bien dejarlo como está con Threads.
 
 Mientras decidio sobre dicho dilema, me encuentro con un problema al migrar
 QL:processLazy, pues me da el famoso error :
 """
 Process Process-1:
Traceback (most recent call last):
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 232, in _bootstrap
    self.run()
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 88, in run
    self._target(*self._args, **self._kwargs)
  File "/home/panic/DEVELOP/PIPELINE/PAPI/trunk/QL/mainGUI.py", line 2610, in worker
    func, args = input.get()[0]
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 91, in get
    res = self._recv()
  File "/home/panic/DEVELOP/PIPELINE/PAPI/trunk/QL/mainGUI.py", line 100, in _unpickle_method
    for cls in cls.mro():
AttributeError: ("class ApplyDarkFlat has no attribute 'mro'", <function _unpickle_method at 0x2c937d0>, ('apply', <reduce.applyDarkFlat.ApplyDarkFlat instance at 0x2f153b0>, <class reduce.applyDarkFlat.ApplyDarkFlat at 0x1b48600>))
"""

2012-06-20
==========  

- Encuentro la solución al problema de pickle/unpickle --> el problema estaba
en que la clase ApplyDarkFlat no derivaba de Object, y por eso no tenia los
atributos que necesitan los métodos de serialization.

2012-07-11
==========  

- Videoconf PANIC

*) Le mando a JF lo siguiente:

Dear Josef,

sorry for the delay, but I forgot it.

Please, take next inputs (QL & Pipeline) for the videoconf :

- Talk presenting the PANIC Quick-Look tool at SPIE2012
- Implemented procedure that mix dome & sky FF
- Continue with endless debugging
 

And the AIs to be done in QL & Pipeline before send PANIC to CAHA:

- Add support for distinguished files (non integrated)
- Implement health-check routines of the instrument (copy from JF's)
- Complete the debugging and tests of QL and Pipeline (might need additional developments)
- Review the initial photometric calibration
- Complete the Verification and Validation of pipeline results (in progress)
- Write QL and Pipeline User's Guide doc (initiated)
- Decide if the whole software must run in single computer or separate on control & processing computers (depend on memory problem found in GEIRS)    
- Choose & buy the computer/s to be used at Telescope
- Install the computer/s and write installation document
- Test QL & Pipeline at HD (2nd. Software Integration)


For the moment these are the AIs I can remember, but for sure not the ones.

*) Como resumen de la videoconf:

- JF se ve abrumado por las 3 slides de SW, así que prefiere resumirlo en : SW is going on.
Sin embargo, le preguntamos por GEIRS y las tareas pendientes:

   - todo parece indicar que CS implementara el control de las ruedas de filtros (Agost-Sep), 
   pero que el resto de cosas (sensors, fast readout, windowing, ...) lo hará si le sobra tiempo.
   - le preguntamos a JF si sabe algo del problema de memoria en GEIRS, y nos dice que no sabe nada,
   pero que le preguntará a CS. Tambien le pido que aproveche y le pregunte por una fecha tentativa
   para la 2da.Software Integration.
   JF en el mail de resumen de la videoconf, incluye:
   """ 
   Computer/memory:
     - status of memory problem is as before (i.e.reason unknown)
     - this problem has to be attacked again, wtih updated operating system etc
     - CS sees no problem to run PANIC including GEIRS on 1 computer
  """

  - Ulli informa que el problema de movimientos relativos en el 3.5 ha sido resulto, por
  lo que el OT podría usarlo.

  - Tambien se habla de la documentacion(deseable para finales de 2012), en principio en PDF+source. Jens sugiere además
  un trouble shooting document en la Web de forma que puedan hacer copy+paste para solucionar
  problemas del software.


2012-07-17
==========

- Matilde me dice que mejor postponemos las KDD hasta después de vacaciones (septiembre?)

2012-07-18
==========  

- Subida al OSN para enseñarlo a César y Regina


2012-07-19
==========  

- Tras varios días intentando compilar la libreria plplot-5.9.4 para que SCAMP pueda generar los gráficos png, lo consigo !!!:
  
  Los pasos son :
    
    1) Descargar el fuente de gd-libgd (con zypper no consigo encontrar dicha libreria) de https://bitbucket.org/pierrejoye/gd-libgd/overview
    
      >hg clone https://bitbucket.org/pierrejoye/gd-libgd
      
    2) Compilar dicha libraria (libgd):
       
       > cd gd-libgd
       > mkdir build
       > cd build 
       > cmake -DBUILD_TEST=1  -DENABLE_PNG=1 -DCMAKE_LIBRARY_PATH=/usr/loca/gdlib/lib -DCMAKE_INCLUDE_PATH=/usr/local/gdlib/include ../../gd-libgd/
       > make
       > make install
       
    3) Descargar la plplot-5.9.4 (pues parece que es la que recomiendan en el foro de SCAMP  http://www.astromatic.net/forum/showthread.php?tid=761)
       aunque puede que con la 5.9.9 también funcionase.
       
       http://sourceforge.net/projects/plplot/files/plplot/5.0.1/
       
    
    4) Compilar plplot-5.9.4
    
       > cd plplot-5.9.4
       > mkdir build
       > cd build 
       > cmake -DCMAKE_INSTALL_PREFIX=/usr/local/plplot594 -DBUILD_TEST=ON ../../plplot-5.9.4 >&cmake.out
       > ccmake ..
         y editar a mano 
 
          GDI32_LIBRARY /usr/local/lib/libgd.so
          ENABLE_python OFF (pues da un problema al no encontrar un .h de numpy ??)
          PLD_png ON
    
        básicamente eso.
        
     > make 
     > make install
     
     IMPORTANTE: copiar /usr/loca/gdlib/libgd.so en /usr/local/plplot594/lib/ pues si no se quejará el PLPLOT de que no la encuentra.
     
     > export PLPLOT_LIB=/usr/local/plplot594
     
     y listo !!! SCAMP debe generar los graficos PNG sin problema (glup!).
     
     
     FAQ:
       My program exits with the error message Unable to either (1) open/find or (2) allocate memory for the font file

       The PLplot library can't find the font files plstnd5.fnt and plxtnd5.fnt. Set the environment variable PLPLOT_LIB to the directory where these files are, e.g. export PLPLOT_LIB=/usr/local/plplot/data. 
     
     
    HA costado lo suyo !!! lo ideal sería que SCAMP (E.Bertin) migrara a la libraría cairo para generar los PNGs !!!
    
    Sin embargo, si le digo a SCAMP que genere ficheros JPEG no lo hace (Requested device jpeg not available), pregunta cada vez por el tipo de fichero....por qué ?
    PDF's si lo genera bien, incluso con mejor calidad que los PNG !!
    PS: en B/N y no completos
    Recompilo PLPLOT library con PLD_jpeg ON y ya si genera SCAMP los JPEG's, pero de una calidad pésima, inservibles !!!
    
    
    
    


2012-07-20
==========  
    

2012-07-24
==========  

- Pruebas con PyQt4 (en openSuSE11.4)
 
   * instalo SIP 4.13.3 (requerido por PyQt4.9.4)
   * compilo PyQt4.9.4
   *

- Pruebas con Pyside (en openSuSE11.4)

   * Sigo las instrucciones de http://qt-project.org/wiki/Building_PySide_on_Linux
   y todo OK !
   
- Modifico PQL (mainGUI) para que no tenga que hacer uso de la clase RunQtProcess
pues sólo se usaba en un caso (Subtract own-sky), y no merece la pena tener 
una clase para sólo eso. 
Lo que hago es que llamo directamente de forma sincrona (sin hebras ni nada) a
la clase sextractor.
No puedo usar hebras pues sex.run() no devuelve nada, y ExecTaskThread necesita
de el fichero generado para poder mostrarlo.
Todo esto para refactorizar código y simplificar !!
Muevo temporalmente runQtProcess.py al directorio deprecated.


2012-10-01
==========  
- Después de un parón de dos meses en PAPI por estar con TCS2, retomo a PAPI.
- Añado la escritura de los valores del diccionario del config_file que usa el
ReductionSet en el log_file de cara a poder luego depurar la reduccion realizada
por PAPI en cada ejecución.

- Encuentro un Bug(?) al lanzar PAPI en el portatil, pues da un error al crear
un master_dark de conjunto de Alhambra....en cambio en udit43 no ocurre ???


2012-10-02
==========  

- Test: aplico una distorsión (applyDistort.py) a una imagen reducida del
dataset de ALHAMBRA. Después, le paso astrowarp.py y compruebo que el plot
distort_1.png que genera SCAMP coincide con el que patrón de distorsión aplicado
(dist_mat_K.txt, que me pasó hace tiempo Conchi de PANIC).
Luego, buscando como interpretar mejor los plots que genera SCAMP (ver http://www.astro.uni-bonn.de/theli/gui/astromphotom.html)
extraigo que los pixels más grandes (rojo en plot) son los que deben coincidir
con el eje óptico del instrumento, y el resto serán más pequeños y por tanto
generan la distorsión; pensado un poco, eso tiene sentido....


- Aniado a reductionset.py 

 >>> pyraf.iraf.prcacheOff()

que me reportó VTerron tras consultar en los foros de PyRAF y creer que era un bug.
Aunque creo que ya no la necestio, pues no se que hice para evitar los problemas....

No obstante, la añado también con la intención de solucionar el problema siguiente
ya conocido desde hace tiempo:


Exception in thread Thread-1 (most likely raised during interpreter shutdown):
Traceback (most recent call last):
  File "/usr/lib64/python2.7/threading.py", line 530, in __bootstrap_inner
  File "/usr/lib64/python2.7/threading.py", line 483, in run
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 272, in _handle_workers
<type 'exceptions.TypeError'>: 'NoneType' object is not callable


pero SIGUE dando el problema a pesar de deshabilitar la Cache.
Leo en un foro que a alguien le pasa algo parecido, y le encuentro la siguiente
respuesta interesante: 

"""
From: http://stackoverflow.com/questions/4079810/python-thread-exception-errors-when-exit-the-whole-program

The problem is caused by the use of threading.Thread.setDaemon. Threads set 
daemonic don't prevent the Python intepreter from exiting, but they still keep 
running. Because Python cleans up the environment before the process is 
terminated, the threads can run into trouble when stuff is removed from under 
them. That raises an exception, which the thread class tries to print for your 
convenience -- but that, then, too fails because the process is exiting.

You could try to silence the exception, but that's tricky (and if the thread 
does anything substantial, it might hide a real problem. Not the case here, 
though.) Or you could ask the thread to stop before exiting, and not set the 
thread daemonic. Or you can simply avoid using threads altogether. I do not 
remember if wxPython has a convenient mechanism for getting a process's output 
or even of doing asynchronous I/O, but many GUI toolkits do. And there's always
Twisted, which does it all for you.
"""


2012-10-17
==========  
- En busca del error que hace que falle PyRAF+multiprocessing (sin clases ni nada)
en python 2.6 ( HD, portatil, udit43), y que sin embargo funciona perfectamente
en python 2.7:


#!/usr/bin/env python

import pyraf.iraf
from pyraf.iraf import noao, imred, ccdred, mscred
from pyraf.iraf import images,imutil

import time
import multiprocessing
import sys

pyraf.iraf.prcacheOff()

def run_iraf():
    print "Start run_iraf"

    pyraf.iraf.unlearn("imstat")
    #import pdb; pdb.set_trace()
    pyraf.iraf.imstat(images = "/tmp/dark.fits", fields="mean")

    print "End run_iraf"

    return "Success!"

if __name__ == '__main__':
    #run_iraf()
    #sys.exit(0)
    pool = multiprocessing.Pool(processes=2)      # start 4 worker processes
    result = pool.apply_async(run_iraf, args=())   
    result.wait()
    #result = multiprocessing.Pool(processes=4).apply_async(f, [10])
    print result.get(timeout=5) 
    
    sys.exit(0)


2012-10-18
==========  
- Continuo buscando el problema de PyRAF; escribo a help@stsci.edu preguntando
sobre el problema.
- Lo pruebo en el ordenador de VTerron (python 2.6.6, PyRAF 2.0) y funciona 
perfectamente. El me recomienda pasar a PyRAF 2.0
- Instalo PyRAF 2.0, en udit43, pero siguen los problemas.
- Instalo Python 2.7 en un directorio a parte, pero no puedo probarlo pues
no encuentra PyRAF, etc ....
- Instalo en el portatil (/usr/local/python273) Python 2.7.3 y todos los 
modulos de python que necesita PAPI. Lo documento en el PAPI_Install.txt. 
Ahora todo parece funcionar correctamente en el portatil con la nueva version 
de Python273.

- comienzo desarrollo de check_papi_modules.py para incluyir al inicio de papi.py



   
FOR NEXT VIDEOCONF
==================


KDD con MATILDE (15-May-2012)
=============================

 1) integration of cubes/individual files (add or mean)
   -->Si; sumatorio "simple" del cubo/ficheros sin mas.
   individual, quizás el OT me pueda ayudar, al menos para PAPI (ot?)
 2) integration of single-images (individual files) --> keyword FRAMENUM
   (ver arriba)
 3) how to proceed with windowed/binned images ? 
   --> MF preguntara a la gente de Barcelona sobre las ventanas 
   y como se podrian reducir (sky, astrometry, etc). (pendiente)
   --> JM Preguntara CS sobre el binning: CS responde que no, que en IR no hay binning 
 4) JF: must be possible to check the photometry of a specific star selected in the display. Imexam ?? how ? 
   --> MF le preguntara a JF que quiere exactamente; MF no ve muy interesante el ir viendo la Mag de cada
   estrella al marcarla en el display. Es mucho más útil la grafica de magnitud instrumental VS magnitud catalogo.
   --->JM mirara si con Aladin de puede hacer lo de leer un catalogo+imagen para consultar la magnitud, y tambien
   con imexam.
   --> JM : con > aladin /tmp/reduced_SEQ.fits /tmp/reduced_SEQ_zp.xml se puede hacer !! y haciendo click sobre una 
   objeto no muestra los valores de catalogo leido (/tmp/reduced_SEQ_zp.xml) y generado con SExtractor con el MAG_ZEROPOINT 
   calculado previamente con photometry.py
   --> JM : ademas, "Quick-look Photometry with Imexamine" 
   --> JM: Además, imexam te muestra con 'a' la magnitud (MAG), teniendo en cuenta el ZP que se puede modificar con (epar rimexam)
   
   #   COL    LINE     COORDINATES
   #     R    MAG    FLUX     SKY    PEAK    E   PA BETA ENCLOSED   MOFFAT DIRECT 
     2243.31 2888.93 2243.31 2888.93
     28.92  13.82  29750.   1.239   70.36 0.18  -77 1.14    13.63    15.59   9.68
   ( en este ejemplo ZP=25)
   
 5) how to reduce 'other' readout modes (rrr-mpia, lir, mer, srr, cntsr) or only work for lir (line-interlaced-read)
   MF preguntara a CS, pues no sabe a priori de que diferencias puede haber pero tiene "curiosidad" por ver que quería decir CS 
   (aunque JF dijo que no había diferencias)
 6) how to remove the stripe/quadrant background offsets in dxtalk.py --> MF no se le ocurre a priori como eliminarlo; 
 JM preguntara al Chino (WIRCAM); Otra opcion es ver si se puede restar solamente la estrella, lo estudiará JM.
 JM--> Wei-Hao me responde:
   """
   How about a simple background subtraction in each stripe after
   the subtraction of the median?  Maybe this will solve the problem.
   """
   Lo que dice Wei-hao (restar a cada stripe su propio cielo) podría funcionar, pero nuestra "triste" realidad (imagenes con gradiente en el background), 
   no puede funcionar.
   
KDD con MATILDE (29-May-2012)
=============================
 
 - repasamos los punto de la ultima KDD; MF no ha podido hacer sus "deberes", por lo que lo dejamos 
 para la proxima KDD.
 - JM comenta sus "deberes" y muestra el ejemplo : aladin /tmp/reduced_SEQ.fits /tmp/reduced_SEQ.xml
   que a MF le parece bien.
   NO obstante, MF no está muy conforme con la dispersión (STD=RMS=0.105950) que tenemos en el ejemplo que le muestro (o2k-120105).
   MF pensará sobre ello, y yo probaré con MAG_APER, qphot, a ver que diferencias hay.
   
 - comentamos la respuesta de Wei-Hao:
   How about a simple background subtraction in each stripe after
   the subtraction of the median?  Maybe this will solve the problem.
   """
   Lo que dice Wei-hao (restar a cada stripe su propio cielo) podría funcionar, pero nuestra "triste" realidad (imagenes con gradiente en el background), 
   no puede funcionar.
   
   Matilde sugiere restar al stripe-mediana el su propio background antes de restarlo a los N stripes de la imagen a
   corregir, de forma que "solo" restesmos los artefactos ->"estrellas de crosstalk".
   Quizas es background podría ser la "moda" de la imagen.
 
 - "significado" de MagInstrumental negativa ? 
   MF: bueno, no tiene importancia, pues el resultado es el mismo; lo que pasa es que normalmente hace
   el ajuste con una estimación inicial ZP=25 de forma que no salgan valores "negativos".
   
    mag_instrumental = zmag - 2.5 * log10(flujo/tiempo_integracion)

  - En cuanto al problema de identificar los grupos/secuencias cuando se graban en modo "individual",
  MF comenta que quizás con la información extra del OT se pueda hacer.
  JM lo pensará, pues quizás para el Pipe sirva, aunque no para el QL.
  
  - JM le comenta a MF que para la proxima sesion le dará un "tutoria" sobre como usar PAPI.
  
  - MF pensara sobre cual puede ser el origen de la dispersion "tan grande" en la estimacion de fot. absoluta.
JM probar con qphot con MAG_APER, etc ...


KDD con MATILDE (19-Jun-2012)
=============================
- Le enseño brevemente un poco del CL de PAPI, y la primera pregunta fué:
  
  ¿ cómo reducir toda una campaña ? - TODO !!! buscar en todos los subdirectorios 
  de un directorio, pero crear logfiles distintos ??? yo creo que sería mejor.

- Luego pasamos a ver las series de dark y le extraña el gran numero de pixeles 
  calientes !! ¿ cómo podría afectar a la reducción suya ?
  
  MF investigará sobre el tema. JM buscará como los trata PAPI.
  
- Le enseño el procedimineto para combinar domeFF y skyFF. Le parece interesante, 
pues ellos (VT y MF) están intentado algo parecido en LEMON. MF estudiará la 
utilización de esta mix de Flats.

- MF me pregunta cómo se tratan los BadPixels en la sky_subtraction ? TODO !!!

Respuesta JM:

Los pixeles malos(BP) se comportan de la siguiente manera:

  a) en la primera iteracion de sky_subtraction (sin mascara de objetos):
  
     - los pixeles malos de dejan con el valor del background medio (moda) de
     dicha imagen
  
  b) en la segunda iteracion de sky_subtraction (con máscara de objetos):
  
      - los pixeles malos o enmascarados por SExtractor como objeto, se les
      deja su propio valor, es decir, no se modifican.
     

- MF me pregunta si he cambiado algo en PAPI desde la reducción de sus datos en Febrero. Le digo
que tengo que mirarlo en los logs, pero que lo que puede que haya cambiado es el fichero de configuración !!!

- TODO: implementar en PAPI algo para hacer una copia del fichero de configuración usado en cada reducción,
quizás incluirlo en el logfile !!!




DOUBTS FOR MATILDE (next)
================================

- New module for mix dome & sky FF : calCombineFF()
- show MF PAPI CL interface:

> papi.py -s /data/O2K/2012-Matilde/20120103/ -g filter -p
> papi.py -s /data/O2K/2012-Matilde/20120103/ -S 15  -g filter 
> photometry.py -i /tmp/reduced_SEQ.fits -z 26.821570
> aladin /tmp/reduced_SEQ.fits /tmp/reduced_SEQ.xml
> papi.py -s /data/O2K/Matilde/120105/ -S 0  -g filter -R lemon
> cp /data/out/mDark_EXRfly.fits /data/calibs/mDark_serie.fits
> papi.py -s /data/O2K/Matilde/120105/ -S 4  -g filter -R lemon -D /data/calibs/mDark_serie.fits
> papi.py -s /data/O2K/Matilde/120105/ -S 28 -g filter -R lemon -D /data/calibs/mDark_serie.fits -F /data/calibs/mTwFlat_J.fits 



TODO's for Clemens
==================
  - Observo algo que parece una condición de carrera, y es que alguna vez puede ocurrir que aunque
  el chequeo del FITS sea correcto, GEIRS no haya aún añadido las keywords que le da el OT y entonces
  el QL no detecte bien el fichero pues no puede leer dichas keywords esenciales.
  Esto creo que no ocurre cuando usamos los modos 'file' el datacollector.
  

- comando para añadir cualquier keyword al header
- WCS correcto en los headers, actualmente tiene
TYPE1  = 'PIXEL'
CTYPE2  = 'PIXEL'
CRPIX1  =                  1.0
CRPIX2  =                  1.0
CRVAL1  =                  1.0
CRVAL2  =                  1.0
CDELT1  =                  1.0
CDELT2  =                  1.0

- bug en la salida del comando median cuando se envia desde el OT con snd_panic_new, que ahora sólo devuleve OK


FAQ:
===
1) ¿ para que se usa en PAPI los gainmap ? 
   - skyfilter
   - dithercubemean


NEXT TODOs
==========
- ver notas libreta sobre si se reduce o no HAWK-I-4
- ver notas libreta sobre si se reduce o no HAWK-I-5; 
en el portatil lo hace, pero el resultado no es muy bueno, 
incluso la astrometria no parece funcionar

- escribir al Chino sobre el dxtalk.py --> probar su sugerencia !!
- graficos SCAMP de distorsion !!!


DEPENDENCIAS DE IRDR
====================
- skyfilter
- dithercubemean
- offsets


DUDAS OT
========
- ¿ en un OB solo puede haber un calibration_series ?
- en la pantalla de Telescope-Iterator, por que el valor de Cycles=5 cuando creas un patron cualquiera ? 
(parace que es el valor que pone por defecto en Cycles en "Single Exposure")
Yo pondría por defecto 1 cycle
