PAPI DEVELOPER DIARY
====================

2011-10-24
----------


2011-10-25
----------
- Implemented in cube.c the next sky models:

     cube_median_min ( N )
     cube_mean_min ( N )
     cube_mean_min_w ( N )  weighted

 and modified the skyfilter.c routine in order to accept a new (optional)
 parameter 'skymodel' for the skyfiltering stage. The current accepted values
 for skymodel are:
     
     median : median/mean skymodel (normal or sparse fields)
     min : minimal sky model (for crowded fields)


- Al reducir la el DS de 13-Julio-2011-Matilde de O2k en el filtro Z
  (18:25:15+00:10:15) de 5 imágenes, observo que hay una reflejo que parece
  originado fuera del campo; le pregunto a Matilde, y buscando en 
http://archive.stsci.edu/cgi-bin/dss_form comprobamos que se debe a una
  estrella muy brillante que hay cerca del campo, y aunque no cae en el
  detector, lo que estamos viendo probablemente sean los arcos de difracción
  que genera la luz de la estrella en la óptica del telescopio/instrumento y
  que son vistos por el detector.
  
  Según Matilde, a priori, no sabe o no cree que eso se pueda eliminar
  facilmente, así que no habrá que preocuparse de momento por eso. 

  De todas formas, yo creo que con los skyflats(superflats) debería de haberse
  eliminado, no ?? pues están observando la misma zona del cielo...pero noooo,
  pues están cayendo sobre distintos píxeles, por lo que no hay nada que
  hacer, no ?? de todas formas tendría que ver si con alguna técnica de
  fringing removal se podría hacer algo ....

- Modificado genLogsheet para que pueda mostrar un subconjuto de filas y que
  además se pueda omitir la cabecera; todo esto con el objetivo de poder crear
  ficheros que puedan leer datasimy.py y createSeq.py



2011-10-26
----------

- Me suscribo a 3 listas de python, una de ellas en español ! para intentar
  estar un poco más actualizado del mundo Python. 

- Me pongo a buscar el bug que encontré al ejecutar el Test#23;
  Encotrado BUG sintáctico, estaba en ClFits.isScience()
 
- Me encuentro con otro/s bug/s a la hora de agrupar los datos:

     1) los master creados tienen un PAT_NEXP != N, y PAT_EXPN=1, con lo cual
     son confundidos/mezclados con los datos agrupados, provocando además que
     se queden fuera algunos ficheros que tendrían que ser agrupados.
     Para solucionar esto hago lo siguiente:

     	  - modifico las rutinas de creación de master para que actualicen el
                 valor de PAT_NEXP=1
	  - modifico en dataset.GetSeqFilesB() para que no tenga en cuenta a
                 la hora de agrupar los ficheros de tipo MASTER_XXXXX
		      

     2) En las rutinas de creación de masters, no se actualiza la keyword
     IMAGETYP, con lo cual PAPITYPE dice una cosa y IMAGETYP dice otro. Aunque
     PAPITYPE tiene prioridad, lo arreglo para que ambas digan lo mismo,
     aunque lo correcto sería eliminar IMAGETYP....

  
- Me surge la duda siguiente: ¿ qué debe tener más prioridad, un master dado
  de forma externa o uno creado por el propio pipeline como resultado de la
  reducción de la secuencia correspondiente ?
  Yo creo que debería tener prioridad el que reciba de forma externa ...pero
  tampoco lo tengo muy claro. Ahora el problema está en como implementar esa
  prioridad ....
  Se me ocurre, que vamos a tomar aquel que sea más reciente, mirando para
  ello la MJD --> usando el índice -1 de Python es sencillo.
  Para ello modifico RS.getCalibFor() de forma que devuelva el último elemento
  de la lista de master encontrados, que se supone será el más reciente.

- Modificación en el QL para que si no se ha activado la checkBox del outDir,
  se añadan las salidas generadas durante el procesamiento de los distintos
  datasets, básicamente para posibilitar que un science-DS pueda usar los
  master de calibración que hayan podido encontrarse y creado anteriormente.
  Para ello se modificó : MainGUI::checkLastTask()

- 
 
- Realizo los test #23-#30; destaco el test 30 que incluye a datos según el
  formato de GEIRS, que tienen que ser "convertidos" a 4 x (simple FITS) que
  puedan luego ser procesados por PAPI. Parece que de momento la cosa va bien,
  aunque aún queda por comprobar con datos reales si la astrometría de las
  nuevas imágenes creadas al partir el fichero original de GEIRS es correcta o
  no....

2011-10-27
----------


- Ejecutando el test #31, que fue bien, me doy cuenta de que por ejemplo, si
  para reducir una secuencia necesita alguna calibración con MJD posterior, la
  ordenación y ejecución de la reducción de secuencias no funcionaria, pues no
  la habría reducido todavía cuando es necesitada por una secuencia en
  cuestión. Es decir, sin en el test #31, los darks son posteriores a los
  twflats, da un ERROR diciendo que no encuentra el master dark necesario y
  que por tanto no puede crear el master TWFlat.

  Una posible solución que se me ocurre: que la ordenación de secuencias a
  procesar siga el criterio siguiente:

  	   	1- ordenar por MJD
		2- ordenar por DARK, DOME_FLATS, TW_FLATS, SCIENCE

  Para implementar esta solución añadi la funcion RS:reorder_sequences(), que
  hace justamente eso. La probé con el test #32 y funcionó correctamente. No
  obstante, llamo a esta función de reordenación a la hora de la reducción del
  RS, pero no cuando se muestra en la consola las Seqs encuentradas, más que
  nada para poder verlas ordenadas temporalmente.

  Obviamente, esto no es válido para el QL, pues en el QL se reducen las
  imágenes según van llegando...aunque pensandolo bien, también se podría usar
  cuando el usuario selecciona manualmente una sequencia de SCI y quiere que
  esté disponibles las calibraciones posteriores. Pero pensandolo mejor, es
  preferible que el usuario tenga que marcar/seleccionar todos aquellos
  ficheros que quiera tener en cuenta para la reducción o bien, indique
  explicitamente qué masterDark,masterFlat quiere usar.

- A raiz del tema de la ordenación de las sequencias y los problemas que puede
  dar en el QL si para reducir un SkyFlat no se han reducido aún los dark
  correspondientes, hago una modificación en QL para que avise también cuando
  no pueda reducir una secuencia, pues hasta ahora sólo avisava por la
  consola; ahora también muestra el mensaje en el Log de la GUI.
  Esto se puede probar con el test #32.


 
2011-11-02
----------

- Instalación de MV con openSuSE-11.1-64bit. Me dió bastantes problemas,
  entre:
	* primero de todo, al intentar instalar un SO guest de 64 bit,
  VirtualBox me avisa que tengo que habilitar en el BIOS del host principal el
  modo VT-x/AMD-v; no lo encontré en mi bios (DELL 390), pero había algo de
  virtualización y lo activé. A partir de ahí, VB me dejó instalar el SO 64bit.
	* me avisa de que el display del host es de 32 bit, pero que el guest
  está configurado con 16 bit--> eso no pasa nada, simplemente que para
  mejorar las prestaciones gráficas hay que instalar las GuestAdditions.
  	* Se me quedaba colgado al inicio de la instalación, y no sabía de qué
  podia ser; en un principio pensaba que era debido al mensaje de los 32/16
  bits del display, así que probé en modo texto (y seguia dicho mensaje), y
  fué cuando me di cuenta de que daba un error por el famoso ACPI. Para
  intentar solucionar esto desactivé en la definición de la máquina virtual la
  opción de ACPI. Con esto, ya me dejó instalar sin problemas.
  	* bueno, también se me quedó un par de veces colgada la instalación
por que no podía leer el DVD (incluso tampoco lo podia leer elwindowsXP), 
así que limpié varias veces el DVD hasta que volvió a leerlo sin problemas 
y pude instalar el openSuSE11.164bit.


 
- Implementación de apply_dark_flat=2
- Encontrado problema al ejecutar calTwFlat.py

2011-11-03
----------

- Encontrado y solucionado bug en calTwFlat.py --> el problema estaba en el
  parámetro input del mscred.flatcombine() que no estaba bien formado por el
  tema de la barra doble "//" que no acepta IRAF en los pathnames.

- Tras implementar el modo apply_dark_flat=2, hice las pruebas
  correspondientes y me dí cuenta de que tenía un error a la hora de crear el
  fichero stack1.pap en la llamada a coaddStackImages(). Tras solucinar dicho
  bug, todo parecía ir bien, aunque el test con datos de ALHAMBRA demostró que
  el FF después del skysubtraction (apply_dark_flat=2) es "como" (o sin el
  como) deshacer el skysubtraction, cosa que ya había comprobado en día
  anteriores y que coincide con lo que me decía Wei-Hao (SIMPLE).
  Por eso, realmente no le veo sentido a implementar dicho modo
  (apply_dark_flat=2), pero bueno, por si acaso...ya está implementado.

- Repito el test anterior (#32) con red_mode='science'


2011-11-04
==========

- Termino de instalar todo el software de PAPI en la Maquina Virtual (MV) de
  openSuSE que he creado eleborar el documento de instalación. 
  Al instalar la VBoxAdditions, me da un aviso de que parace que ya están
  instaladas en el SO guest, y que es mejor que no las re-instale, pero como
  tengo algunos problemas con el ratón y no tengo el FS para el mount.vboxfs
  para poder compartir carpetas con entre el host y el guest, pues no hago
  caso al aviso y dedido instalarlas. Después de un rato, re-compilando
  algunos módulos para el kernel y tal, pues todo parece terminar bien y
  funcionar correctamente. Veremos ....:-D

- Consigo finalmente instalar el binario (64bit) de SCAMPv1.7 y su dichosa
  dependencia de la libraria libplplot9; finalmente encuentro el RPM
  libplplot9-5.7.1-1.2.x86_64.rpm que se instala sin problemas.

2011-11-07
==========

- Videoconf PANIC: en cuanto al SW, aunque AGS dice que no está preparado y
  que prefiere postponer el viaje, JF insiste y dice que no se puede mover,
  así que finalmente iremos en el semana 47 como estaba previsto.
    

- Muevo el RS::reorder_sequences() al método  RS::getSequences  
  y ahora reoder_sequences() sólo se ejecuta si queremos reducir todo el DS,
  pero si hemos especificado una secuencia específica, no se reordenan pues no
  hace falta; con esto nos evitamos el problema de la altereación del número
  de secuencia mostrado según el ordernamiento MJD y el que le correspondería
  según el ordenamiento DARK, FLAT, SCIENCE, etc que hacer reorder_sequences.
  
  Es decir, NO hay problema de identificación del número de secuencia al
  especificar una secuencia a reducir en lugar de todo el DS.



2011-11-09
==========
- Defino algunos test para empezar las pruebas con AGS

- Asisto reunión convocada por Julio sobre HEXA

- Repito el test 18 con el Set HAWK-I-5, y obtengo un stitch final muy mal;
  miro los cuandrantes individiales Q0N y ninguno tiene la astrometría bien.
  Depurando, me doy cuenta de que SCAMP se queja (linea roja), y por eso no
  hace bien la astrometría con GSC-2.3.
  Cambio a 2MASS, y ahora la astrometría es buena !!! por qué ?? será que
  habré cambiado algún parámetro (NSIG en skyfilter, DETECT_THRESH, ...) ?
  La imagen final de los cuatro cuadrantes (stiched) está más o menos bien,
  con poca marca de la noise-cross-shape central.

- Inicio de pruebas integración OT-QL:


  
2011-11-10
==========

- Continuo pruebas de QL y depurando.
- Implemento eval_focus_serie.py, que basandose en checkQuality.py, calcula el
  mejor foco de una serie de foco. Lo pruebo con el ejemplo  de O2k que me
  pasó Ulli y funciona bien !!! Para el caso de PANIC, debería funcionar
  también sobre las imágnes 4kx4k, a pesar de la cruceta, pues SExtractor es
  robusto a eso...lo mejor sería simularlo y probarlo. 

- Por la tarde, hacemos algunas pruebas AGS y yo con el OT y el QL (ver
  documento manuscrito). Encontramos varios BUGS tanto en OT como QL.
  
  En OT: básicamente que no enumera bien las secuencias con el instrument
  iterator
  En QL: que no avisa de que un conjunto de ficheros no tiene ninguna
  secuencia, dando una exception "TypeError". (lo solucioné al día siguiente).

 


2011-11-11
==========

- Encuetro el bug del día anterior.
- Encuentro otro bug en eval_focus_serie, pues en los nuevos ficheros de PANIC
  el kw de foco telescopio se llama T_FOCUS en lugar de T-FOCUS. Modifico
  convenientemente la rutina.

- Comienzo diseño de DEMO PAPI/QL (papi_demo.txt)

- Tarde: AGS y yo continuamos con las pruebas de OT-QL:

  Basicamente hicimos un recorrido por el documento "WhatWeNeed.doc" de JF, y
  los principales fallos/problemas encontrados fueron:

      1) domeflats no tiene el orden on/off correcto, pues mezcla con los
      filtros. Lo correcto para una secuencia de 1-N sería
      on-on-on-off-off-off y seguir con el siguiente filtro.

      2) skyflats : no los podemos probar, pues no los tiene completamente
      implementados, pues el OT no tiene simulado el incremento artificial del
      número de cuentas.

      3) focur series: no implementado en OT, pero le doy el .prg y la idea de
      cómo hay que hacerlo. Intentará implementarlo para HD.

      4) simple exposure: no funciona ese caso particular

      5) nodding pattern: no implementado, pero le paso el sky_pointing.prg y
      cómo lo podría implementar. No cree que pueda tenerlo para HD.

      6) Pause: no está en OT, pero cree que lo podrá implementar, no es muy
      dificil.

  En cuanto al QL, no encontré errores, sólo lo siguientes comentarios:

      1) ver que nodding pattern puede contemplar PAPI ( y el OT) según las
      sugerencias de Ulli.

      2) ver que hace el QL/PAPI cuando encuentra dos PAT_EXPN=1 en una
      secuencia ????


2011-11-14
==========

- Pruebas O2k objetos extenso, secuencia T-S-T-T-S-T-T-....(NGC5866). 
  Encuentro&Soluciono BUG en skyfilter_general, en la funcion que lee el IMAGETYP, pues
  no contenplaba bien los NULL.

- Reduciendo la serie anterior, SExtractor da el mensaje :


WARNING: Pixel stack overflow at position 


que según E.Bertin es debido a :

"""
Hi.
Given the fairly large size of your image, different memory settings (and/or aperture settings) can lead to a different number of sources. This may seem like a bug but it isn't (in principle!). The reason is that the SExtractor engine was originally written at a time when computer memory was scarse (a good workstation had ~16MB of memory back then, and SExtractor was meant to work with 1.8 GB Schmidt plate scans). Hence memory usage had to be kept under strict control, which explains the buffer limit settings. These limits may be reached if your image is populated with many and/or very large objects and/or if some measurements require large apertures. In that case, SExtractor has to make choices: change the order in which objects are extracted and/or measured, change details about the cleaning of spurious sources around bright sources, and, for the most critical cases, give up on extracting and/or deblending and/or measuring objects. Obviously, decisions of statistical significance are accompanied by a 
proper flagging of the detections involved (see the SExtractor documentation). Most of the time, this will concern bright, saturated stars or large image artifacts (halos, bad columns, satellite trails, etc.). It may however affect "normal" sources if inappropriate detection parameters are used: exceedingly low detection thresholds and/or unsuitable background mapping parameters (the detection algorithm has to percolate through the background noise and deblend large "empty" areas), exceedly high deblending contrast in very crowded fields...
In suspicious cases, I would recommend checking SEGMENTATION check-images and
source FLAGS to verify that SExtractor is operating in the intended regime.

"""

Ese mismo warning ya lo he visto en otras ocasiones, pero nunca le he hecho
caso. Habría que ver como afecta a la reducción....



- DUDA en eval_focus_serie.py habría que ordenar los frames por MJD
  antes de evaluarlos ???
  Realmente el orden va a dar igual, pues para el ajuste no afecta para nada.

- DUDA a resolver : en eval_focus_serie.py habría que hacerles algún tipo de
  procesamiento (Dark, Flat, Sky....) antes de evaluar el FWHM ?
  Pues en teoria se obtendrían mejores resultados...habría que hacer algunas
  pruebas.

- BUG resuelto: faltaba en db.getFilterFiles() en el primer select un "order
  by MJD"

- Pruebas OT-QL:

  * domeflat : sigue el problema de la numeración de secuencias
  * single exposure + telescope interator : no contemplado
  * single exposute + cycles = 2 : no enumera bien las secuencias
  * skyflats : no terminados de implementar
  

2011-11-15
==========

- Añadido nuevo tipo de agrupamiento --> "none" , que hace que no se agrupe y
  que simplemente considere todos los ficheros como pertenecientes a un mismo
  grupo.

- Añadida al config file skysub.skymodel y modificada la función
  RS::skyfilter() para que admita dicho parámetro.
  
- Hago el primer esquema del proceso de reducción de PAPI; queda pasarlo a
  limpio.

2011-11-16
==========

- Bug resuelto en QL: había un bug en la creación del QTimer cuando se
  especifica un directorio a "monitorizar" que afectaba a mainGUI.py

2011-11-20 al 25
================

- Pruebas SW de integración en HD. (ver documentos de notas)
 
2011-11-29
==========
- Inicio funcion read_GEIRS_fitsLog() para mejorar la lectura de los ficheros de
log de GEIRS, tanto

    * ~/GEIRS/log/save_CA2.2m.log
    * ~/tmp/fitsfiles.corrected
    
2011-12-12
==========

- Teleconf PANIC: JF me comenta que no tiene inconveniente en enviarme la carta
de consentimiento para la ayuda de movilidad, pero me pregunta que fechas tendría
previsto para ir. Yo lo contesto que en principio Verano, pero que aún o se cuando
estaría el dinero y tal. JF piensa que es muy tarde, pues el piensa en poder 
hacer algo para GEIRS.
Y sobre el SW, pues que el OT le parece demasiado complicado, y que quizás sería
mejor hablar con CA (Ana Guijarro). 
También comenta que van a contratar una persona para que ayude a CS con el SW.

- Recibo llamada de Jens para hablarme del nuevo CCD-SW para Twin. Por lo visto
el software de bajo nivel lo harían en HD, a modo de librería similar a la que 
hicieron para CAFOS-upgrade, y la GUI sería para hacerla nosotros, más la GUI
de control del instrumento Twin, para sincronizar las dos CCDs etc ...
Le digo a Jens que tenemos que consularlo con Matilde & Julio.


- Modifico QL para que se pueda seleccionar desde el botón Input/Source dir tanto
un directorio como los ficheros de log de GEIRS (save_CA2.2mlog y fitsfiles.corrected).
Tengo que probar bien si funcionar en cualquier versión de SuSE, pues me pareció 
que en el portatil no funcionaba bien.


2011-12-13
==========

- Pruebo el qphot de forma interactiva para ir seleccionando y visualizando los
valores fotometrícos de los objetos en la imagen reducida y aunque al principio
me costó entender el manejo, luego es muy potente y útil. Además, si tenemos 
activado el radplot=yes, es muy interesante. Podemos decirle además el ZPOINT
que queremos que use para el cálculo de la fotometría.


2011-12-14
==========

- Implemento rutina 'plot_cpu_mem_stats.py' para sacar las gráficas de CPU y 
memoria de los test hechos en Heidelberg.

- Instalo sphinx + pygments (con easy_install) para empezar a documentar PAPI

- Comienzo con primeras pruebas.


2011-12-15
==========

- Continuo probando Sphinx, pues parece muy interesante para usar en la documentación
de PAPI. Sin embargo, de cara a documentar el codigo fuente (python) de PAPI
me encuentro con el problema de que hasta ahora el codigo fuente de PAPI lo 
estaba documentando en las docstring siguiendo la sintaxis de epytext/javadoc, 
pero resulta que Sphinx usa las docstring del formato reST(reStructuredText);
según he buscado en google, no parece que haya una forma fácil para pasar de
epytext a reST.

La sintaxis de reST para las docstring de python es la siguiente:
 
 -http://epydoc.sourceforge.net/manual-fields.html#epydoc-fields

 -http://mundogeek.net/archivos/2008/07/07/documentacion-en-python/#more-1582


También me doy cuenta de que en las docstrings del codigo python no podemos usar
todos los metatags de reST, pues al importar los modulos en sphinx se queja;sin
embargo, veo que la documentación de Numpy si los usa, pero para ello hay que 
instalar una extensión a sphinx propia de Numpy para que se genera la documentación
como en Numpy ( ver  https://github.com/numpy/numpy/tree/master/doc/sphinxext)

2012-01-09
==========
- Incorporación después de vacaciones !
- Matilde me dice que han estado observando con O2k para su proyecto. Quedamos
en que me bajaré los datos y iré mirando como reducirlos, al menos hasta la
sustracción de cielo, pues a partir de ahí continuará LEMON.


2012-01-10
==========
- Comienzo la implementación para que PAPI se detenga en después de la sustracción
de cielo y devuelta la lista de ficheros pre-reducidos para pasarle a LEMON.

- En las primeras pruebas de la reducción de datos de Matilde, me doy con 
problemas como:

    1) Hay un objeto extenso (nebulosa) y no han observado en modo "T-S-T-S-...",
    por lo que PAPI no puede reducir bien las imágenes por la nebulosa.
    1) las secuencias de Ks tiene dos iteraciones sobre un patrón de dithering
    de 5 posiciones, con lo cual el algorimo estimación de cielo no funciona 
    bien y hace sobrecorrección.
    2) los parametros del calculo del gainmap son muy severos (0.7,13), por lo
    que los relajo a (0.5, 1.5)
    
- Hablo con Matilde de estos primeros problemas y me dice que no me preocupe, 
que primero ella estudiará cual es le mejor método para la sustracción de cielo.

2012-02-22
==========
- Modificación en applyDarkFlat, calTwFlat y ReductionSet para usar 
MASTER_DARK_MODEL de forma que se pueda escalar correctamente, pues como se hacia
antes con un MASTER_DARK normal, no estaba bien, pues se estaba escalando también
el BIAS intrinseco de los DARK.

- Modifico también la rutina calDarkModel para que se grabe en el header alguna
información mas sobre el DARK_MODEL.

2012-02-24
==========

- Implementacion metodo dxtalk.py (O2k y PANIC)

2012-02-25
==========

- Lanzamiento de PAPI (modo lemon) con todos los datos de Matilde de 
O2k (Enero-Febrero 2012)

2012-02-27
==========
- Revision resultados reducción de PAPI
- Implementacion de nueva opcion en PAPI para que permita usar ficheros de
calibracion maestros (master dark, flat ...) de un repositorio (directorio)
externo, de forma que si al reducir un DS no dispone de los correspondiente masters,
pueda usar los que haya en dicho repositorio.


2012-02-28
==========
- Dudas sobre los valores obtenidos en el dark model. Pregunto a Clemens, Vianak 
y Rene Fassbinder sobre el tema para ver si me sacan de la duda.


2012-03-02
==========
- Rene Fassbinder me responde aclarandome finalmente donde estaba mi error con 
la estimación de dark model medio---> El valor de MEAN no es significativo !!!!
Está "contaminado" por los hot-pixels !!! 
De todas formas, el método de dark-model y la sustracción de dark correspondiente
hecha en las imágenes de Matilde creo que están bien !


2012-03-05
==========
- Estudio para ver como mejorar el dxtalk.py de forma que tenga en cuenta los 
outliers y estrellas brillantes al calcular la mediana.
Encuentro interesante el método : Standard Deviation Mask que trae Maxim/DL.

- Encontrado en http://www.astro.yale.edu/dokkum/lacosmic/ código Python para 
eliminar Cosmic-Rays (CR) de imágenes basado en http://arxiv.org/abs/astro-ph/0108003 
Lo pruebo con imágenes de O2k y parece que va bien, aunque tarda 2'20''.
Los CR en principio se "resuelven" en el IR al hacer el combine del stack, pero
en el modo Lemon quizás sea interesante tenerlo ????

2012-03-06
==========
- Continuo con el estudio y pruebas de rutina alternativa para iraf.imcombine,
pero sin éxito.

- Escribo en las listas de AstroPy y NumPy para pregunar acerca del tema.
Objengo respuestas, diciendo que el paquete stsci contempla dicha rutina, pero 
hay que instalar PyRAF !!!! entonces estamos en la misma. No obstante podría
ser un punto de partida para mi implementación.

  
2012-03-08
==========
- Modificación en PAPI para que detecte secuencia de Dark para DarkModel o 
Master dark tradicional. Esto implicó modificar un poco la funcion RS.checkData().

2012-03-09
==========
- Implementada nueva funcionalidad a QL para restar los 2 últimos SCI-frames
recibidos, mejor dicho, los 2 más nuevos (MJD) --> pushB_subtract_last2_slot()

- Añado opción remove_cosmic_ray al fichero de configuración 

2012-03-10
==========


2012-03-14
==========

- Videoconf: le envio las siguientes notas:

"""
-PAPI+LEMON reduced ~7000 O2k images (Z,J,H,Ks) of Matilde's project 
-PAPI : dark, flat, sky-subtraction and de-crosstalk (also ready for PANIC) - 
- LEMON: time series analysis - Photometric precision up to 0.015mag (constant star) 
  Attached figure: preliminary V and Ks band lightcurves of one star of the sample for which there is an shift between a visible and a near-infrared minimun. 
- Added to PANIC a module for cosmic rays removal (based on P. van Dokkum's L.A.Cosmic algorithm, http://www.astro.yale.edu/dokkum/lacosmic/) 
- Improvement in master dark model computation 

About the OT, no news; Antonio is in vacation. 
"""

Sale nuevamente el tema de los problemas de memoria en GEIRS, en los que está
aún trabajando CS, y que cree que son problemas en el kernel, pero que espera
poder resolverlos pronto.

2012-03-27
==========

 - Modificación en calDomeFlat, calTwFlat, calSuperFlat para solucionar/mejorar
 la normalization wrt chip 1, además de mejoras varias y documentacion en codigo
 - Encuentro el metodo (trick) para usar dome+sky flat de forma que aprovechemos
 las propiedades de ambos:
 
"""
A trick to combine domeFF and skyFF :

Often for a run you have dome flats with an accumulated number of
electrons in the millions, but a poor match in illumination and color to the dark
sky. You also have a limited number of twilight flats or dark-sky images that can
be combined to make a dark-sky flat, but the total counts per pixel in either set of
flats is not very high. A fairly standard procedure is to “median-smooth” dome
and twilight or dark-sky flat. A median smoothing replaces each pixel with the
median of the pixel values in a box of a given size on a side. The result is an image
that has been smoothed on the scale of the smoothing box size.
A procedure for taking advantage of the facts that the large-scale flat-field
variation of the dark-sky flat match that of the program frames and the dome flats
have very high S/N in each pixel goes as follows:
 
 (a) Median smooth the combined, dark-sky flat — this improves the S/N and
preserves the large-scale features of the flat.
 (b) Median smooth the combined dome flats using the same filter size as was
used for the dark-sky flat.
 (c) Divide the combined dome flat by it’s median smoothed-version. The result is
a frame that is flat on large scales but contains all the high spatial frequency
flat-field information.
 (d) Now multiply the smoothed dark-sky frame and the result of the division in
the previous step. You now have a flat-field with the low spatial frequency
properties of the dark-sky flat combined with the high S/N, high spatial
frequency properties of the dome flat.
"""

2012-03-28
==========
 - Modificación en calGainMap para hacer (opcionalmente) la normalization wrt 
 chip 1 para el caso de imágenes full-frame de PANIC (como las saca GEIRS).
 Aunque en principio la normalizacion ( si hay varios detectores, wrt chip1), 
 puede ser realizada al crear los master-flat, tambien está la opción de hacerla
 en calGainMap.
 Si por "error" se hicese en los dos casos (master flat y gainmap), no creo que 
 pasase nada. 
 
 - Una vez más me surge la duda de si aplicar el FF y luego usar el GM (gainmap)
 puede ser redundante y/o contraproducente. Después de ver donde se usa el GM
 en PAPI:
    1) skyfilter :
        1.a) como BPM
        1.b) crear el wmap (NCOMBINE*INT_TIME*gainmap*ImageVariance) 
        cuando usamos cube_mean() con mascara de objetos
        1.c) procedimiento IRDR::destripe() que no usamos de momento en PAPI
    2) dithercubemean:
        2.a) de nuevo, al crear el wmap, y en cube_mean()
 
 llego a la conclusión de que el gainmap es "cte" para todas la imagenes de un
 stack de dithering, y por tanto no debe ser determinante.
 Además, revisando la documentacion "IRDR Users Guide" veo que hacen igual,
 aplican FF, generan GM con el FF y luego usan el GM en skyfilter y dithercubemean.
 Por tanto, de momento podemos dejarlo así.
 
 - Encuentro un BUG(?) en mean.c, pues MINCLIP estaba a 1.5 en lugar de 5, que
 es el valor original. Debe ser que alguna de mis pruebas con el NSIG del
 cube.c, me confundí y modifiqué erroneamente el MINCLIP. 

 

2012-03-29
==========

 - Añadida option de 'median_smooth' a los FF (dome,tw,sky)
 - Implementado modulo para combinar domeFF y skyFF --> calCombineFF.py
 

2012-03-30
==========

  - Pruebas de los procedimientos modificados el día anterior, procurando que 
pase por todos los casos posibles.

  - Estudio de los modos de autenticacion de subversion 

2012-05-09
==========
   - Videoconf: no pude asistir por subir al OSN a instalar la CCD Excelon 
   en Albireo.
   Parace ser que lo unico destacable respecto al SW fue que JF pregunto para
   cuando la segunda integracion del SW.
   

2012-05-10
==========

   - Comienzo migracion de pprocess a multithreading (python >2.7)
   - Encuentro un problema pues lo metodos de clases no los soporta
   directamente Pool.apply_async(), hay que hacerlos "picklable".

2012-05-11
==========
   - Encuentro una solucion para el problema anterior:
   http://stackoverflow.com/questions/3288595/multiprocessing-using-pool-map-on-a-function-defined-in-a-class
   
   y parece que funciona. 
   
   
2012-05-12
==========
   - Lanzo PAPI con mutiprocessing.Pool y parece que funciona bien (data set
   de HAWK-I-3).
   
   - Ahora detecto un problema "aleatorio" (no ocurre siempre) en el multiprocessing:
   
   Exception in thread Thread-1 (most likely raised during interpreter shutdown):
Traceback (most recent call last):
  File "/gel/usr/mawal32/system/lib/python2.7/threading.py", line 530, in __bootstrap_inner
  File "/gel/usr/mawal32/system/lib/python2.7/threading.py", line 483, in run
  File "/gel/usr/mawal32/system/lib/python2.7/multiprocessing/pool.py", line 272, in _handle_workers
<type 'exceptions.TypeError'>: 'NoneType' object is not callable
   
y parece que esta reportado el bug, pero no consigo solucionarlo de momento:
   
   http://bugs.python.org/issue9207.

2012-05-14
==========
   - Añado al multiprocessing las llamadas:
   
        pool.close()
        pool.join() 
        
     para intentar solucionar el problema aparecido el dia anterior.
   - Lanzo PAPI varias veces y parece que funciona bien (data set HAWK-I-3).
   - En una de las veces que ejecute PAPI el 15-Mayo si fallo otra vez dando el
   mensaje de arriba (12-May), por lo que parece que con el close()+join()
   no se soluciona.
  
2012-05-15
==========
   - Pruebas en reduceSingleObj() con AstroWarp en el modo "quick":
     
       - con HAWK-I-3, y DETECT_THRESH=4, no es capaz de hacer astrometría ni crear el mosaico;
       con DETECT_THRESH=1.5, hace astrometría mal, y por tanto el mosaico final tambien está
       desformado.
       - con O2k-Matilde-2012-20120105-S-5, si lo hace bien (DETECT_THRESH=1.5)
       
   - Una prueba con O2k-Matilde-2012-20120105-S-6 falló, pues el gainmap era todo BPM !!!! ---> BUG ????
       
   - Reunion con MF para dudas de PAPI (ver comentarios abajo, sección DOUBTS FOR MATILDE)

2012-05-16
==========
    - Compruebo que haciendo :
      
      > aladin /tmp/reduced_SEQ.fits /tmp/reduced_SEQ_zp.xml 
      
      y haciendo click sobre una objeto no muestra los valores de catalogo leido 
      (/tmp/reduced_SEQ_zp.xml) y generado con SExtractor con el MAG_ZEROPOINT 
      calculado previamente con photometry.py
  
    - Le pregunto a VTerron si el ha tenido problemas con multiprocessing, parece
    que no ha tenido problemas; el usa Pool.map_asycn(), asi que voy yo a probar 
    con esa llamada para ver si así se soluciona.
    

2012-05-17y18
=============
    - Implementacion y pruebas del metodo collapse() para sumar cubos; aun pendiente
    la suma de ficheros independientes, pues aunque el suma de ficheros independientes
    esta implementada de momento, aun no se como "agrupar" los ficheros. Le pregunto
    a Clemens si podria usar el FRAMENUM y si me podria añadir algo para saber cuantos
    ficheros tiene una exposición (repeats). Me responde que en la nueva logica de los 
    FITS que tambien necesita Lucifer, y que para septiembre:

"""    
Will come with the new FITS-header-organisation at least until September
(needed also for Lucifer). Please just assume a dummy-keyword name, which you
might replace with  the correct on.
"""
    
    
2012-05-21
==========    
    - Me encuentro un problema a ejecutar PAPI en el portatil (suse11.1-64);
    el problema surge al importar el paquete cosmics, que a su vez importa un
    modulo de scipy que da problemas.
    Para intentar solucinarlo, actualizo numpy1.6.2, scipy0.10.1
    Pruebo la demo de cosmics y ahora ya no da problemas !!!  

   - Otro problema es que en el portatil tengo python2.5, y no tiene el paquete multiprocessing
    por defecto a partir de python2.6, por lo que me bajo el paquete independiente de 
    backport de multiprocessing para python 2.5. Se instala sin problemas y las pruebas de unidad
    se ejecutan sin problema.

2012-05-22
==========    
    - Escribo a Wei-Hao para preguntarle sobre el dxtalk_wircam
     Wei-Hao me responde:
      """
      How about a simple background subtraction in each stripe after
      the subtraction of the median?  Maybe this will solve the problem.
      """
    - Busco en THELI sobre el dxtalk, y aunque aparece en la documentacion no encuentro el código

2012-05-24
==========    
    - Haciendo pruebas con PAPI, me encuentro con el un error aleatorio, pues no siempre ocurre (50%), 
    y tanto con pprocess como con multiprocessing. El error se produce en la llamada iraf.mscred.mscarith(...)
    en calSuperFlat.py. Compruebo que los parametros de llamada de la función están bien; no se por qué puede ser ???
    Este error se produce tanto en openSuSE11.1-i586 (python2.6) como con suse11.4-x64 (python2.7)  

    [PAPI]: 2012-05-24 17:13:00,575 DEBUG    calSuperFlat:222: Normalization of master (O2k?) flat frame. (MODE=2857)
    [PAPI]: 2012-05-24 17:13:00,576 DEBUG    calSuperFlat:226: Normalization parametes---> (tmp1=/data/out/Q02/tmp_sf.fits,result=/data/out/Q02/superFlat.fits)
    [PAPI]: 2012-05-24 17:13:00,632 DEBUG    calSuperFlat:222: Normalization of master (O2k?) flat frame. (MODE=2857)
    [PAPI]: 2012-05-24 17:13:00,633 DEBUG    calSuperFlat:226: Normalization parametes---> (tmp1=/data/out/Q01/tmp_sf.fits,result=/data/out/Q01/superFlat.fits)
Killing IRAF task `delete'
Killing IRAF task `delete'
Exception OSError: (10, 'No child processes') in <bound method Subprocess.__del__ of <Subprocess '/iraf/iraf/bin.linux/x_system.e -c', at 15a6d40>> ignored
Exception OSError: (10, 'No child processes') in <bound method Subprocess.__del__ of <Subprocess '/iraf/iraf/bin.linux/x_system.e -c', at 15a6d40>> ignored
    [PAPI]: 2012-05-24 17:13:03,286 ERROR    reductionset:2085: [reduceSeq] Error while parallel data reduction ! --> Error running IRAF task delete
('IRAF task terminated abnormally\nERROR (601, "Parameter not a legal boolean (try \'yes\' or \'no\') (verify)\x07")\n', 10, 'No child processes')                                                   
    [PAPI]: 2012-05-24 17:13:03,286 ERROR    reductionset:1773: [reduceSet] Cannot reduce sequence : 
 ['/data/i_test/001/dark_seq_ind0072.fits', '/data/i_test/001/dark_seq_ind0073.fits', '/data/i_test/001/dark_seq_ind0074.fits', '/data/i_test/001/dark_seq_ind0075.fits', '/data/i_test/001/dark_seq_ind0076.fits']                                                                                                                                                                                       
 Error running IRAF task delete                                                                                                                                                                      
('IRAF task terminated abnormally\nERROR (601, "Parameter not a legal boolean (try \'yes\' or \'no\') (verify)\x07")\n', 10, 'No child processes')  



    SOLUCION: sustituyo la llamada a iraf.mscred.mscarith por las operaciones correspondientes en python !!!
    

2012-05-25
==========  
  - Elimino el chequeo de los FITS en la funcion mainGUI:new_file_func(), pues ahora es realizado
  en el clfits::recognize(). Lo pruebo y parece que va muy bien.
  Esto servira para todos los modos 'file' & 'dir' del datacollector.
  - Observo algo que parece una condición de carrera, y es que alguna vez puede ocurrir que aunque
  el chequeo del FITS sea correcto, GEIRS no haya aún añadido las keywords que le da el OT y entonces
  el QL no detecte bien el fichero pues no puede leer dichas keywords esenciales.
  
  - Se siguen produciendo errores de PyRAF de vez en cuando !!!!:
    
       [PAPI]: 2012-05-25 13:29:58,295 INFO     calSuperFlat:145: Combining images...(images are scaled to have the same median)
Killing IRAF task `combine'
Exception OSError: (10, 'No child processes') in <bound method Subprocess.__del__ of <Subprocess '/iraf/extern/mscred/bin.linux/x_combine.e -c', at 32692d8>> ignored
    [PAPI]: 2012-05-25 13:29:58,457 INFO     reductionset:2440: ##################################
    [PAPI]: 2012-05-25 13:29:58,457 ERROR    reductionset:2085: [reduceSeq] Error while parallel data reduction ! --> Error running IRAF task combine
('IRAF task terminated abnormally\nERROR (603, "Parameter not a legal number (project)\x07")\n', 10, 'No child processes')                                                                                                   
    [PAPI]: 2012-05-25 13:29:58,458 INFO     reductionset:2441: #### Starting Object Data Reduction #####
    [PAPI]: 2012-05-25 13:29:58,458 ERROR    reductionset:1773: [reduceSet] Cannot reduce sequence : 
 ['/home/panic/data/i_test/001/dark_seq_ind0217.fits', '/home/panic/data/i_test/001/dark_seq_ind0218.fits', '/home/panic/data/i_test/001/dark_seq_ind0219.fits', '/home/panic/data/i_test/001/dark_seq_ind0220.fits', '/home/panic/data/i_test/001/dark_seq_ind0221.fits']                                                                                                                                                                                
 Error running IRAF task combine                                                                                                                                                                                             
('IRAF task terminated abnormally\nERROR (603, "Parameter not a legal number (project)\x07")\n', 10, 'No child processes')


  Otro error:
    
    [PAPI]: 2012-05-25 13:33:26,592 ERROR    reductionset:1901: [reduceSeq] Some error while creating master DARK: [Errno 32] Broken pipe
    [PAPI]: 2012-05-25 13:33:26,592 ERROR    reductionset:1773: [reduceSet] Cannot reduce sequence : 
 ['/home/panic/data/i_test/001/dark_seq_ind0222.fits', '/home/panic/data/i_test/001/dark_seq_ind0223.fits', '/home/panic/data/i_test/001/dark_seq_ind0224.fits', '/home/panic/data/i_test/001/dark_seq_ind0225.fits', '/home/panic/data/i_test/001/dark_seq_ind0226.fits']                                                                                                                                                                                
 [Errno 32] Broken pipe                                                                                                                                                                                                      
    [PAPI]: 2012-05-25 13:33:26,592 DEBUG    reductionset:1774: [reduceSet] Procceding to next sequence...
Exception in thread Thread-10:
Traceback (most recent call last):
  File "/usr/lib64/python2.7/threading.py", line 530, in __bootstrap_inner
    self.run()
  File "/home/panic/DEVELOP/PIPELINE/PANIC/trunk/reduce/threadsmod.py", line 51, in run
    raise e
OSError: [Errno 32] Broken pipe


  - Hago una primera prueba/implementación en QL para usar Process+Queue en lugar de la clase ExecTaskThread que "pienso"
  que puede ser la causa de los errores de PyRAF descritos arriba.
  
  - Muevo algunos métodos relaccionados con FITS del módulo misc.utils al modulo clfits

2012-05-29
==========  
  - Reunion con Matilde (ver notas más abajo).
  - paper SPIE2012

2012-05-30
==========  

   - Modificacion en phometry para que genere al catalogo con el ZP estimado (sugerencia MF)
   

2012-06-11
==========  
   - Working on TaskRunner in QL and improvements in DataCollector 
   
2012-06-12
==========  
 - Sent to JF next notes for the videoconf:
   
    - Implemented support for FITS cubes (non integrated mode)
    - Implementing support for distinguished FITS-files (non integrated)
    - doing improvements on the parallel processing 
    - (of course) debugging and profiling 

  - Encuentro problemas serios en QL cuando se intenta reducir todo un DataSet
  de un directorio leido del tirón.
  Ese mismo error se produce tambien en PAPI cuando por ejemplo hacemos:
  
     > papi -s ~/DATA/i_test/001/ -S 8 9
     
     donde 8 es una secuencia de DARK 
           9 es una secuencia de SCI

    en cambio si 8 fuese una secuencia de SCI tambien, entoces no hay error !!!
    por que ???
    
    ---> TODO PARECE INDICAR QUE EL PROBLEMA ES POR LA CONCURRENCIA DE IRAF !!!!!!!
    
"""
Killing IRAF task `combine'
Exception OSError: (10, 'No child processes') in <bound method Subprocess.__del__ of <Subprocess '/iraf/extern/mscred/bin.linux/x_combine.e -c', at 208fea8>> ignored
    [PAPI]: 2012-06-12 18:56:03,092 ERROR    reductionset:2087: [reduceSeq] Error while parallel data reduction ! --> Error running IRAF task combine
('IRAF task terminated abnormally\nERROR (603, "Parameter not a legal number (project)\x07")\n', 10, 'No child processes')                                                                                                                                                     
    [PAPI]: 2012-06-12 18:56:03,092 ERROR    reductionset:1773: [reduceSet] Cannot reduce sequence : 
 ['/home/panic/data/i_test/001/dark_seq_ind0046.fits', '/home/panic/data/i_test/001/dark_seq_ind0047.fits', '/home/panic/data/i_test/001/dark_seq_ind0048.fits', '/home/panic/data/i_test/001/dark_seq_ind0049.fits', '/home/panic/data/i_test/001/dark_seq_ind0050.fits']     
 Error running IRAF task combine                                                                                                                                                                                                                                               
('IRAF task terminated abnormally\nERROR (603, "Parameter not a legal number (project)\x07")\n', 10, 'No child processes')                                                                                                                                                     
    [PAPI]: 2012-06-12 18:56:03,092 DEBUG    reductionset:1774: [reduceSet] Procceding to next sequence...
    [PAPI]: 2012-06-12 18:56:03,092 DEBUG    reductionset:1781: [reduceSet] All sequences processed.
    [PAPI]: 2012-06-12 18:56:03,093 DEBUG    reductionset:1782: [reduceSet] Files generated # 1 #: ***
    [PAPI]: 2012-06-12 18:56:03,093 DEBUG    reductionset:1783:             - /data/out/mDark_FVSjmi_2_2.fits
    [PAPI]: 2012-06-12 18:56:03,093 DEBUG    reductionset:1784:             Sequences failed  # 1 #: ***
    [PAPI]: 2012-06-12 18:56:03,093 INFO     reductionset:1371: Purging the output dir ...


Well done (I hope) -  Elapsed time(s): 10.733102!!!
List of images to combine ('@/data/out/Q01/files.txt'): XIO:  fatal IO error 11 (Resource temporarily unavailable) on X server ":0"
      after 24 requests (24 known processed) with 0 events remaining.

PANIC in `/iraf/extern/mscred/bin.linux/x_combine.e': Write to IPC with no reader
"""

2012-06-13
==========  

 * Pre-videoconf, videoconf y postvideoconf
  - JF pregunta sobre que es el profiling y que es LEMON
  - JF pregunta sobre la fecha para hacer la II-Sw-integration: CS está sin tiempo !!
  - Quedamos en preparar un TODO-list con las cosas del SW de PANIC que quedan pendientes
  con el objetivo de intentar determinar cuando podríamos tener la II-SI
  
 * Solucion a bug de PyRAF cuando llamamos al algún metodo en multiprocessing (ver notas del día 12-Jun-2012)
   Gracias V.Terrón (ejemplo pyraf_multiproc.py) , que el ya había pasado por el mismo problema, 
   encontramos que el "truco" está en crear el multiprocessing.pool antes de cualquier posible llamada a alguna rutina de PyRAF.
   En el ejemplo del 12-Jun, la al reducirse la secuencia de DARK con darkcombine y luego reducir 
   la secuencia de SCI con un Pool, entonces se corrompe el espacio de nombres de PyRAF o lo que sea
   y ya se produce el error. 
   Lo soluciono en reductionset.py declarando el Pool justo despues de la clase ReductionSet, pues si lo
   declaro antes, da otro error por que no conoce la clase RS.
   
 * Ahora queda probar que en el QL todo funciona bien tambien.
   Pues nada mas probar, me doy cuenta de que no funciona, pues el declarar
   variables globales (pool) en reductionset.py, luego el Process que creamos
   en el QL para procesar las secuencias (vía Queue) no puede acceder a dicho
   pool global; aunque no se queja de ningún error, proceso de reducción 
   se queda esperando forever en el result.get().
   
   Solución: ver 15-6-2012
   
2012-06-15
==========  
   
   * Por fin encuentro la solución la problema del interbloqueo por la variable
   global pool para evitar el bug de IRAF.
   La solucion (espero que definitiva!) es crear el pool local en RS.reduceSeq()
   de forma que lo usemos para todas la operaciones que requieran IRAF, de forma
   que siempre habremos creado el pool con todo su espacio de nombres correcto
   antes de llamar a IRAF (bug detectado por V.Terrón)
   
2012-06-19
==========  

 - Estudion y/o migracion de los métodos que usan ExecTaskThread en QL;
 Me encuentro con un dilema al migrarlo todo y hacer que todas las operaciones
 pasen por el TaskManager y su cola, pues podría interesar que mientras se esté 
 ejecutando la reducción de un DS "largo" se pueda interactura con el QL para 
 realizar otra operación de "corta" duración (subtract_last_2, divide, etc...).
 En dicho caso, habría que tener dos colas o bien dejarlo como está con Threads.
 
 Mientras decidio sobre dicho dilema, me encuentro con un problema al migrar
 QL:processLazy, pues me da el famoso error :
 """
 Process Process-1:
Traceback (most recent call last):
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 232, in _bootstrap
    self.run()
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 88, in run
    self._target(*self._args, **self._kwargs)
  File "/home/panic/DEVELOP/PIPELINE/PAPI/trunk/QL/mainGUI.py", line 2610, in worker
    func, args = input.get()[0]
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 91, in get
    res = self._recv()
  File "/home/panic/DEVELOP/PIPELINE/PAPI/trunk/QL/mainGUI.py", line 100, in _unpickle_method
    for cls in cls.mro():
AttributeError: ("class ApplyDarkFlat has no attribute 'mro'", <function _unpickle_method at 0x2c937d0>, ('apply', <reduce.applyDarkFlat.ApplyDarkFlat instance at 0x2f153b0>, <class reduce.applyDarkFlat.ApplyDarkFlat at 0x1b48600>))
"""

2012-06-20
==========  

- Encuentro la solución al problema de pickle/unpickle --> el problema estaba
en que la clase ApplyDarkFlat no derivaba de Object, y por eso no tenia los
atributos que necesitan los métodos de serialization.

2012-07-11
==========  

- Videoconf PANIC

*) Le mando a JF lo siguiente:

Dear Josef,

sorry for the delay, but I forgot it.

Please, take next inputs (QL & Pipeline) for the videoconf :

- Talk presenting the PANIC Quick-Look tool at SPIE2012
- Implemented procedure that mix dome & sky FF
- Continue with endless debugging
 

And the AIs to be done in QL & Pipeline before send PANIC to CAHA:

- Add support for distinguished files (non integrated)
- Implement health-check routines of the instrument (copy from JF's)
- Complete the debugging and tests of QL and Pipeline (might need additional developments)
- Review the initial photometric calibration
- Complete the Verification and Validation of pipeline results (in progress)
- Write QL and Pipeline User's Guide doc (initiated)
- Decide if the whole software must run in single computer or separate on control & processing computers (depend on memory problem found in GEIRS)    
- Choose & buy the computer/s to be used at Telescope
- Install the computer/s and write installation document
- Test QL & Pipeline at HD (2nd. Software Integration)


For the moment these are the AIs I can remember, but for sure not the ones.

*) Como resumen de la videoconf:

- JF se ve abrumado por las 3 slides de SW, así que prefiere resumirlo en : SW is going on.
Sin embargo, le preguntamos por GEIRS y las tareas pendientes:

   - todo parece indicar que CS implementara el control de las ruedas de filtros (Agost-Sep), 
   pero que el resto de cosas (sensors, fast readout, windowing, ...) lo hará si le sobra tiempo.
   - le preguntamos a JF si sabe algo del problema de memoria en GEIRS, y nos dice que no sabe nada,
   pero que le preguntará a CS. Tambien le pido que aproveche y le pregunte por una fecha tentativa
   para la 2da.Software Integration.
   JF en el mail de resumen de la videoconf, incluye:
   """ 
   Computer/memory:
     - status of memory problem is as before (i.e.reason unknown)
     - this problem has to be attacked again, wtih updated operating system etc
     - CS sees no problem to run PANIC including GEIRS on 1 computer
  """

  - Ulli informa que el problema de movimientos relativos en el 3.5 ha sido resulto, por
  lo que el OT podría usarlo.

  - Tambien se habla de la documentacion(deseable para finales de 2012), en principio en PDF+source. Jens sugiere además
  un trouble shooting document en la Web de forma que puedan hacer copy+paste para solucionar
  problemas del software.


2012-07-17
==========

- Matilde me dice que mejor postponemos las KDD hasta después de vacaciones (septiembre?)

2012-07-18
==========  

- Subida al OSN para enseñarlo a César y Regina


2012-07-19
==========  

- Tras varios días intentando compilar la libreria plplot-5.9.4 para que SCAMP pueda generar los gráficos png, lo consigo !!!:
  
  Los pasos son :
    
    1) Descargar el fuente de gd-libgd (con zypper no consigo encontrar dicha libreria) de https://bitbucket.org/pierrejoye/gd-libgd/overview
    
      >hg clone https://bitbucket.org/pierrejoye/gd-libgd
      
    2) Compilar dicha libraria (libgd):
       
       > cd gd-libgd
       > mkdir build
       > cd build 
       > cmake -DBUILD_TEST=1  -DENABLE_PNG=1 -DCMAKE_LIBRARY_PATH=/usr/loca/gdlib/lib -DCMAKE_INCLUDE_PATH=/usr/local/gdlib/include ../../gd-libgd/
       > make
       > make install
       
    3) Descargar la plplot-5.9.4 (pues parece que es la que recomiendan en el foro de SCAMP  http://www.astromatic.net/forum/showthread.php?tid=761)
       aunque puede que con la 5.9.9 también funcionase.
       
       http://sourceforge.net/projects/plplot/files/plplot/5.0.1/
       
    
    4) Compilar plplot-5.9.4
    
       > cd plplot-5.9.4
       > mkdir build
       > cd build 
       > cmake -DCMAKE_INSTALL_PREFIX=/usr/local/plplot594 -DBUILD_TEST=ON ../../plplot-5.9.4 >&cmake.out
       > ccmake ..
         y editar a mano 
 
          GDI32_LIBRARY /usr/local/lib/libgd.so
          ENABLE_python OFF (pues da un problema al no encontrar un .h de numpy ??)
          PLD_png ON
    
        básicamente eso.
        
     > make 
     > make install
     
     IMPORTANTE: copiar /usr/loca/gdlib/libgd.so en /usr/local/plplot594/lib/ pues si no se quejará el PLPLOT de que no la encuentra.
     
     > export PLPLOT_LIB=/usr/local/plplot594
     
     y listo !!! SCAMP debe generar los graficos PNG sin problema (glup!).
     
     
     FAQ:
       My program exits with the error message Unable to either (1) open/find or (2) allocate memory for the font file

       The PLplot library can't find the font files plstnd5.fnt and plxtnd5.fnt. Set the environment variable PLPLOT_LIB to the directory where these files are, e.g. export PLPLOT_LIB=/usr/local/plplot/data. 
     
     
    HA costado lo suyo !!! lo ideal sería que SCAMP (E.Bertin) migrara a la libraría cairo para generar los PNGs !!!
    
    Sin embargo, si le digo a SCAMP que genere ficheros JPEG no lo hace (Requested device jpeg not available), pregunta cada vez por el tipo de fichero....por qué ?
    PDF's si lo genera bien, incluso con mejor calidad que los PNG !!
    PS: en B/N y no completos
    Recompilo PLPLOT library con PLD_jpeg ON y ya si genera SCAMP los JPEG's, pero de una calidad pésima, inservibles !!!
    
    
    
    


2012-07-20
==========  
    

2012-07-24
==========  

- Pruebas con PyQt4 (en openSuSE11.4)
 
   * instalo SIP 4.13.3 (requerido por PyQt4.9.4)
   * compilo PyQt4.9.4
   *

- Pruebas con Pyside (en openSuSE11.4)

   * Sigo las instrucciones de http://qt-project.org/wiki/Building_PySide_on_Linux
   y todo OK !
   
- Modifico PQL (mainGUI) para que no tenga que hacer uso de la clase RunQtProcess
pues sólo se usaba en un caso (Subtract own-sky), y no merece la pena tener 
una clase para sólo eso. 
Lo que hago es que llamo directamente de forma sincrona (sin hebras ni nada) a
la clase sextractor.
No puedo usar hebras pues sex.run() no devuelve nada, y ExecTaskThread necesita
de el fichero generado para poder mostrarlo.
Todo esto para refactorizar código y simplificar !!
Muevo temporalmente runQtProcess.py al directorio deprecated.


2012-10-01
==========  
- Después de un parón de dos meses en PAPI por estar con TCS2, retomo a PAPI.
- Añado la escritura de los valores del diccionario del config_file que usa el
ReductionSet en el log_file de cara a poder luego depurar la reduccion realizada
por PAPI en cada ejecución.

- Encuentro un Bug(?) al lanzar PAPI en el portatil, pues da un error al crear
un master_dark de conjunto de Alhambra....en cambio en udit43 no ocurre ???


2012-10-02
==========  

- Test: aplico una distorsión (applyDistort.py) a una imagen reducida del
dataset de ALHAMBRA. Después, le paso astrowarp.py y compruebo que el plot
distort_1.png que genera SCAMP coincide con el que patrón de distorsión aplicado
(dist_mat_K.txt, que me pasó hace tiempo Conchi de PANIC).
Luego, buscando como interpretar mejor los plots que genera SCAMP (ver http://www.astro.uni-bonn.de/theli/gui/astromphotom.html)
extraigo que los pixels más grandes (rojo en plot) son los que deben coincidir
con el eje óptico del instrumento, y el resto serán más pequeños y por tanto
generan la distorsión; pensado un poco, eso tiene sentido....


- Aniado a reductionset.py 

 >>> pyraf.iraf.prcacheOff()

que me reportó VTerron tras consultar en los foros de PyRAF y creer que era un bug.
Aunque creo que ya no la necestio, pues no se que hice para evitar los problemas....

No obstante, la añado también con la intención de solucionar el problema siguiente
ya conocido desde hace tiempo:


Exception in thread Thread-1 (most likely raised during interpreter shutdown):
Traceback (most recent call last):
  File "/usr/lib64/python2.7/threading.py", line 530, in __bootstrap_inner
  File "/usr/lib64/python2.7/threading.py", line 483, in run
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 272, in _handle_workers
<type 'exceptions.TypeError'>: 'NoneType' object is not callable


pero SIGUE dando el problema a pesar de deshabilitar la Cache.
Leo en un foro que a alguien le pasa algo parecido, y le encuentro la siguiente
respuesta interesante: 

"""
From: http://stackoverflow.com/questions/4079810/python-thread-exception-errors-when-exit-the-whole-program

The problem is caused by the use of threading.Thread.setDaemon. Threads set 
daemonic don't prevent the Python intepreter from exiting, but they still keep 
running. Because Python cleans up the environment before the process is 
terminated, the threads can run into trouble when stuff is removed from under 
them. That raises an exception, which the thread class tries to print for your 
convenience -- but that, then, too fails because the process is exiting.

You could try to silence the exception, but that's tricky (and if the thread 
does anything substantial, it might hide a real problem. Not the case here, 
though.) Or you could ask the thread to stop before exiting, and not set the 
thread daemonic. Or you can simply avoid using threads altogether. I do not 
remember if wxPython has a convenient mechanism for getting a process's output 
or even of doing asynchronous I/O, but many GUI toolkits do. And there's always
Twisted, which does it all for you.
"""


2012-10-17
==========  
- En busca del error que hace que falle PyRAF+multiprocessing (sin clases ni nada)
en python 2.6 ( HD, portatil, udit43), y que sin embargo funciona perfectamente
en python 2.7:


#!/usr/bin/env python

import pyraf.iraf
from pyraf.iraf import noao, imred, ccdred, mscred
from pyraf.iraf import images,imutil

import time
import multiprocessing
import sys

pyraf.iraf.prcacheOff()

def run_iraf():
    print "Start run_iraf"

    pyraf.iraf.unlearn("imstat")
    #import pdb; pdb.set_trace()
    pyraf.iraf.imstat(images = "/tmp/dark.fits", fields="mean")

    print "End run_iraf"

    return "Success!"

if __name__ == '__main__':
    #run_iraf()
    #sys.exit(0)
    pool = multiprocessing.Pool(processes=2)      # start 4 worker processes
    result = pool.apply_async(run_iraf, args=())   
    result.wait()
    #result = multiprocessing.Pool(processes=4).apply_async(f, [10])
    print result.get(timeout=5) 
    
    sys.exit(0)


2012-10-18
==========  
- Continuo buscando el problema de PyRAF; escribo a help@stsci.edu preguntando
sobre el problema.
- Lo pruebo en el ordenador de VTerron (python 2.6.6, PyRAF 2.0) y funciona 
perfectamente. El me recomienda pasar a PyRAF 2.0
- Instalo PyRAF 2.0, en udit43, pero siguen los problemas.
- Instalo Python 2.7 en un directorio a parte, pero no puedo probarlo pues
no encuentra PyRAF, etc ....
- Instalo en el portatil (/usr/local/python273) Python 2.7.3 y todos los 
modulos de python que necesita PAPI. Lo documento en el PAPI_Install.txt. 
Ahora todo parece funcionar correctamente en el portatil con la nueva version 
de Python273.

- comienzo desarrollo de check_papi_modules.py para incluyir al inicio de papi.py


2012-10-22
==========  
- Me doy cuenta de que calBPM y calBPM_2 no funcionan bien (temp_dir, master_dark, ...)
y además le actualizo el Parser de opciones de la CL.

2012-10-23
==========  
- añadidas bastantes mejoras a calBPM (incluso tenia un bug) y calBPM_2.
- buscando algo para sustituir STILTS para el cross-matching de catalogos,
encuentro un código de Sergio Pascual, 'gmatch' en

     https://bitbucket.org/sergiopr/gmatch/src

que habrá que probar.
   
2012-10-24
==========  
- Encuentro una implementación de un wrapper para Sextractor de un compañero
de Sergio Pascual, en :

    https://gitorious.org/~gruel   

- Astrometry.net: instalo y compilo la última version (0.38) en udit43/udit22 y 
le copio los index files en (/usr/local/astrometry/data) y la pruebo con una
imagen reducida y ya calibrada de O2k (Alhambra):

solve-field ~/reduced_SEQ.fits --scale-units arcsecperpix --scale-low 0.2 --scale-high 0.4 --overwrite

y lo hace aparentemente bien (aunque era una imagen ya calibrada astrometricamente por scamp!).

Observaciones:
   - SCAMP tardó 12 segundos en resolver el .ldac creado por SExtractor (6 secs),
   en total unos 19secs; 
   por otro lado Astrometry.net tarda 32secs en total (buscar fuentes y resolver 
   astrometría)
   Sin embargo, si ejecuto 'solve-field' con la opcion --no-plots, tarda 8secs !!!
   
   - Astrometry.net usa BD (/usr/local/astrometry/data/index-nnn.fits) local !
   
   - Astrometry genera un fichero reduce_SEQ.new con un WCS que usa proyección
   TAN-SIP (TAN (gnomic) projection + SIP distortions).

   - Si le paso una imagen no calibrada astrometricamente 
            
            /data/O2K/Matilde/120105/ferM_0065.fits
     
     entonces Astrometry.net empieza a buscar iterando sobre los indices y al
     final lo paro pues después de más de 30minutos no parece terminar ...
     Aunque le pase las coordenadas aproximadas, --ra 100.427917 --dec 9.522,
     tampoco resuelve.
     
    Sin embargo, con astrowarp.py (PAPI) si puedo calibrar la misma imagen 
    en bruto en 17secs:
    
    >> python reduce/astrowarp.py -s /data/O2K/Matilde/120105/ferM_0065.fits -o /tmp/astro_cal.fits

- Josef Fried me responde el mail en el que le pregunto por las rutinas de
Health-Check para PANIC, pero no entiendo, pues lo que me manda es muy parecido
a la rutina ana.prg que ya tenía (incluso parece más antigua) y además no concuerda
con lo que me comenta en el email ????

- Recibo nueva oferta de Belen de DELL sobre el R720 (16K€)



2012-10-29
==========  
- Escribo email resumen para enviar acerca del PANIC-computer (aún no lo envío)

- Inicio implementación de health.py ...sin saber aún muy bien que tengo que hacer !!!!

2012-10-30
==========  
- Sigo con el tema del health-check, y me pongo a probar manualmente la fórmula
de Janisky para calcular la ganancia(K) y el RON, pero no me salen resultados
congruentes.
Además encuentro lo siguiente:

"""
In CCD imaging, gain refers to the magnitude of amplification a given system 
will produce. Gain is reported in terms of electrons/ADU (analog-to-digital unit). 
A gain of 8 means that the camera digitizes the CCD signal so that each ADU 
corresponds to 8 photoelectrons.

The system gain of a Photometrics camera is typically set so that the full 
well of the CCD matches the full range of the digitizer (at 1x gain). The 
camera's gain can also be selected under software control to meet the needs of 
a given application. For example, the gain can be increased to 4x when the 
application is photon starved and a high-sensitivity mode is required. 
Alternatively, the gain can be reduced to 1/2x when the application is 
photon-shot-noise limited and a high SNR mode is required. Because gain refers 
to the amplification of a system and the gain reported in CCD imaging is 
actually inverse amplification, the meaning of gain is not entirely intuitive. 
As gain increases, the reported gain value decreases. For example, if the 
system gain (1x) is 8e-/ADU, then the high-gain (4x) mode would be 2e-/ADU.

A simple method to calculate the system gain is shown below:

    1-Collect a bias image (zero-integration dark image) and label it "bias".
    2-Collect two even-illumination images and label them "flat1" and "flat2".
    3-Calculate a difference image: diff = flat2 - flat1.
    4-Calculate the standard deviation of the central 100 x 100 pixels in the difference image.
    5-Calculate the variance by squaring the standard deviation and dividing by 2 (variance adds per image, so the variance of the difference image is the sum of the variance of flat1 and flat2).
    6-Calculate a bias-corrected image by subtracting the bias from one of the flat images and label it corr: corr = flat1 - bias.
    7-Obtain the mean illumination level by calculating the mean of the central 100 x 100 region of the corr image.
    8-The mean divided by the variance equals the gain: gain = mean /variance.

A more rigorous method is that of Mortara and Fowler (SPIE Vol. 290 Solid State 
Imagers for Astronomy (1981) pp. 28-33), which essentially involves repeating 
the above procedure for a series of illumination levels over the full range of 
the CCD full well. In addition, their method recommends collecting four or more
flat images at each exposure level and averaging them to improve the precision 
of the measurement. The authors also provide the theory supporting the method. 
Another rigorous, excellent method that can be used to calculate gain is the 
photon-transfer technique of Janesick et al. (Optical Engineering Vol. 26 (10) 
(1987) pp. 972-980).
"""


2012-10-31
==========  
- Continuo con health.py.


2012-11-05
==========
- Nos manda Matilde un mail pidiendo lo siguiente:

"""
Muy buenas a todos,

  como todos los annos, en la reunion del Comite Ejecutivo de Calar Alto presentaremos dos dispositivas sobre PANIC.
  Para preparar estas dispositivas, me podeis mandar un par de frases o tres sobre la situacion actual de lo que estais llevando cada uno?
  Alguien tiene alguna foto reciente o relevante?

Me gustaria montar esto el miercoles por la mannana.
 
"""
Yo le respondo con:


Hola Matilde,

te adjunto un párrafo que creo que resumen de forma general el estado
del pipeline. Modúlalo como tu veas más conveniente, y en su caso, **
completa ** algunos datos que faltan de tu proyecto.


"""
Concerning the Pipeline and quick-look tool, the development and
debugging was continued, making improvements to some processing
routines and adding new features. In addition, the pipeline was run
successfully with a observing campaign of the project <xxxxxxx>  of
<xxxxxx> nights with Omega2000 at CA.
Currently, the pipeline debugging and improvement are being continued,
the computer system is about to be ordered, and a second software
integration to be hold early next year is being prepared.
"""

2012-11-07
==========
- Encuentro información que me aclara bastante como hacer el calculo de la
Gain y RON de un CCD (o IR detector) en :

    http://spiff.rit.edu/classes/phys445/lectures/gain/gain.html

- A partir de la web anterior, pero ahora en :

http://spiff.rit.edu/classes/phys445/lectures/align/pipeline.html

encuentro el artículo:
    "FOCAS Automatic Catalog Matching Algorithms"
    
que describe como hacer el matching de catalogos de forma eficiente.

- Hablo con Jessica de DELL acerca de los problemas con openSuSE en el
equipo DELL y me dice lo siguiente:
    
    1) Probablemente no tengamos problema con la distribucion openSuSE (o 
    cualquier otra open), pero no nos pueden garantizar que no haya problemas
    con algún driver de alguna controladora, pues es por eso que no esta
    certificado.
    
    2) Incluso, tambien podriamos tener problemas con el soporte tecnico, pues
    en cuanto le digamos que tenemos openSUSE, pues incluso por el fallo de un
    disco nos pueden negar el soporte.
  
    3) Hemos quedado que maniana me pasara un presupuesto con el coste de la 
    licencia para SuSE entreprise para 3 y 5 anios.

- Hago mejoras en health.py :

    - estimacion del full-well
    - chequeo de tamaño ventana
    - rango de ficheros en el paquete
 
  Pero todo esto quedaría pendiente de probar con datos reales de PANIC o
  cualquier otro instrumento.
  
  Todo:
  ----
    - temporal_noise (cfr. vianak)
    - usar numpy en lugar de cubemean
    - implementar chequeo de rango y sigma-clipping  !
    
2012-11-08
==========
- implemento spatial_noise.py para calcular el RON a partir de la ganancia
y de una serie de parejas de imagenes con el mismo TEXP.
Esta basado en las rutinas que me pasó Josef Fried y en :
  
        http://bit.ly/YUdJsD

        Noise = stdDev(Darkframe1-Darkframe2)/sqrt(2)*AD-Factor/EM-Gain


2012-11-12
==========
- Continuo con la documentación con Sphinx de PAPI; me esta dado un monton
de WARNINGS que al generar el latex se convierten en un error. 
Todo es por estar usando la extensión de Numpy `sphinxext`.

- Envio a Josef para la videoconf lo siguiente:

    * Added some kind of detector health-check routines (gain and noise computation)
    * PAPI doc in progress (http://www.iaa.es/~jmiguel/PANIC/PAPI/html/)
    * Defined the PANIC computer ?

2012-11-16
==========

- Avanzo bastante con la migracion a PyQt4 !! al menos puedo lanzar el QL, aunque
hay bastantes metodos que aun hay que migrar y actualizar, y para ellos hay
que ir probando la GUI por completo !


2012-11-19
==========
- Encuentro buscando por la red como "silenciar" los warnings de sphinx con la 
extension numpydoc:

numpydoc_show_class_members = False

Con esto ya no da los warnings, y se genera el latex+pdf bien. 
No obstante, parece que para generar bien la documentación habría que usar
un generador propio en python, como hacen otros proyectos (incluido el propio
numpy) como:

    http://www.pymvpa.org/index.html
    http://scikit-image.org/docs/dev/

2012-11-21
==========
- Continuo con la migracion a PyQt4.
- Me surge la duda sobre si para los Master TwLight flats es imprescindible
un dark model o bastaría con un simple master_dark ?? Ahora mismo sólo
se calculan con un master_dark_model.
- Intento instalar en el portatil la version QL4, pero como no me deja instalar
PyQt4; parece que la version de PyQt4 no es compatible con la libreria Qt4 que
tengo instalada en el sistama ...
Lo mejor será esperar a migrar a openSuSE 12.2.


2012-11-22
==========
- Richard Mattar me manda una nueva version de geirs2Panic; la compilo, aunque
el '-Ofast' no me funciona (solo para GCC >= 4.7.x), pero con -O2 si compila
y se ejecuta en 1.5secs.

Lo pruebo aniadiendolo en en ~/GEIRS/scripts/QueueFiles

OJO: Geirs2Panic no puede ser lanzado aquí en background, pues si no GEIRS
se creería que ha terminado y continuaría con la secuencia que estuvise 
ejecutando ...

""
modify_fits_hdr -v -a ~/tmp/fitsheader_panic.txt $1 >>~/GEIRS/log/add_panic_fits.log
/home/panic/DEVELOP/GEIRS/geirs2Panic/src/geirs2Panic $1 $1_r.fits -r
export ret=$?
if [ $ret -eq 0 ]; then
    echo `date '+%Y-%m-%d_%Hh%Mm%S'` $1_r.fits   >>~/tmp/fitsfiles.corrected
else
    echo `date '+%Y-%m-%d_%Hh%Mm%S'` "ERROR $ret in modifying fits-header of $1"  >>~/tmp/fitsfiles.corrected
fi
exit $ret
""

y lanzo varias secuencias del OT con dicha modificación y perece que el QL
no se queja. Aunque habría que ver los efecto en el proceso de reducción....
De momento eso no lo voy a probar, pues no se muy bien si se usará el Geirs2Panic ....
 


- Decido quitar en ExecTaskThread.run el "raise e" pues no se como capturarla
después y la saca por la de forma fea por la stdout.
No creo que sea necesario elevar la exceptio, pues el error se detecta de todas
formas; parece que no tendrá efectos colaterales.
 

2012-11-23
==========

- Instalacion de todo el software de PAPI en openSUSE12.2
- Actualizo el documento de instalación
- Pruebo 'casi' todo, y parece que ve bien: QL4, reduccion de HAWK-I-3, photometric calib, ...
- SCAMP con soporte para graficos PNG : es lo que mas guerra me dió !!! la libraria plplot-5.9.9 y cia.;
se me habia olvidado copiar la nueva libplplotd a /usr/lib64 y por eso no me funcionaba; el PLPLOT_LIB no hace falta !!


2012-11-26
==========

- Instalo la ultima version de OT y la vieja de GEIRS para seguir con las
  pruebas.
- Le escribo a Clemens diciendole que igual es mejor comprar los equipos aquí
  para evitar que yo tenga que viajar a HD para la instalación.
- Bug fix.:
Al lanzar el designer, me da varios errores y no deja lanzarlo. Buscado en
  google encuentro una forma "chapucerilla" para que funcione, y es creado el
  fichero  ~/.config/ibus/bus.


"""
Every KDE and QT GUI application complains on startup:

QInotifyFileSystemWatcherEngine::addPaths: inotify_add_watch failed: No such file or directory
QFileSystemWatcher: failed to add paths: /home/allee-o/.config/ibus/bus

that very disturbing when working on the command line, e.g. with kate or okular etc.

Creating the directory ~/.config/ibus/bus makes the error go away. I installed ibus-daemon
"""

2012-10-27
==========  

- Instalo la nueva versioń de Eclipse (4.2.1 - Juno) junto con la extensión
para los Color Theme (Oblion).
De paso encuentro una versión "custom" de eclipse para Python (+php,web,ruby) : Aptana Studio 3!!
Habrá que probarla.

2012-10-28
==========  
- Modificación de photometry.py con la implementación de xmatching de catalogos
usando un modulo de python coords.py que encontre en :
   >>> https://bitbucket.org/nhmc/pyserpens/src/6e805f1f08ef/coord.py

Eché de menos el 'merge' de catalogos en AtPy, así que me tuve que buscar la vida
con otro xmatch para mezclarlos.
De esta forma me evito el tener que usar STILTS (java app), que aunque funciona 
muy bien, me crea otra dependencia externa a python.
Lo pruebo y parece que va bien, al menos obtengo identicos resultados que con
STILTS, y en un poco de menos tiempo de CPU.
De momento decido dejar las dos implementaciones de xmatching, con stilts y sin el.
Nota: habría tambien la posibilidad de usar gmatch, un modulo python de Sergio
Pascual de la UCM que usa KDTree, pero como coords.py es simple, funciona bien,y
en principio los xmatch serán con pocas estrellas y no nos preocupa mucha la 
eficiencia, para liar más la cosas con un module de la UCM ?
Si viesemos que la eficiencia es importante, entoces lo usariamos...


2012-10-29
==========  
- Instalación de PAPI_SW en portatil con openSuSE12.2; parece que todo OK.

2012-10-30
==========  
- Me pongo a ver por que el set Matilde-120103-27a31 en filtro Z no se reduce
bien. El problema está en el superFlat, que no se calcula bien, pues la normalización
que se hace con la "moda" da una normalizacion con valores >2 !!!
¿ habría que chequear eso en el calculo del SF normlizado ?
¿ es adecuada la normalización con la "moda" ? hago una prueba con la "mean" y
si sale bien.
También me doy cuenta que los umbrales para el calculo de los BP del gainmap que
hay en el fichero de configuracion no son del todo buenos, al menos para la 
secuencia en cuestion.
Los cambio tal que:

 mingain = 0.5 # pixels with sensitivity < MINGAIN are assumed bad (0.7) 
 maxgain = 1.5 # pixels with sensitivity > MAXGAIN are assumed bad (1.3)

El valos más sensible es el mingain !

TODO: Tengo que ver bien como afectan los BPM en todo el proceso de reducción !!!!!
 
2012-12-03
==========
- Dandole vueltas a como hacer la normalización de los flats, veo que en el
pipeline de HAWK-I hacen la normalización con la mediana, que es un estimador
"robusto", mientras que la "mean" no lo es !!!
Por tanto, me pongo a modificar la todas la rutinas que hacen normalización:
Sin embargo, encuentro unas rutinas para calcular un estimador "robusto" de la
media:
http://fornax.phys.unm.edu/lwa/subversion/trunk/lsl/lsl/statistics/robust.py

Comparando los resultados de robust.mean() y numpy.median() los resultados son
muy parecidos. De momento vamos a usar la mediana.
Modifico en todas las rutinas la normalización por la median en lugar de por la moda !!

Me surge la duda de si la campania de Matilde con O2k se redujo bien; miro las
imágenes reducidas y veo que al menos la secuencia 120103-27a31 "se ven estrellas";
esa se redujeron con flast de cielo, y por eso quizás el gain.fits no se calculó
del todo mal.
 

2012-12-04
==========

- Encuentro el paquete de reducción del LSST, y hay cosas muy interesantes:

    http://www.astro.princeton.edu/~bick/lsstdox/userLsst/mast-1413/python/lsst/

- Intentado usar la funcion robust.polyfit(), pero me doy cuenta de que tiene
un par de bugs, entre ellos que la funcion __processPoly() no está implementada...
De todas formas, puedo llegar a comparar el resultado vs np.polyfit(), pero en
el ejemplo que pruebo los resultados son muy parecidos.

Sin embargo, habría otra opción, y es usar fit.polyfitr() que es una copia
de la que encontré en pyserpens. 

2012-12-05
==========

- Continuo con la documentacion.
- A la vez voy mejorando algunos modulos (calDark, calDarkModel, ...) tanto
la documentacion/ayuda y actualizando para usar OptionParser que en algunos
no estaba actualizado aún.


2012-12-11
==========
Le envio a JF las notas para la videoconf:
"""
- QL: GUI migration from Qt3 to Qt4
- Pipeline & QL running on openSUSE12.2
- several improvements in (flats, photometry)
- documentation: in progress
"""


2012-12-17
==========
- Preparación de la demo de sw de PANIC:

En mi portatil (openSuSE12.2 x86_64) debo hacer lo siguiente:

$ rcrpcbind start
$ mount udit36.iaa.es:/home/panic/tmp /mnt/tmp/
$ mount udit36.iaa.es:/home/panic/DATA /mnt/DATA
$ ln -s /mnt/tmp /home/panic/tmp



2012-12-18
==========
- Demo de sw de PANIC:

A las 10.15 aprox. comenzamos, asistiendo : MF, JR, CC, VT, AG, JM

- Revisar los valores RA,Dec,Time offset del setup usados para el agrupamiento
de datasets no observados con el OT.
- Cambiar el color botón "Start Processing" y modificar la funcionalidad t.q.:
 "Process all, only new files, Cancel"

- Revisar agrupamiento de serie de darks; en 'Build Calibrations' parece que lo hace
de forma distinta.
- Añadir otro parametro 'max. número ficheros/grupo' para el agrupamiento de 
datos no observados con el OT;
- Intentar obtener la matriz de distorsión, bien a partir de SCAMP preguntando
a E.Bertín o bien implementando el procedimiento para calcularla.

- Revisar el procedimiento del cálculo del FWHM, psf, ...


2012-12-19
==========

- Rapaso notas tomadas de la demo-review de sw

2012-12-20
==========
- Empiezo con la implementación de sugerencias/bugs en el QL:

  * bug photometry
  
2012-12-21
==========
  * Soluciono BUG importante en RS::self.out_file que no permitía reducir 
  correctamente (se machacaba el fichero de salida) todo un directorio de datos
  con multiples secuencias.
  
2012-12-28
==========
  * Soluciono BUG en setEnabled's del popup menu del QL


2013-01-03
==========

FELIZ AÑO NUEVO !!!

  * Modifico DS::GetFilterFiles() para además de encontrar gaps temporal, poder:
     - limitar la distancia en AR,DEC máxima entre dos ficheros consecutivos de un grupo;
     si se supera dicha distancia (parametro) se 'parte' el grupo.
     - liminar el número máximo de ficheros dentro de un grupo.
  * Modifico QL::worker() y QL::checkDoneQueue() para atrapar excepciones de 
    errores que solo salian por la consola (terminal) y no en la pantalla del QL.

  * Modifico QL para que en el Tab 'Setting' el grouping tenga efecto


2013-01-04
==========
- Currently, this code will not distinguish between next
  dark sequences:
     - 2s 2s 2s  5s 5s 5s 10s 10s 10s 20s 20s 20s ...
     - 2s 5s 10s 20s ...
 both will be classified as dark_model sequences, but
 if max_nfiles=3, then they will be distinguished, although
 it will also affect the other sequences.

- Modifico RS::reduceSet() para poder reducir sequencias según su tipo;
  de esta forma corrijo RS::buildCalibrations() para que reduzca sólo las
  secuencias de calibracion; antes se usaba buildMasterDarks(), buildMasterDomeFlats(), etc
  que hacia su propio agrupamiento pero de forma incorrecta, sin atender
  a grouping por 'ot' ni 'filter'.
  Por tanto, buildMasterDarks() & cia. ya no son necesarias.
 
- Implemento QL:stopProcessing() para detener/abortar la reducción en el QL.
- Elimino la 'tab-Pipeline' de la GUI del QL, pues no hacia nada.


2013-01-17
==========
- Retomo modificaciones en QL:
  
   * cambio de sitio el TempDir, pues es algo no importante para el usuario;
   lo muevo a la pestaña Setup
   * elimino la opción "Stack-Frames" del Pop-up, y la "fundo" con "Quick-red",
   pues al fin las dos estaban haciendo lo mismo, excepto que Stack-frames
   buscaba los proximos en caso de solo seleccionar uno.
- Modifico RS:reduceSet() para que en caso de que fallen todas la secuencias,
lanze una excepción.

- Elimino el bug que provocaba que se insertaran dos veces algunos de los ficheros
generados por el QL, por ejemplo, al terminar de reducir se insertan en la outputDB,
y al hacer click en "OutDir" se revisa el outdir y se insertan todos los que hubiese
en dicho directorio, sin comprobar si ya habian sido insertados previamente.
Para solucionarlo, compruebo en DB::insert(filename) si el filaname ya está en 
la BD, de esta forma nunca podrá haber dos ficheros con el mismo nombre en la BD,
entendiendo como nombre del fichero (path+filaname). 

2013-01-18
==========
- continuo depurando checkQuality para homogeneizar y que lea los ficheros de
configuración de PAPI_CONF en lugar de irdr/conf/....
Importante: actualizo los ficheros de configuracion de Sex del config_files con
los que usaba checkQuality y que estaban dentro del directorio de IRDR de PAPI.

- Añado a RS::reduceSingleObject la opcion de calcular el FWHM al final de 
una quick-reduction; tb. lo añado como opción del fichero de configuracion de PAPI.

2013-01-21
==========
- Implementado refPixelCorrection.py para el tratamiento de los
'ReferencePixels' basado en el métido de la WIRCAM (http://goo.gl/zdLdC)

2013-02-27
==========
- Retomo PAPI despues de varias semanas con el OSN (WeatherServer y nueva web meteo).
- Me pongo a mejorar la rutina astrowarp para poder calibrar las imagenes de
la CCDs del OSN (T150 y  T90). De entrada no funciona con ninguna, de queja SCAMP
con el tipico mensaje de :

    """
    > Fixing the degrees of freedom
    > WARNING: Not enough matched detections in instrument A1 
    """

  - Me doy cuenta de que la orientacion no sigue la norma de Norte arriba y Este
  a izquierda. Hay que hacer un FlipY(vertical) para que las imagenes estén bien.
  No se porque en los headers dice "Mirror/Rotate 90 CW", que es lo que está
  seleccionado en Maxim/DL. Le pregunto a Fran a ver que me dice.

- Instalo la ultima version de Astrometry.net en udit22 (opensuse12.2), pero
no va bien. Da un error de dependencias de librerias .... y auque sigue trabajando,
no es capaz de resolver los campos de Roper.


2013-03-01
==========

- Reanudo pruebas de astrometría con SCAMP & Astrometry.net de cara a implementar
la calibracion astrometrica en el archivo del OSN.


2013-03-05
==========
-- Me descargo el nuevo "catalogo" de la serie index-40XX-YY.fits.bz2 que
provienen de 2MASS:

    wget -c -r -A .bz2 http://broiler.astrometry.net/~dstn/4000/ -o log.txt

Des-cromprimidos ocupan 32GB !!!

 - Lo pruebo con RoperT90 y aunque tarda mas que SCAMP, lo resulve:
 
 solve-field --scale-units arcsecperpix --scale-low 0.7 --scale-high 0.8 /home/panic/as/90/new.fits --overwrite

El mismo campo lo resuelve más rápido SCAMP usando astrowarp !!


Astromatic.net (web service)
----------------------------
...get_or_create_image(df)
  File "process_submissions.py", line 469, in get_or_create_image
    img = create_source_list(df)
  File "process_submissions.py", line 548, in create_source_list
    raise e
TypeError: cannot perform reduce with flexible type

29-Abril-2013
=============
 
- Herramientas para medir prestaciones de la máquina:
  
* sysbench 
Nota: para compilarla puede ser necesario cambiar lo siguiente:
(http://www.randombugs.com/linux/compiling-sysbench-0412-debian.html)
   En el fichero configure.ca
    #AC_PROG_LIBTOOL 
   AC_PROG_RANLIB

Seeing this variable in configure.ca I just comment the variable and re run autogen.sh. This time all works flawlessly. After this I run

./configure && make && make install
with success.

In short. Edit configure.ca:

#AC_PROG_LIBTOOL
AC_PROG_RANLIB
and re-run

./autogen.sh
and your are ready to

./configure && make && make install



* Bonnie++
* IoZone


2013-05-02
==========
- Retomo la astrometría para ROPER del T150/T90:

1- Hay que darle una matrix CDi_j que se aproxime.
2- Probar con astrometry.net y astrowarp y ver cual funciona mejor


2013-05-13
==========
- Test con Bonnie++
"""
panic@panic1:~/SOFTWARE/bonnie++-1.03e> ./bonnie++ -d /data1/bonie/
Writing with putc()...done
Writing intelligently...done
Rewriting...done
Reading with getc()...done
Reading intelligently...done
start 'em...done...done...done...
Create files in sequential order...done.
Stat files in sequential order...done.
Delete files in sequential order...done.
Create files in random order...done.
Stat files in random order...done.
Delete files in random order...done.
Version 1.03e       ------Sequential Output------ --Sequential Input- --Random-
                    -Per Chr- --Block-- -Rewrite- -Per Chr- --Block-- --Seeks--
Machine        Size K/sec %CP K/sec %CP K/sec %CP K/sec %CP K/sec %CP  /sec %CP
panic1         126G 68870  86 87450  11 50864   8 103034  93 168632   7 442.5   1
                    ------Sequential Create------ --------Random Create--------
                    -Create-- --Read--- -Delete-- -Create-- --Read--- -Delete--
              files  /sec %CP  /sec %CP  /sec %CP  /sec %CP  /sec %CP  /sec %CP
                 16 +++++ +++ +++++ +++ +++++ +++ +++++ +++ +++++ +++ +++++ +++
panic1,126G,68870,86,87450,11,50864,8,103034,93,168632,7,442.5,1,16,+++++,+++,+++++,+++,+++++,+++,+++++,+++,+++++,+++,+++++,+++
"""


"""
panic@panic2:~/SOFTWARE/bonnie++-1.03e> ./bonnie++ -d /data2/prueba/
Writing with putc()...done
Writing intelligently...
done
Rewriting...

done
Reading with getc()...done
Reading intelligently...done
start 'em...done...done...done...
Create files in sequential order...done.
Stat files in sequential order...done.
Delete files in sequential order...done.
Create files in random order...done.
Stat files in random order...done.
Delete files in random order...done.
Version 1.03e       ------Sequential Output------ --Sequential Input- --Random-
                    -Per Chr- --Block-- -Rewrite- -Per Chr- --Block-- --Seeks--
Machine        Size K/sec %CP K/sec %CP K/sec %CP K/sec %CP K/sec %CP  /sec %CP
panic2         126G 116656  99 306223  40 122402  17 107048  93 343784  19 545.2   1
                    ------Sequential Create------ --------Random Create--------
                    -Create-- --Read--- -Delete-- -Create-- --Read--- -Delete--
              files  /sec %CP  /sec %CP  /sec %CP  /sec %CP  /sec %CP  /sec %CP
                 16 +++++ +++ +++++ +++ +++++ +++ +++++ +++ +++++ +++ +++++ +++
panic2,126G,116656,99,306223,40,122402,17,107048,93,343784,19,545.2,1,16,+++++,+++,+++++,+++,+++++,+++,+++++,+++,+++++,+++,+++++,+++
"""


21-Mayo-2013
============
- Sigo haciendo pruebas de las prestaciones de los RAIDs, ahora
con la herramienta filebench, que parece muy interesante.

22-Mayo-2013
============
-Parece que la herrmienta filebench no da siempre los mismos resultados,
es decir, fluctuan bastante.



23-Mayo-2013
============
-Actualización del documento de instalación de PAPI en openSuSE12.2, 
para instalarlo en panic1/2.iaa.es y hacer pruebas.

-Miro a ver si merece la pena instalar astropy pues integra PyFITS, pyvo, PyWCS, ...
pero parece que puede haber algún problema con los imports que tengo yo
en el código aunque se podrían solventar instalando los 'Compatibility packages'.
Pero de momento lo voy a dejar.


03-Junio-2013
=============
-Instalación de IRAF:

* IRAF
mkdir -p /iraf/iraf
cd /iraf/iraf
tar -xvzf /home/panic/SOFTWARE/PANIC/IRAF/iraf.lnux.x86_64.tar.gz 
/iraf/iraf/unix/hlib/install

* x11IRAF
x11iraf (xgterm)
----------------
mkdir x11iraf (temporal directory used only for packege installation)
cd x11iraf
wget http://iraf.net/ftp/iraf/x11iraf/x11iraf-v1.5DEV-bin.redhat.tar.gz 
tar xfz x11iraf-v1.5DEV-bin.redhat.tar.gz
ln -s bin.redhat bin.suse
ln -s lib.redhat lib.suse
mkdir /usr/lib64/X11/app-defaults
sudo ./install

STSDAS And TABLES (v3.16)
-------------------------

cd /iraf/iraf/extern
wget http://stsdas.stsci.edu/download/release_2013-03/stsci_iraf-3.16.redhat.tar.gz

04-Junio-2013
=============

- Continuo con la instalación de PAPI en panic2 y comienzo pruebas de PAPI
con datos de O2k.

- Me doy cuenta de que la app kate vía ssh con panic2 va muy lenta; busco en
la red y encuentro una solución:

 > ssh -Y panic2.iaa.es  kate -graphicssystem native

(http://lists.fedoraproject.org/pipermail/users/2012-May/417786.html)

- Encuentro un bug en la version de pywcs (pywcs>=1.10.2) que usa stsci_python_2.14,
respecto las keywords PV que genera SCAMP:

""
[PAPI]: 2013-06-04 19:01:06,044 ERROR    clfits:584: Error reading RA keyword :ERROR 6 in wcsset() at line 1561 of file wcslib/C/wcs.c:
PV1_5 : Unrecognized coordinate transformation parameter.
""
-->https://github.com/astropy/astropy/issues/299

Parece que de momento no hay parche, aunque con la pywcs_1.11 que yo usaba antes 
también aparece el problema (comprobado en udit22).

- Hago un :
 
 > pip install pywcs --upgrade 
 
 y se instala la ultima version de pywcs (1.11-4.7) pero el error sigue apareciendo!!!
 
  """PV1_5 : Unrecognized coordinate transformation parameter"""


07-Junio-2013
=============
- Instalo OPTPCI-e en panic2
- Instalo driver  PlxLinux_v6.50_modified.tar.gz; con el warning del kernel ya conocido
  La version PlxSdk_v6.50_modCL.tar.gz además del warning, da un error por asm/system.h.
  En principio, comentandolo compila sin problemas, pero he optado por usar la 
  version PlxLinux_v6.50_modified.tar.gz.
  
- Hago las pruebas que me dijo U.Mall según el punto 2.15.4 del documento CARMENES-FDR-04C2-NIR-Channel-ROE.pdf,
pero no veo que el LED parpadee rapidamente como dice el manual cuando hacemos
un (rotype dgen + read);

- Además tengo algunas dudas sobre como instalar el driver para que lo lea
en el arranque del sistema. La documentación no está completa, no encuentro
el admin/plxload, aunque si hay un Plx_load/Plx_unload + argumento.
Habrá que preguntar como se instala correctamente.

 
12-Junio-2013
=============
- Videoconf de PANIC:
  Sobre el sw, basicamente hablamos del problema detectado con las pruebas
  de la OPTPCIe; sólo está Richard M., y dice que en un par de semanas
  depurará el problema.
 
- Ulrich me manda una rutina para que la compile y la pruebe en panic2 y le
mande los resultados.
 
13-Junio-2013
=============
- Pruebo la rutina de Ulrich M. con la version PLX_6.5 del driver. Antes tuve
que aniadirle al fichero  OptPCI.h la siguiente linea:

    typedef PLX_STATUS RETURN_CODE;

pues la rutina que me mandó por lo visto era para la version PLX_6.31.

- Le envio los resultados a Ulrich M. y me dice que son correctos, y que por
tanto parece que la tarjeta está funcionando correctamente.
Sin embargo, yo le comento que con la version PLX_7.00 no funciona su programa
de pruebas. Me dice que lo depurará en la próxima semanas.


14-Junio-2013
=============
- Encuentro bug importante en astrowarp debido a los cambios que estuve haciendo
para la astrometría de la imagenes del OSN.


17-Junio-2013
=============
- Encuentro una posible solución al problema que tiene pywcs con las keywords
PVi_j:
"""
Error reading RA keyword :ERROR 6 in wcsset() at line 1561 of file pywcs/wcslib/C/wcs.c:
PV1_5 : Unrecognized coordinate transformation parameter.
"""

La solución pasaría por usar el modulo wcsutil.py de http://code.google.com/p/esutil/.
y usar image2sky/sky2image.


- Otra opción sería convertir el modelos de distorsion de SCAMP (PVi_j) a la 
proyección SIP, como describe el articulo "More Flexibility in representing
geometric distortion in Astronomical Images", de David L.Shupe.
Le escribí un email para ver si me podrían dejar el source de pv2sip/sip2pv pero
me dijeron que no; que si quería que les mandase yo mi rutina y me dirían si
estaba bien o no comparando los resultados.


18-Junio-2013
=============
 
19-Junio-2013
=============
-Dejo mas o menos operativo astrowarp tras modificar clfits.py con image2sky.

-Intentando reducir el HAWK-I_3 (cualquier sequencia) veo que no hay manera !!!!
Miro las notas de mi libreta, y parece que ya me dió problemas en su día, pero
parece que el S3 si conseguí reducirlo sin problemas, pero no hay manera tampoco
de reducir dicha secuencia. 
Haciendo una busqueda en google, me doy con un post ***muuuy interesante *** en
el foro de astromatic.net (http://www.astromatic.net/forum/showthread.php?tid=759)
sobre esto. Parece que tengo que mejorar algunas cosas en PAPI !!!!!!!!!!!!!

20-Junio-2013
=============
- Encuentro el problema que me traia loco con pixeles saturados en el catalogo
que genera SExtractor. Todo venía porque las imagenes en cuestion tenian
la keyword SATURATE 100000, y dicha variable mayor prioridad que SATUR_LEVEL,
incluso si la damos por la linea de comandos a sextractor.

- VTerron me anuncia que los coadds deberian tener en el header el NCOADDS para
poder hacer la estimacion del limite de saturacion.


- Encuentro el problema que impedia reducir el HAWK-I-3 (cualquier secuencia): 
todo radicaba en los parametros siguientes del fichero de configuracion:


    astrometry::mask_thresh = 5   # default 1.5
    astrometry::mask_minarea = 20 # default 5

Tras establecer esos nuevos valores, se reducen sin problemas todos las 
secuencias de HAWK-I-3.

El problame esta ahora en como "parametrizar" eso de forma "automatica" para
todos los datasets (HAWKI, PANIC, O2k, ....). Quizás un fichero de configuración
distinto para cada instrumento !!!! 
Además habrá que leer bien los comentarios de E.Bertin en el foro :

    http://www.astromatic.net/forum/showthread.php?tid=759


21-Junio-2013
=============
- Me pongo a solucionar el problema de la propagacion de la key NCOADDS y 
establacer en el fichero de configuracion cual es el SATURLEVEL que se debe
usar.

  * Propagacion NCOADDS/NDIT:
     - dithercubemean - copia el header de la primera imagen, y por tanto
     propaga bien para PAPI y O2k, pero no para HAWK-I, pues el split no
     copia la key NDIT.
     
     




FOR NEXT VIDEOCONF
==================
- Tested OPTPCIe board with U.Mall routine (optpci_hw_test.c); results show 
all is working well (PLX_v6.5 & PLX_v7.00) on PANIC computer.
- However, GEIRS simulation 'rotype dgen' still is not working.







Questions:
- Linearity values --> 15K ADUs for saturation
- Readout modes for PANIC
- GEIRS Upgrade for PANIC 
- PICe Interface with ROE for testing with new computers ( ROE simulator ?)
- How many serial ports are required ? or MOXA NPort (serial-ethernet converter) ? should also be tested !
- any other interface
- Ask CA about Archive interfece (run tests !)



KDD con MATILDE (15-May-2012)
=============================

 1) integration of cubes/individual files (add or mean)
   -->Si; sumatorio "simple" del cubo/ficheros sin mas.
   individual, quizás el OT me pueda ayudar, al menos para PAPI (ot?)
 2) integration of single-images (individual files) --> keyword FRAMENUM
   (ver arriba)
 3) how to proceed with windowed/binned images ? 
   --> MF preguntara a la gente de Barcelona sobre las ventanas 
   y como se podrian reducir (sky, astrometry, etc). (pendiente)
   --> JM Preguntara CS sobre el binning: CS responde que no, que en IR no hay binning 116
 4) JF: must be possible to check the photometry of a specific star selected in the display. Imexam ?? how ? 
   --> MF le preguntara a JF que quiere exactamente; MF no ve muy interesante el ir viendo la Mag de cada
   estrella al marcarla en el display. Es mucho más útil la grafica de magnitud instrumental VS magnitud catalogo.
   --->JM mirara si con Aladin de puede hacer lo de leer un catalogo+imagen para consultar la magnitud, y tambien
   con imexam.
   --> JM : con > aladin /tmp/reduced_SEQ.fits /tmp/reduced_SEQ_zp.xml se puede hacer !! y haciendo click sobre una 
   objeto no muestra los valores de catalogo leido (/tmp/reduced_SEQ_zp.xml) y generado con SExtractor con el MAG_ZEROPOINT 
   calculado previamente con photometry.py
   --> JM : ademas, "Quick-look Photometry with Imexamine" 
   --> JM: Además, imexam te muestra con 'a' la magnitud (MAG), teniendo en cuenta el ZP que se puede modificar con (epar rimexam)
   
   #   COL    LINE     COORDINATES
   #     R    MAG    FLUX     SKY    PEAK    E   PA BETA ENCLOSED   MOFFAT DIRECT 
     2243.31 2888.93 2243.31 2888.93
     28.92  13.82  29750.   1.239   70.36 0.18  -77 1.14    13.63    15.59   9.68
   ( en este ejemplo ZP=25)
   
 5) how to reduce 'other' readout modes (rrr-mpia, lir, mer, srr, cntsr) or only work for lir (line-interlaced-read)
   MF preguntara a CS, pues no sabe a priori de que diferencias puede haber pero tiene "curiosidad" por ver que quería decir CS 
   (aunque JF dijo que no había diferencias)
 6) how to remove the stripe/quadrant background offsets in dxtalk.py --> MF no se le ocurre a priori como eliminarlo; 
 JM preguntara al Chino (WIRCAM); Otra opcion es ver si se puede restar solamente la estrella, lo estudiará JM.
 JM--> Wei-Hao me responde:
   """
   How about a simple background subtraction in each stripe after
   the subtraction of the median?  Maybe this will solve the problem.
   """
   Lo que dice Wei-hao (restar a cada stripe su propio cielo) podría funcionar, pero nuestra "triste" realidad (imagenes con gradiente en el background), 
   no puede funcionar.
   
KDD con MATILDE (29-May-2012)
=============================
 
 - repasamos los punto de la ultima KDD; MF no ha podido hacer sus "deberes", por lo que lo dejamos 
 para la proxima KDD.
 - JM comenta sus "deberes" y muestra el ejemplo : aladin /tmp/reduced_SEQ.fits /tmp/reduced_SEQ.xml
   que a MF le parece bien.
   NO obstante, MF no está muy conforme con la dispersión (STD=RMS=0.105950) que tenemos en el ejemplo que le muestro (o2k-120105).
   MF pensará sobre ello, y yo probaré con MAG_APER, qphot, a ver que diferencias hay.
   
 - comentamos la respuesta de Wei-Hao:
   How about a simple background subtraction in each stripe after
   the subtraction of the median?  Maybe this will solve the problem.
   """
   Lo que dice Wei-hao (restar a cada stripe su propio cielo) podría funcionar, pero nuestra "triste" realidad (imagenes con gradiente en el background), 
   no puede funcionar.
   
   Matilde sugiere restar al stripe-mediana el su propio background antes de restarlo a los N stripes de la imagen a
   corregir, de forma que "solo" restesmos los artefactos ->"estrellas de crosstalk".
   Quizas es background podría ser la "moda" de la imagen.
 
 - "significado" de MagInstrumental negativa ? 
   MF: bueno, no tiene importancia, pues el resultado es el mismo; lo que pasa es que normalmente hace
   el ajuste con una estimación inicial ZP=25 de forma que no salgan valores "negativos".
   
    mag_instrumental = zmag - 2.5 * log10(flujo/tiempo_integracion)

  - En cuanto al problema de identificar los grupos/secuencias cuando se graban en modo "individual",
  MF comenta que quizás con la información extra del OT se pueda hacer.
  JM lo pensará, pues quizás para el Pipe sirva, aunque no para el QL.
  
  - JM le comenta a MF que para la proxima sesion le dará un "tutoria" sobre como usar PAPI.
  
  - MF pensara sobre cual puede ser el origen de la dispersion "tan grande" en la estimacion de fot. absoluta.
JM probar con qphot con MAG_APER, etc ...


KDD con MATILDE (19-Jun-2012)
=============================
- Le enseño brevemente un poco del CL de PAPI, y la primera pregunta fué:
  
  ¿ cómo reducir toda una campaña ? - TODO !!! buscar en todos los subdirectorios 
  de un directorio, pero crear logfiles distintos ??? yo creo que sería mejor.

- Luego pasamos a ver las series de dark y le extraña el gran numero de pixeles 
  calientes !! ¿ cómo podría afectar a la reducción suya ?
  
  MF investigará sobre el tema. JM buscará como los trata PAPI.
  
- Le enseño el procedimineto para combinar domeFF y skyFF. Le parece interesante, 
pues ellos (VT y MF) están intentado algo parecido en LEMON. MF estudiará la 
utilización de esta mix de Flats.

- MF me pregunta cómo se tratan los BadPixels en la sky_subtraction ? TODO !!!

Respuesta JM:

Los pixeles malos(BP) se comportan de la siguiente manera:

  a) en la primera iteracion de sky_subtraction (sin mascara de objetos):
  
     - los pixeles malos de dejan con el valor del background medio (moda) de
     dicha imagen
  
  b) en la segunda iteracion de sky_subtraction (con máscara de objetos):
  
      - los pixeles malos o enmascarados por SExtractor como objeto, se les
      deja su propio valor, es decir, no se modifican.
     

- MF me pregunta si he cambiado algo en PAPI desde la reducción de sus datos en Febrero. Le digo
que tengo que mirarlo en los logs, pero que lo que puede que haya cambiado es el fichero de configuración !!!

- TODO: implementar en PAPI algo para hacer una copia del fichero de configuración usado en cada reducción,
quizás incluirlo en el logfile !!! - DONE !




DOUBTS FOR MATILDE (next)
================================

- la raw_photometry() sólo esta disponible para los filtros de 2MASS (J, H, Ks), 
pero, ¿ se podría hacer otra aproximación con los filtro que vaya a tener PANIC ??

- ¿ que valor usar para la normalización ? y tenía la moda, pero he visto
que me puede dar problemas (filtro z), y en HAWK-I usan la mediana.
Lo he cambiado todo par ausar la mediana.

- Reference pixel, ¿ algún tratamiento ? de momento descarto.
  (ver como "quitar" los "Reference pixel"  en (http://bit.ly/YP5heF))
  Implementado !! en refPixelCorrection.py, pero pendiente revisar resultados.


- Me surge la duda sobre si para los Master TwLight flats es imprescindible
un dark model o bastaría con un simple master_dark ?? Ahora mismo sólo
se calculan con un master_dark_model.

- New module for mix dome & sky FF : calCombineFF()
- show MF PAPI CL interface:

> papi.py -s /data/O2K/2012-Matilde/20120103/ -g filter -p
> papi.py -s /data/O2K/2012-Matilde/20120103/ -S 15  -g filter 
> photometry.py -i /tmp/reduced_SEQ.fits -z 26.821570
> aladin /tmp/reduced_SEQ.fits /tmp/reduced_SEQ.xml
> papi.py -s /data/O2K/Matilde/120105/ -S 0  -g filter -R lemon
> cp /data/out/mDark_EXRfly.fits /data/calibs/mDark_serie.fits
> papi.py -s /data/O2K/Matilde/120105/ -S 4  -g filter -R lemon -D /data/calibs/mDark_serie.fits
> papi.py -s /data/O2K/Matilde/120105/ -S 28 -g filter -R lemon -D /data/calibs/mDark_serie.fits -F /data/calibs/mTwFlat_J.fits 



TODO's for Clemens
==================
  - Observo algo que parece una condición de carrera, y es que alguna vez puede ocurrir que aunque
  el chequeo del FITS sea correcto, GEIRS no haya aún añadido las keywords que le da el OT y entonces
  el QL no detecte bien el fichero pues no puede leer dichas keywords esenciales.
  Esto creo que no ocurre cuando usamos los modos 'file' el datacollector.
  

- comando para añadir cualquier keyword al header
- WCS correcto en los headers, actualmente tiene
TYPE1  = 'PIXEL'
CTYPE2  = 'PIXEL'
CRPIX1  =                  1.0
CRPIX2  =                  1.0
CRVAL1  =                  1.0
CRVAL2  =                  1.0
CDELT1  =                  1.0
CDELT2  =                  1.0

- bug en la salida del comando median cuando se envia desde el OT con snd_panic_new, que ahora sólo devuleve OK


FAQ:
===
1) ¿ para que se usa en PAPI los gainmap ? 
   - skyfilter
   - dithercubemean

DEPENDENCIAS DE IRDR
====================
- skyfilter
- dithercubemean
- offsets


DUDAS OT
========
- ¿ en un OB solo puede haber un calibration_series ?
- en la pantalla de Telescope-Iterator, por que el valor de Cycles=5 cuando creas un patron cualquiera ? 
(parace que es el valor que pone por defecto en Cycles en "Single Exposure")
Yo pondría por defecto 1 cycle


ASTROMETRIA con Astrometry.net 
==============================

Varias formas de hacer astrometría:

1)IRAF: user-friendly!

2)Aladin: interactivo

3)Astrometry.net: completamente automático

Astrometry.net
--------------
(http://astrometry.net)

- Devuelve la astrometría en el WCS

- Nunca da falsos positivos 
    (quizás falso negativos)

- Tanto con imágenes fits como con tablas de SEXtractor

- Capaz de trabajar sin ninguna indicación
     > solve-field images.fits

- Necesita “licencia”

- Está en desarrollo

Requisitos:
----------
  * gcc
  * cairo
  * netpbm
  * libpng
  * libjpeg
  * python (probablemente ≥ 2.4)
  * numpy
  
Resultado
---------
   <base>-ngc.png : an annotation of the image.
   <base>.wcs : a FITS WCS header for the solution.
   <base>.new : a new FITS file containing the WCS header.
   <base>-objs.png  : a plot of the sources (stars) we extracted from the image.
   <base>-indx.png  : sources (red), plus stars from the index (green), plus the skymark ("quad") used to solve the image.
   <base>-indx.xyls : a FITS BINTABLE with the pixel locations of stars from the index.
   <base>.rdls : a FITS BINTABLE with the RA, Dec of sources we extracted from the image.
   <base>.axy : a FITS BINTABLE of the sources we extracted, plus headers that describe the job (how the image is going to be                               solved).
   <base>.solved : exists and contains (binary) 1 if the field solved.
   <base>.match : a FITS BINTABLE describing the quad match that solved the image.
   <base>.kmz : (optional) KMZ file for Google Sky-in-Earth. 
   
Trucos
------
- Darle la escala de la imagen:
    > solve-field  image.fits --scale-units degwith --scale-low 1 --scale-high 2
    > solve-field  image.fits --scale-units arcsecperpix --scale-low 0.3 --scale-high 0.4
 
- Darle la posicion aproximada y radio en grados (o en hh:mm:ss y dd:mm:ss)
    > solve-field  image.fits --ra 20 --dec –85 --radius 2

- Que no pinte las plots 
    > solve-field  image.fits --no-plots

- Utilizar tabla de SEXtractor
    Configurar SEXtractor          
        CATALOG_TYPE        FITS_1.0
        CATALOG_NAME    tabla.xyls
        PARAMETERS_NAME xylist.param (X_IMAGE, Y_IMAGE, MAG_ISO

    > solve-field  tabla.xyls --x-column X_IMAGE --y-column Y_IMAGE  sort-ascending --sort-column MAG_ISO --width 2000 --height 1500

PIPELINE
---------
1-Obtengo la tabla con SEXtractor.

2-Lanzo Astrometry. Utilizo la posición aproximada que esta en la cabecera.

3-Utilizo las ftools para incluir las WCS en la imagen de BUSCA.

4-Nueva tabla de SEXtractor con la astrometría corregida.

5-Utilizo Aladin para comparar con los catálogos USNO-B1 y 2MASS

6-Hago la estadística usando IDL

7-Incluyo la estadística en la cabecera de la imagen con las ftools

 
NEXT TODOs
==========
- eliminar del todo RS::self.out_file
- crear "bateria" de tests para lanzar de forma automatica con un conjunto de
datos fijo (Ok2, PANIC, HAWK-I) de forma que se prueben "todas" los modulos de PAPI !!!

- ver como "quitar" los "Reference pixel"  (http://bit.ly/YP5heF)
- ver las diferencias entre calBPM.py y calBPM_2.py (este último es el que se 
esta usando)
- implementar main() en remove_cosmics.py
- usar fit.polyfitr() en photometry 
- ver notas libreta sobre si se reduce o no HAWK-I-4
- ver notas libreta sobre si se reduce o no HAWK-I-5; 
en el portatil lo hace, pero el resultado no es muy bueno, 
incluso la astrometria no parece funcionar

- escribir al Chino sobre el dxtalk.py --> probar su sugerencia !!
- graficos SCAMP de distorsion !!!

BUGS QL
=======
- Si selecionamos varios science con distinto filtro y le decimos "reduce",
no lo hace pero no dice el porqué !
- checkQuality usa la variable TERAPIX !!
