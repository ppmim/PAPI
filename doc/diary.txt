PAPI DEVELOPER DIARY
====================

2011-10-24
----------


2011-10-25
----------
- Implemented in cube.c the next sky models:

     cube_median_min ( N )
     cube_mean_min ( N )
     cube_mean_min_w ( N )  weighted

 and modified the skyfilter.c routine in order to accept a new (optional)
 parameter 'skymodel' for the skyfiltering stage. The current accepted values
 for skymodel are:
     
     median : median/mean skymodel (normal or sparse fields)
     min : minimal sky model (for crowded fields)


- Al reducir la el DS de 13-Julio-2011-Matilde de O2k en el filtro Z
  (18:25:15+00:10:15) de 5 imágenes, observo que hay una reflejo que parece
  originado fuera del campo; le pregunto a Matilde, y buscando en 
http://archive.stsci.edu/cgi-bin/dss_form comprobamos que se debe a una
  estrella muy brillante que hay cerca del campo, y aunque no cae en el
  detector, lo que estamos viendo probablemente sean los arcos de difracción
  que genera la luz de la estrella en la óptica del telescopio/instrumento y
  que son vistos por el detector.
  
  Según Matilde, a priori, no sabe o no cree que eso se pueda eliminar
  facilmente, así que no habrá que preocuparse de momento por eso. 

  De todas formas, yo creo que con los skyflats(superflats) debería de haberse
  eliminado, no ?? pues están observando la misma zona del cielo...pero noooo,
  pues están cayendo sobre distintos píxeles, por lo que no hay nada que
  hacer, no ?? de todas formas tendría que ver si con alguna técnica de
  fringing removal se podría hacer algo ....

- Modificado genLogsheet para que pueda mostrar un subconjuto de filas y que
  además se pueda omitir la cabecera; todo esto con el objetivo de poder crear
  ficheros que puedan leer datasimy.py y createSeq.py



2011-10-26
----------

- Me suscribo a 3 listas de python, una de ellas en español ! para intentar
  estar un poco más actualizado del mundo Python. 

- Me pongo a buscar el bug que encontré al ejecutar el Test#23;
  Encotrado BUG sintáctico, estaba en ClFits.isScience()
 
- Me encuentro con otro/s bug/s a la hora de agrupar los datos:

     1) los master creados tienen un PAT_NEXP != N, y PAT_EXPN=1, con lo cual
     son confundidos/mezclados con los datos agrupados, provocando además que
     se queden fuera algunos ficheros que tendrían que ser agrupados.
     Para solucionar esto hago lo siguiente:

     	  - modifico las rutinas de creación de master para que actualicen el
                 valor de PAT_NEXP=1
	  - modifico en dataset.GetSeqFilesB() para que no tenga en cuenta a
                 la hora de agrupar los ficheros de tipo MASTER_XXXXX
		      

     2) En las rutinas de creación de masters, no se actualiza la keyword
     IMAGETYP, con lo cual PAPITYPE dice una cosa y IMAGETYP dice otro. Aunque
     PAPITYPE tiene prioridad, lo arreglo para que ambas digan lo mismo,
     aunque lo correcto sería eliminar IMAGETYP....

  
- Me surge la duda siguiente: ¿ qué debe tener más prioridad, un master dado
  de forma externa o uno creado por el propio pipeline como resultado de la
  reducción de la secuencia correspondiente ?
  Yo creo que debería tener prioridad el que reciba de forma externa ...pero
  tampoco lo tengo muy claro. Ahora el problema está en como implementar esa
  prioridad ....
  Se me ocurre, que vamos a tomar aquel que sea más reciente, mirando para
  ello la MJD --> usando el índice -1 de Python es sencillo.
  Para ello modifico RS.getCalibFor() de forma que devuelva el último elemento
  de la lista de master encontrados, que se supone será el más reciente.

- Modificación en el QL para que si no se ha activado la checkBox del outDir,
  se añadan las salidas generadas durante el procesamiento de los distintos
  datasets, básicamente para posibilitar que un science-DS pueda usar los
  master de calibración que hayan podido encontrarse y creado anteriormente.
  Para ello se modificó : MainGUI::checkLastTask()

- 
 
- Realizo los test #23-#30; destaco el test 30 que incluye a datos según el
  formato de GEIRS, que tienen que ser "convertidos" a 4 x (simple FITS) que
  puedan luego ser procesados por PAPI. Parece que de momento la cosa va bien,
  aunque aún queda por comprobar con datos reales si la astrometría de las
  nuevas imágenes creadas al partir el fichero original de GEIRS es correcta o
  no....

2011-10-27
----------


- Ejecutando el test #31, que fue bien, me doy cuenta de que por ejemplo, si
  para reducir una secuencia necesita alguna calibración con MJD posterior, la
  ordenación y ejecución de la reducción de secuencias no funcionaria, pues no
  la habría reducido todavía cuando es necesitada por una secuencia en
  cuestión. Es decir, sin en el test #31, los darks son posteriores a los
  twflats, da un ERROR diciendo que no encuentra el master dark necesario y
  que por tanto no puede crear el master TWFlat.

  Una posible solución que se me ocurre: que la ordenación de secuencias a
  procesar siga el criterio siguiente:

  	   	1- ordenar por MJD
		2- ordenar por DARK, DOME_FLATS, TW_FLATS, SCIENCE

  Para implementar esta solución añadi la funcion RS:reorder_sequences(), que
  hace justamente eso. La probé con el test #32 y funcionó correctamente. No
  obstante, llamo a esta función de reordenación a la hora de la reducción del
  RS, pero no cuando se muestra en la consola las Seqs encuentradas, más que
  nada para poder verlas ordenadas temporalmente.

  Obviamente, esto no es válido para el QL, pues en el QL se reducen las
  imágenes según van llegando...aunque pensandolo bien, también se podría usar
  cuando el usuario selecciona manualmente una sequencia de SCI y quiere que
  esté disponibles las calibraciones posteriores. Pero pensandolo mejor, es
  preferible que el usuario tenga que marcar/seleccionar todos aquellos
  ficheros que quiera tener en cuenta para la reducción o bien, indique
  explicitamente qué masterDark,masterFlat quiere usar.

- A raiz del tema de la ordenación de las sequencias y los problemas que puede
  dar en el QL si para reducir un SkyFlat no se han reducido aún los dark
  correspondientes, hago una modificación en QL para que avise también cuando
  no pueda reducir una secuencia, pues hasta ahora sólo avisava por la
  consola; ahora también muestra el mensaje en el Log de la GUI.
  Esto se puede probar con el test #32.


 
2011-11-02
----------

- Instalación de MV con openSuSE-11.1-64bit. Me dió bastantes problemas,
  entre:
	* primero de todo, al intentar instalar un SO guest de 64 bit,
  VirtualBox me avisa que tengo que habilitar en el BIOS del host principal el
  modo VT-x/AMD-v; no lo encontré en mi bios (DELL 390), pero había algo de
  virtualización y lo activé. A partir de ahí, VB me dejó instalar el SO 64bit.
	* me avisa de que el display del host es de 32 bit, pero que el guest
  está configurado con 16 bit--> eso no pasa nada, simplemente que para
  mejorar las prestaciones gráficas hay que instalar las GuestAdditions.
  	* Se me quedaba colgado al inicio de la instalación, y no sabía de qué
  podia ser; en un principio pensaba que era debido al mensaje de los 32/16
  bits del display, así que probé en modo texto (y seguia dicho mensaje), y
  fué cuando me di cuenta de que daba un error por el famoso ACPI. Para
  intentar solucionar esto desactivé en la definición de la máquina virtual la
  opción de ACPI. Con esto, ya me dejó instalar sin problemas.
  	* bueno, también se me quedó un par de veces colgada la instalación
por que no podía leer el DVD (incluso tampoco lo podia leer elwindowsXP), 
así que limpié varias veces el DVD hasta que volvió a leerlo sin problemas 
y pude instalar el openSuSE11.164bit.


 
- Implementación de apply_dark_flat=2
- Encontrado problema al ejecutar calTwFlat.py

2011-11-03
----------

- Encontrado y solucionado bug en calTwFlat.py --> el problema estaba en el
  parámetro input del mscred.flatcombine() que no estaba bien formado por el
  tema de la barra doble "//" que no acepta IRAF en los pathnames.

- Tras implementar el modo apply_dark_flat=2, hice las pruebas
  correspondientes y me dí cuenta de que tenía un error a la hora de crear el
  fichero stack1.pap en la llamada a coaddStackImages(). Tras solucinar dicho
  bug, todo parecía ir bien, aunque el test con datos de ALHAMBRA demostró que
  el FF después del skysubtraction (apply_dark_flat=2) es "como" (o sin el
  como) deshacer el skysubtraction, cosa que ya había comprobado en día
  anteriores y que coincide con lo que me decía Wei-Hao (SIMPLE).
  Por eso, realmente no le veo sentido a implementar dicho modo
  (apply_dark_flat=2), pero bueno, por si acaso...ya está implementado.

- Repito el test anterior (#32) con red_mode='science'


2011-11-04
==========

- Termino de instalar todo el software de PAPI en la Maquina Virtual (MV) de
  openSuSE que he creado eleborar el documento de instalación. 
  Al instalar la VBoxAdditions, me da un aviso de que parace que ya están
  instaladas en el SO guest, y que es mejor que no las re-instale, pero como
  tengo algunos problemas con el ratón y no tengo el FS para el mount.vboxfs
  para poder compartir carpetas con entre el host y el guest, pues no hago
  caso al aviso y dedido instalarlas. Después de un rato, re-compilando
  algunos módulos para el kernel y tal, pues todo parece terminar bien y
  funcionar correctamente. Veremos ....:-D

- Consigo finalmente instalar el binario (64bit) de SCAMPv1.7 y su dichosa
  dependencia de la libraria libplplot9; finalmente encuentro el RPM
  libplplot9-5.7.1-1.2.x86_64.rpm que se instala sin problemas.

2011-11-07
==========

- Videoconf PANIC: en cuanto al SW, aunque AGS dice que no está preparado y
  que prefiere postponer el viaje, JF insiste y dice que no se puede mover,
  así que finalmente iremos en el semana 47 como estaba previsto.
    

- Muevo el RS::reorder_sequences() al método  RS::getSequences  
  y ahora reoder_sequences() sólo se ejecuta si queremos reducir todo el DS,
  pero si hemos especificado una secuencia específica, no se reordenan pues no
  hace falta; con esto nos evitamos el problema de la altereación del número
  de secuencia mostrado según el ordernamiento MJD y el que le correspondería
  según el ordenamiento DARK, FLAT, SCIENCE, etc que hacer reorder_sequences.
  
  Es decir, NO hay problema de identificación del número de secuencia al
  especificar una secuencia a reducir en lugar de todo el DS.



2011-11-09
==========
- Defino algunos test para empezar las pruebas con AGS

- Asisto reunión convocada por Julio sobre HEXA

- Repito el test 18 con el Set HAWK-I-5, y obtengo un stitch final muy mal;
  miro los cuandrantes individiales Q0N y ninguno tiene la astrometría bien.
  Depurando, me doy cuenta de que SCAMP se queja (linea roja), y por eso no
  hace bien la astrometría con GSC-2.3.
  Cambio a 2MASS, y ahora la astrometría es buena !!! por qué ?? será que
  habré cambiado algún parámetro (NSIG en skyfilter, DETECT_THRESH, ...) ?
  La imagen final de los cuatro cuadrantes (stiched) está más o menos bien,
  con poca marca de la noise-cross-shape central.

- Inicio de pruebas integración OT-QL:


  
2011-11-10
==========

- Continuo pruebas de QL y depurando.
- Implemento eval_focus_serie.py, que basandose en checkQuality.py, calcula el
  mejor foco de una serie de foco. Lo pruebo con el ejemplo  de O2k que me
  pasó Ulli y funciona bien !!! Para el caso de PANIC, debería funcionar
  también sobre las imágnes 4kx4k, a pesar de la cruceta, pues SExtractor es
  robusto a eso...lo mejor sería simularlo y probarlo. 

- Por la tarde, hacemos algunas pruebas AGS y yo con el OT y el QL (ver
  documento manuscrito). Encontramos varios BUGS tanto en OT como QL.
  
  En OT: básicamente que no enumera bien las secuencias con el instrument
  iterator
  En QL: que no avisa de que un conjunto de ficheros no tiene ninguna
  secuencia, dando una exception "TypeError". (lo solucioné al día siguiente).

 


2011-11-11
==========

- Encuetro el bug del día anterior.
- Encuentro otro bug en eval_focus_serie, pues en los nuevos ficheros de PANIC
  el kw de foco telescopio se llama T_FOCUS en lugar de T-FOCUS. Modifico
  convenientemente la rutina.

- Comienzo diseño de DEMO PAPI/QL (papi_demo.txt)

- Tarde: AGS y yo continuamos con las pruebas de OT-QL:

  Basicamente hicimos un recorrido por el documento "WhatWeNeed.doc" de JF, y
  los principales fallos/problemas encontrados fueron:

      1) domeflats no tiene el orden on/off correcto, pues mezcla con los
      filtros. Lo correcto para una secuencia de 1-N sería
      on-on-on-off-off-off y seguir con el siguiente filtro.

      2) skyflats : no los podemos probar, pues no los tiene completamente
      implementados, pues el OT no tiene simulado el incremento artificial del
      número de cuentas.

      3) focur series: no implementado en OT, pero le doy el .prg y la idea de
      cómo hay que hacerlo. Intentará implementarlo para HD.

      4) simple exposure: no funciona ese caso particular

      5) nodding pattern: no implementado, pero le paso el sky_pointing.prg y
      cómo lo podría implementar. No cree que pueda tenerlo para HD.

      6) Pause: no está en OT, pero cree que lo podrá implementar, no es muy
      dificil.

  En cuanto al QL, no encontré errores, sólo lo siguientes comentarios:

      1) ver que nodding pattern puede contemplar PAPI ( y el OT) según las
      sugerencias de Ulli.

      2) ver que hace el QL/PAPI cuando encuentra dos PAT_EXPN=1 en una
      secuencia ????


2011-11-14
==========

- Pruebas O2k objetos extenso, secuencia T-S-T-T-S-T-T-....(NGC5866). 
  Encuentro&Soluciono BUG en skyfilter_general, en la funcion que lee el IMAGETYP, pues
  no contenplaba bien los NULL.

- Reduciendo la serie anterior, SExtractor da el mensaje :


WARNING: Pixel stack overflow at position 


que según E.Bertin es debido a :

"""
Hi.
Given the fairly large size of your image, different memory settings (and/or aperture settings) can lead to a different number of sources. This may seem like a bug but it isn't (in principle!). The reason is that the SExtractor engine was originally written at a time when computer memory was scarse (a good workstation had ~16MB of memory back then, and SExtractor was meant to work with 1.8 GB Schmidt plate scans). Hence memory usage had to be kept under strict control, which explains the buffer limit settings. These limits may be reached if your image is populated with many and/or very large objects and/or if some measurements require large apertures. In that case, SExtractor has to make choices: change the order in which objects are extracted and/or measured, change details about the cleaning of spurious sources around bright sources, and, for the most critical cases, give up on extracting and/or deblending and/or measuring objects. Obviously, decisions of statistical significance are accompanied by a 
proper flagging of the detections involved (see the SExtractor documentation). Most of the time, this will concern bright, saturated stars or large image artifacts (halos, bad columns, satellite trails, etc.). It may however affect "normal" sources if inappropriate detection parameters are used: exceedingly low detection thresholds and/or unsuitable background mapping parameters (the detection algorithm has to percolate through the background noise and deblend large "empty" areas), exceedly high deblending contrast in very crowded fields...
In suspicious cases, I would recommend checking SEGMENTATION check-images and
source FLAGS to verify that SExtractor is operating in the intended regime.

"""

Ese mismo warning ya lo he visto en otras ocasiones, pero nunca le he hecho
caso. Habría que ver como afecta a la reducción....



- DUDA en eval_focus_serie.py habría que ordenar los frames por MJD
  antes de evaluarlos ???
  Realmente el orden va a dar igual, pues para el ajuste no afecta para nada.

- DUDA a resolver : en eval_focus_serie.py habría que hacerles algún tipo de
  procesamiento (Dark, Flat, Sky....) antes de evaluar el FWHM ?
  Pues en teoria se obtendrían mejores resultados...habría que hacer algunas
  pruebas.

- BUG resuelto: faltaba en db.getFilterFiles() en el primer select un "order
  by MJD"

- Pruebas OT-QL:

  * domeflat : sigue el problema de la numeración de secuencias
  * single exposure + telescope interator : no contemplado
  * single exposute + cycles = 2 : no enumera bien las secuencias
  * skyflats : no terminados de implementar
  

2011-11-15
==========

- Añadido nuevo tipo de agrupamiento --> "none" , que hace que no se agrupe y
  que simplemente considere todos los ficheros como pertenecientes a un mismo
  grupo.

- Añadida al config file skysub.skymodel y modificada la función
  RS::skyfilter() para que admita dicho parámetro.
  
- Hago el primer esquema del proceso de reducción de PAPI; queda pasarlo a
  limpio.

2011-11-16
==========

- Bug resuelto en QL: había un bug en la creación del QTimer cuando se
  especifica un directorio a "monitorizar" que afectaba a mainGUI.py

2011-11-20 al 25
================

- Pruebas SW de integración en HD. (ver documentos de notas)
 
2011-11-29
==========
- Inicio funcion read_GEIRS_fitsLog() para mejorar la lectura de los ficheros de
log de GEIRS, tanto

    * ~/GEIRS/log/save_CA2.2m.log
    * ~/tmp/fitsfiles.corrected
    
2011-12-12
==========

- Teleconf PANIC: JF me comenta que no tiene inconveniente en enviarme la carta
de consentimiento para la ayuda de movilidad, pero me pregunta que fechas tendría
previsto para ir. Yo lo contesto que en principio Verano, pero que aún o se cuando
estaría el dinero y tal. JF piensa que es muy tarde, pues el piensa en poder 
hacer algo para GEIRS.
Y sobre el SW, pues que el OT le parece demasiado complicado, y que quizás sería
mejor hablar con CA (Ana Guijarro). 
También comenta que van a contratar una persona para que ayude a CS con el SW.

- Recibo llamada de Jens para hablarme del nuevo CCD-SW para Twin. Por lo visto
el software de bajo nivel lo harían en HD, a modo de librería similar a la que 
hicieron para CAFOS-upgrade, y la GUI sería para hacerla nosotros, más la GUI
de control del instrumento Twin, para sincronizar las dos CCDs etc ...
Le digo a Jens que tenemos que consularlo con Matilde & Julio.


- Modifico QL para que se pueda seleccionar desde el botón Input/Source dir tanto
un directorio como los ficheros de log de GEIRS (save_CA2.2mlog y fitsfiles.corrected).
Tengo que probar bien si funcionar en cualquier versión de SuSE, pues me pareció 
que en el portatil no funcionaba bien.


2011-12-13
==========

- Pruebo el qphot de forma interactiva para ir seleccionando y visualizando los
valores fotometrícos de los objetos en la imagen reducida y aunque al principio
me costó entender el manejo, luego es muy potente y útil. Además, si tenemos 
activado el radplot=yes, es muy interesante. Podemos decirle además el ZPOINT
que queremos que use para el cálculo de la fotometría.


2011-12-14
==========

- Implemento rutina 'plot_cpu_mem_stats.py' para sacar las gráficas de CPU y 
memoria de los test hechos en Heidelberg.

- Instalo sphinx + pygments (con easy_install) para empezar a documentar PAPI

- Comienzo con primeras pruebas.


2011-12-15
==========

- Continuo probando Sphinx, pues parece muy interesante para usar en la documentación
de PAPI. Sin embargo, de cara a documentar el codigo fuente (python) de PAPI
me encuentro con el problema de que hasta ahora el codigo fuente de PAPI lo 
estaba documentando en las docstring siguiendo la sintaxis de epytext/javadoc, 
pero resulta que Sphinx usa las docstring del formato reST(reStructuredText);
según he buscado en google, no parece que haya una forma fácil para pasar de
epytext a reST.

La sintaxis de reST para las docstring de python es la siguiente:
 
 -http://epydoc.sourceforge.net/manual-fields.html#epydoc-fields

 -http://mundogeek.net/archivos/2008/07/07/documentacion-en-python/#more-1582


También me doy cuenta de que en las docstrings del codigo python no podemos usar
todos los metatags de reST, pues al importar los modulos en sphinx se queja;sin
embargo, veo que la documentación de Numpy si los usa, pero para ello hay que 
instalar una extensión a sphinx propia de Numpy para que se genera la documentación
como en Numpy ( ver  https://github.com/numpy/numpy/tree/master/doc/sphinxext)

2012-01-09
==========
- Incorporación después de vacaciones !
- Matilde me dice que han estado observando con O2k para su proyecto. Quedamos
en que me bajaré los datos y iré mirando como reducirlos, al menos hasta la
sustracción de cielo, pues a partir de ahí continuará LEMON.


2012-01-10
==========
- Comienzo la implementación para que PAPI se detenga en después de la sustracción
de cielo y devuelta la lista de ficheros pre-reducidos para pasarle a LEMON.

- En las primeras pruebas de la reducción de datos de Matilde, me doy con 
problemas como:

    1) Hay un objeto extenso (nebulosa) y no han observado en modo "T-S-T-S-...",
    por lo que PAPI no puede reducir bien las imágenes por la nebulosa.
    1) las secuencias de Ks tiene dos iteraciones sobre un patrón de dithering
    de 5 posiciones, con lo cual el algorimo estimación de cielo no funciona 
    bien y hace sobrecorrección.
    2) los parametros del calculo del gainmap son muy severos (0.7,13), por lo
    que los relajo a (0.5, 1.5)
    
- Hablo con Matilde de estos primeros problemas y me dice que no me preocupe, 
que primero ella estudiará cual es le mejor método para la sustracción de cielo.

2012-02-22
==========
- Modificación en applyDarkFlat, calTwFlat y ReductionSet para usar 
MASTER_DARK_MODEL de forma que se pueda escalar correctamente, pues como se hacia
antes con un MASTER_DARK normal, no estaba bien, pues se estaba escalando también
el BIAS intrinseco de los DARK.

- Modifico también la rutina calDarkModel para que se grabe en el header alguna
información mas sobre el DARK_MODEL.

2012-02-24
==========

- Implementacion metodo dxtalk.py (O2k y PANIC)

2012-02-25
==========

- Lanzamiento de PAPI (modo lemon) con todos los datos de Matilde de 
O2k (Enero-Febrero 2012)

2012-02-27
==========
- Revision resultados reducción de PAPI
- Implementacion de nueva opcion en PAPI para que permita usar ficheros de
calibracion maestros (master dark, flat ...) de un repositorio (directorio)
externo, de forma que si al reducir un DS no dispone de los correspondiente masters,
pueda usar los que haya en dicho repositorio.


2012-02-28
==========
- Dudas sobre los valores obtenidos en el dark model. Pregunto a Clemens, Vianak 
y Rene Fassbinder sobre el tema para ver si me sacan de la duda.


2012-03-02
==========
- Rene Fassbinder me responde aclarandome finalmente donde estaba mi error con 
la estimación de dark model medio---> El valor de MEAN no es significativo !!!!
Está "contaminado" por los hot-pixels !!! 
De todas formas, el método de dark-model y la sustracción de dark correspondiente
hecha en las imágenes de Matilde creo que están bien !


2012-03-05
==========
- Estudio para ver como mejorar el dxtalk.py de forma que tenga en cuenta los 
outliers y estrellas brillantes al calcular la mediana.
Encuentro interesante el método : Standard Deviation Mask que trae Maxim/DL.

- Encontrado en http://www.astro.yale.edu/dokkum/lacosmic/ código Python para 
eliminar Cosmic-Rays (CR) de imágenes basado en http://arxiv.org/abs/astro-ph/0108003 
Lo pruebo con imágenes de O2k y parece que va bien, aunque tarda 2'20''.
Los CR en principio se "resuelven" en el IR al hacer el combine del stack, pero
en el modo Lemon quizás sea interesante tenerlo ????

2012-03-06
==========
- Continuo con el estudio y pruebas de rutina alternativa para iraf.imcombine,
pero sin éxito.

- Escribo en las listas de AstroPy y NumPy para pregunar acerca del tema.
Objengo respuestas, diciendo que el paquete stsci contempla dicha rutina, pero 
hay que instalar PyRAF !!!! entonces estamos en la misma. No obstante podría
ser un punto de partida para mi implementación.

  
2012-03-08
==========
- Modificación en PAPI para que detecte secuencia de Dark para DarkModel o 
Master dark tradicional. Esto implicó modificar un poco la funcion RS.checkData().

2012-03-09
==========
- Implementada nueva funcionalidad a QL para restar los 2 últimos SCI-frames
recibidos, mejor dicho, los 2 más nuevos (MJD) --> pushB_subtract_last2_slot()

- Añado opción remove_cosmic_ray al fichero de configuración 

2012-03-10
==========


2012-03-14
==========

- Videoconf: le envio las siguientes notas:

"""
-PAPI+LEMON reduced ~7000 O2k images (Z,J,H,Ks) of Matilde's project 
-PAPI : dark, flat, sky-subtraction and de-crosstalk (also ready for PANIC) - 
- LEMON: time series analysis - Photometric precision up to 0.015mag (constant star) 
  Attached figure: preliminary V and Ks band lightcurves of one star of the sample for which there is an shift between a visible and a near-infrared minimun. 
- Added to PANIC a module for cosmic rays removal (based on P. van Dokkum's L.A.Cosmic algorithm, http://www.astro.yale.edu/dokkum/lacosmic/) 
- Improvement in master dark model computation 

About the OT, no news; Antonio is in vacation. 
"""

Sale nuevamente el tema de los problemas de memoria en GEIRS, en los que está
aún trabajando CS, y que cree que son problemas en el kernel, pero que espera
poder resolverlos pronto.

2012-03-27
==========

 - Modificación en calDomeFlat, calTwFlat, calSuperFlat para solucionar/mejorar
 la normalization wrt chip 1, además de mejoras varias y documentacion en codigo
 - Encuentro el metodo (trick) para usar dome+sky flat de forma que aprovechemos
 las propiedades de ambos:
 
"""
A trick to combine domeFF and skyFF :

Often for a run you have dome flats with an accumulated number of
electrons in the millions, but a poor match in illumination and color to the dark
sky. You also have a limited number of twilight flats or dark-sky images that can
be combined to make a dark-sky flat, but the total counts per pixel in either set of
flats is not very high. A fairly standard procedure is to “median-smooth” dome
and twilight or dark-sky flat. A median smoothing replaces each pixel with the
median of the pixel values in a box of a given size on a side. The result is an image
that has been smoothed on the scale of the smoothing box size.
A procedure for taking advantage of the facts that the large-scale flat-field
variation of the dark-sky flat match that of the program frames and the dome flats
have very high S/N in each pixel goes as follows:
 
 (a) Median smooth the combined, dark-sky flat — this improves the S/N and
preserves the large-scale features of the flat.
 (b) Median smooth the combined dome flats using the same filter size as was
used for the dark-sky flat.
 (c) Divide the combined dome flat by it’s median smoothed-version. The result is
a frame that is flat on large scales but contains all the high spatial frequency
flat-field information.
 (d) Now multiply the smoothed dark-sky frame and the result of the division in
the previous step. You now have a flat-field with the low spatial frequency
properties of the dark-sky flat combined with the high S/N, high spatial
frequency properties of the dome flat.
"""

2012-03-28
==========
 - Modificación en calGainMap para hacer (opcionalmente) la normalization wrt 
 chip 1 para el caso de imágenes full-frame de PANIC (como las saca GEIRS).
 Aunque en principio la normalizacion ( si hay varios detectores, wrt chip1), 
 puede ser realizada al crear los master-flat, tambien está la opción de hacerla
 en calGainMap.
 Si por "error" se hicese en los dos casos (master flat y gainmap), no creo que 
 pasase nada. 
 
 - Una vez más me surge la duda de si aplicar el FF y luego usar el GM (gainmap)
 puede ser redundante y/o contraproducente. Después de ver donde se usa el GM
 en PAPI:
    1) skyfilter :
        1.a) como BPM
        1.b) crear el wmap (NCOMBINE*INT_TIME*gainmap*ImageVariance) 
        cuando usamos cube_mean() con mascara de objetos
        1.c) procedimiento IRDR::destripe() que no usamos de momento en PAPI
    2) dithercubemean:
        2.a) de nuevo, al crear el wmap, y en cube_mean()
 
 llego a la conclusión de que el gainmap es "cte" para todas la imagenes de un
 stack de dithering, y por tanto no debe ser determinante.
 Además, revisando la documentacion "IRDR Users Guide" veo que hacen igual,
 aplican FF, generan GM con el FF y luego usan el GM en skyfilter y dithercubemean.
 Por tanto, de momento podemos dejarlo así.
 
 - Encuentro un BUG(?) en mean.c, pues MINCLIP estaba a 1.5 en lugar de 5, que
 es el valor original. Debe ser que alguna de mis pruebas con el NSIG del
 cube.c, me confundí y modifiqué erroneamente el MINCLIP. 

 

2012-03-29
==========

 - Añadida option de 'median_smooth' a los FF (dome,tw,sky)
 - Implementado modulo para combinar domeFF y skyFF --> calCombineFF.py
 

2012-03-30
==========

  - Pruebas de los procedimientos modificados el día anterior, procurando que 
pase por todos los casos posibles.

  - Estudio de los modos de autenticacion de subversion 

2012-05-09
==========
   - Videoconf: no pude asistir por subir al OSN a instalar la CCD Excelon 
   en Albireo.
   Parace ser que lo unico destacable respecto al SW fue que JF pregunto para
   cuando la segunda integracion del SW.
   

2012-05-10
==========

   - Comienzo migracion de pprocess a multithreading (python >2.7)
   - Encuentro un problema pues lo metodos de clases no los soporta
   directamente Pool.apply_async(), hay que hacerlos "picklable".

2012-05-11
==========
   - Encuentro una solucion para el problema anterior:
   http://stackoverflow.com/questions/3288595/multiprocessing-using-pool-map-on-a-function-defined-in-a-class
   
   y parece que funciona. 
   
   
2012-05-12
==========
   - Lanzo PAPI con mutiprocessing.Pool y parece que funciona bien (data set
   de HAWK-I-3).
   
   - Ahora detecto un problema "aleatorio" (no ocurre siempre) en el multiprocessing:
   
   Exception in thread Thread-1 (most likely raised during interpreter shutdown):
Traceback (most recent call last):
  File "/gel/usr/mawal32/system/lib/python2.7/threading.py", line 530, in __bootstrap_inner
  File "/gel/usr/mawal32/system/lib/python2.7/threading.py", line 483, in run
  File "/gel/usr/mawal32/system/lib/python2.7/multiprocessing/pool.py", line 272, in _handle_workers
<type 'exceptions.TypeError'>: 'NoneType' object is not callable
   
y parece que esta reportado el bug, pero no consigo solucionarlo de momento:
   
   http://bugs.python.org/issue9207.

2012-05-14
==========
   - Añado al multiprocessing las llamadas:
   
        pool.close()
        pool.join() 
        
     para intentar solucionar el problema aparecido el dia anterior.
   - Lanzo PAPI varias veces y parece que funciona bien (data set HAWK-I-3).
   - En una de las veces que ejecute PAPI el 15-Mayo si fallo otra vez dando el
   mensaje de arriba (12-May), por lo que parece que con el close()+join()
   no se soluciona.
  
2012-05-15
==========
   - Pruebas en reduceSingleObj() con AstroWarp en el modo "quick":
     
       - con HAWK-I-3, y DETECT_THRESH=4, no es capaz de hacer astrometría ni crear el mosaico;
       con DETECT_THRESH=1.5, hace astrometría mal, y por tanto el mosaico final tambien está
       desformado.
       - con O2k-Matilde-2012-20120105-S-5, si lo hace bien (DETECT_THRESH=1.5)
       
   - Una prueba con O2k-Matilde-2012-20120105-S-6 falló, pues el gainmap era todo BPM !!!! ---> BUG ????
       
   - Reunion con MF para dudas de PAPI (ver comentarios abajo, sección DOUBTS FOR MATILDE)

2012-05-16
==========
    - Compruebo que haciendo :
      
      > aladin /tmp/reduced_SEQ.fits /tmp/reduced_SEQ_zp.xml 
      
      y haciendo click sobre una objeto no muestra los valores de catalogo leido 
      (/tmp/reduced_SEQ_zp.xml) y generado con SExtractor con el MAG_ZEROPOINT 
      calculado previamente con photometry.py
  
    - Le pregunto a VTerron si el ha tenido problemas con multiprocessing, parece
    que no ha tenido problemas; el usa Pool.map_asycn(), asi que voy yo a probar 
    con esa llamada para ver si así se soluciona.
    

2012-05-17y18
=============
    - Implementacion y pruebas del metodo collapse() para sumar cubos; aun pendiente
    la suma de ficheros independientes, pues aunque el suma de ficheros independientes
    esta implementada de momento, aun no se como "agrupar" los ficheros. Le pregunto
    a Clemens si podria usar el FRAMENUM y si me podria añadir algo para saber cuantos
    ficheros tiene una exposición (repeats). Me responde que en la nueva logica de los 
    FITS que tambien necesita Lucifer, y que para septiembre:

"""    
Will come with the new FITS-header-organisation at least until September
(needed also for Lucifer). Please just assume a dummy-keyword name, which you
might replace with  the correct on.
"""
    
    
2012-05-21
==========    
    - Me encuentro un problema a ejecutar PAPI en el portatil (suse11.1-64);
    el problema surge al importar el paquete cosmics, que a su vez importa un
    modulo de scipy que da problemas.
    Para intentar solucinarlo, actualizo numpy1.6.2, scipy0.10.1
    Pruebo la demo de cosmics y ahora ya no da problemas !!!  

   - Otro problema es que en el portatil tengo python2.5, y no tiene el paquete multiprocessing
    por defecto a partir de python2.6, por lo que me bajo el paquete independiente de 
    backport de multiprocessing para python 2.5. Se instala sin problemas y las pruebas de unidad
    se ejecutan sin problema.

2012-05-22
==========    
    - Escribo a Wei-Hao para preguntarle sobre el dxtalk_wircam
     Wei-Hao me responde:
      """
      How about a simple background subtraction in each stripe after
      the subtraction of the median?  Maybe this will solve the problem.
      """
    - Busco en THELI sobre el dxtalk, y aunque aparece en la documentacion no encuentro el código

2012-05-24
==========    
    - Haciendo pruebas con PAPI, me encuentro con el un error aleatorio, pues no siempre ocurre (50%), 
    y tanto con pprocess como con multiprocessing. El error se produce en la llamada iraf.mscred.mscarith(...)
    en calSuperFlat.py. Compruebo que los parametros de llamada de la función están bien; no se por qué puede ser ???
    Este error se produce tanto en openSuSE11.1-i586 (python2.6) como con suse11.4-x64 (python2.7)  

    [PAPI]: 2012-05-24 17:13:00,575 DEBUG    calSuperFlat:222: Normalization of master (O2k?) flat frame. (MODE=2857)
    [PAPI]: 2012-05-24 17:13:00,576 DEBUG    calSuperFlat:226: Normalization parametes---> (tmp1=/data/out/Q02/tmp_sf.fits,result=/data/out/Q02/superFlat.fits)
    [PAPI]: 2012-05-24 17:13:00,632 DEBUG    calSuperFlat:222: Normalization of master (O2k?) flat frame. (MODE=2857)
    [PAPI]: 2012-05-24 17:13:00,633 DEBUG    calSuperFlat:226: Normalization parametes---> (tmp1=/data/out/Q01/tmp_sf.fits,result=/data/out/Q01/superFlat.fits)
Killing IRAF task `delete'
Killing IRAF task `delete'
Exception OSError: (10, 'No child processes') in <bound method Subprocess.__del__ of <Subprocess '/iraf/iraf/bin.linux/x_system.e -c', at 15a6d40>> ignored
Exception OSError: (10, 'No child processes') in <bound method Subprocess.__del__ of <Subprocess '/iraf/iraf/bin.linux/x_system.e -c', at 15a6d40>> ignored
    [PAPI]: 2012-05-24 17:13:03,286 ERROR    reductionset:2085: [reduceSeq] Error while parallel data reduction ! --> Error running IRAF task delete
('IRAF task terminated abnormally\nERROR (601, "Parameter not a legal boolean (try \'yes\' or \'no\') (verify)\x07")\n', 10, 'No child processes')                                                   
    [PAPI]: 2012-05-24 17:13:03,286 ERROR    reductionset:1773: [reduceSet] Cannot reduce sequence : 
 ['/data/i_test/001/dark_seq_ind0072.fits', '/data/i_test/001/dark_seq_ind0073.fits', '/data/i_test/001/dark_seq_ind0074.fits', '/data/i_test/001/dark_seq_ind0075.fits', '/data/i_test/001/dark_seq_ind0076.fits']                                                                                                                                                                                       
 Error running IRAF task delete                                                                                                                                                                      
('IRAF task terminated abnormally\nERROR (601, "Parameter not a legal boolean (try \'yes\' or \'no\') (verify)\x07")\n', 10, 'No child processes')  



    SOLUCION: sustituyo la llamada a iraf.mscred.mscarith por las operaciones correspondientes en python !!!
    

2012-05-25
==========  
  - Elimino el chequeo de los FITS en la funcion mainGUI:new_file_func(), pues ahora es realizado
  en el clfits::recognize(). Lo pruebo y parece que va muy bien.
  Esto servira para todos los modos 'file' & 'dir' del datacollector.
  - Observo algo que parece una condición de carrera, y es que alguna vez puede ocurrir que aunque
  el chequeo del FITS sea correcto, GEIRS no haya aún añadido las keywords que le da el OT y entonces
  el QL no detecte bien el fichero pues no puede leer dichas keywords esenciales.
  
  - Se siguen produciendo errores de PyRAF de vez en cuando !!!!:
    
       [PAPI]: 2012-05-25 13:29:58,295 INFO     calSuperFlat:145: Combining images...(images are scaled to have the same median)
Killing IRAF task `combine'
Exception OSError: (10, 'No child processes') in <bound method Subprocess.__del__ of <Subprocess '/iraf/extern/mscred/bin.linux/x_combine.e -c', at 32692d8>> ignored
    [PAPI]: 2012-05-25 13:29:58,457 INFO     reductionset:2440: ##################################
    [PAPI]: 2012-05-25 13:29:58,457 ERROR    reductionset:2085: [reduceSeq] Error while parallel data reduction ! --> Error running IRAF task combine
('IRAF task terminated abnormally\nERROR (603, "Parameter not a legal number (project)\x07")\n', 10, 'No child processes')                                                                                                   
    [PAPI]: 2012-05-25 13:29:58,458 INFO     reductionset:2441: #### Starting Object Data Reduction #####
    [PAPI]: 2012-05-25 13:29:58,458 ERROR    reductionset:1773: [reduceSet] Cannot reduce sequence : 
 ['/home/panic/data/i_test/001/dark_seq_ind0217.fits', '/home/panic/data/i_test/001/dark_seq_ind0218.fits', '/home/panic/data/i_test/001/dark_seq_ind0219.fits', '/home/panic/data/i_test/001/dark_seq_ind0220.fits', '/home/panic/data/i_test/001/dark_seq_ind0221.fits']                                                                                                                                                                                
 Error running IRAF task combine                                                                                                                                                                                             
('IRAF task terminated abnormally\nERROR (603, "Parameter not a legal number (project)\x07")\n', 10, 'No child processes')


  Otro error:
    
    [PAPI]: 2012-05-25 13:33:26,592 ERROR    reductionset:1901: [reduceSeq] Some error while creating master DARK: [Errno 32] Broken pipe
    [PAPI]: 2012-05-25 13:33:26,592 ERROR    reductionset:1773: [reduceSet] Cannot reduce sequence : 
 ['/home/panic/data/i_test/001/dark_seq_ind0222.fits', '/home/panic/data/i_test/001/dark_seq_ind0223.fits', '/home/panic/data/i_test/001/dark_seq_ind0224.fits', '/home/panic/data/i_test/001/dark_seq_ind0225.fits', '/home/panic/data/i_test/001/dark_seq_ind0226.fits']                                                                                                                                                                                
 [Errno 32] Broken pipe                                                                                                                                                                                                      
    [PAPI]: 2012-05-25 13:33:26,592 DEBUG    reductionset:1774: [reduceSet] Procceding to next sequence...
Exception in thread Thread-10:
Traceback (most recent call last):
  File "/usr/lib64/python2.7/threading.py", line 530, in __bootstrap_inner
    self.run()
  File "/home/panic/DEVELOP/PIPELINE/PANIC/trunk/reduce/threadsmod.py", line 51, in run
    raise e
OSError: [Errno 32] Broken pipe


  - Hago una primera prueba/implementación en QL para usar Process+Queue en lugar de la clase ExecTaskThread que "pienso"
  que puede ser la causa de los errores de PyRAF descritos arriba.
  
  - Muevo algunos métodos relaccionados con FITS del módulo misc.utils al modulo clfits

2012-05-29
==========  
  - Reunion con Matilde (ver notas más abajo).
  - paper SPIE2012

2012-05-30
==========  

   - Modificacion en phometry para que genere al catalogo con el ZP estimado (sugerencia MF)
   

2012-06-11
==========  
   - Working on TaskRunner in QL and improvements in DataCollector 
   
2012-06-12
==========  
 - Sent to JF next notes for the videoconf:
   
    - Implemented support for FITS cubes (non integrated mode)
    - Implementing support for distinguished FITS-files (non integrated)
    - doing improvements on the parallel processing 
    - (of course) debugging and profiling 

  - Encuentro problemas serios en QL cuando se intenta reducir todo un DataSet
  de un directorio leido del tirón.
  Ese mismo error se produce tambien en PAPI cuando por ejemplo hacemos:
  
     > papi -s ~/DATA/i_test/001/ -S 8 9
     
     donde 8 es una secuencia de DARK 
           9 es una secuencia de SCI

    en cambio si 8 fuese una secuencia de SCI tambien, entoces no hay error !!!
    por que ???
    
    ---> TODO PARECE INDICAR QUE EL PROBLEMA ES POR LA CONCURRENCIA DE IRAF !!!!!!!
    
"""
Killing IRAF task `combine'
Exception OSError: (10, 'No child processes') in <bound method Subprocess.__del__ of <Subprocess '/iraf/extern/mscred/bin.linux/x_combine.e -c', at 208fea8>> ignored
    [PAPI]: 2012-06-12 18:56:03,092 ERROR    reductionset:2087: [reduceSeq] Error while parallel data reduction ! --> Error running IRAF task combine
('IRAF task terminated abnormally\nERROR (603, "Parameter not a legal number (project)\x07")\n', 10, 'No child processes')                                                                                                                                                     
    [PAPI]: 2012-06-12 18:56:03,092 ERROR    reductionset:1773: [reduceSet] Cannot reduce sequence : 
 ['/home/panic/data/i_test/001/dark_seq_ind0046.fits', '/home/panic/data/i_test/001/dark_seq_ind0047.fits', '/home/panic/data/i_test/001/dark_seq_ind0048.fits', '/home/panic/data/i_test/001/dark_seq_ind0049.fits', '/home/panic/data/i_test/001/dark_seq_ind0050.fits']     
 Error running IRAF task combine                                                                                                                                                                                                                                               
('IRAF task terminated abnormally\nERROR (603, "Parameter not a legal number (project)\x07")\n', 10, 'No child processes')                                                                                                                                                     
    [PAPI]: 2012-06-12 18:56:03,092 DEBUG    reductionset:1774: [reduceSet] Procceding to next sequence...
    [PAPI]: 2012-06-12 18:56:03,092 DEBUG    reductionset:1781: [reduceSet] All sequences processed.
    [PAPI]: 2012-06-12 18:56:03,093 DEBUG    reductionset:1782: [reduceSet] Files generated # 1 #: ***
    [PAPI]: 2012-06-12 18:56:03,093 DEBUG    reductionset:1783:             - /data/out/mDark_FVSjmi_2_2.fits
    [PAPI]: 2012-06-12 18:56:03,093 DEBUG    reductionset:1784:             Sequences failed  # 1 #: ***
    [PAPI]: 2012-06-12 18:56:03,093 INFO     reductionset:1371: Purging the output dir ...


Well done (I hope) -  Elapsed time(s): 10.733102!!!
List of images to combine ('@/data/out/Q01/files.txt'): XIO:  fatal IO error 11 (Resource temporarily unavailable) on X server ":0"
      after 24 requests (24 known processed) with 0 events remaining.

PANIC in `/iraf/extern/mscred/bin.linux/x_combine.e': Write to IPC with no reader
"""

2012-06-13
==========  

 * Pre-videoconf, videoconf y postvideoconf
  - JF pregunta sobre que es el profiling y que es LEMON
  - JF pregunta sobre la fecha para hacer la II-Sw-integration: CS está sin tiempo !!
  - Quedamos en preparar un TODO-list con las cosas del SW de PANIC que quedan pendientes
  con el objetivo de intentar determinar cuando podríamos tener la II-SI
  
 * Solucion a bug de PyRAF cuando llamamos al algún metodo en multiprocessing (ver notas del día 12-Jun-2012)
   Gracias V.Terrón (ejemplo pyraf_multiproc.py) , que el ya había pasado por el mismo problema, 
   encontramos que el "truco" está en crear el multiprocessing.pool antes de cualquier posible llamada a alguna rutina de PyRAF.
   En el ejemplo del 12-Jun, la al reducirse la secuencia de DARK con darkcombine y luego reducir 
   la secuencia de SCI con un Pool, entonces se corrompe el espacio de nombres de PyRAF o lo que sea
   y ya se produce el error. 
   Lo soluciono en reductionset.py declarando el Pool justo despues de la clase ReductionSet, pues si lo
   declaro antes, da otro error por que no conoce la clase RS.
   
 * Ahora queda probar que en el QL todo funciona bien tambien.
   Pues nada mas probar, me doy cuenta de que no funciona, pues el declarar
   variables globales (pool) en reductionset.py, luego el Process que creamos
   en el QL para procesar las secuencias (vía Queue) no puede acceder a dicho
   pool global; aunque no se queja de ningún error, proceso de reducción 
   se queda esperando forever en el result.get().
   
   Solución: ver 15-6-2012
   
2012-06-15
==========  
   
   * Por fin encuentro la solución la problema del interbloqueo por la variable
   global pool para evitar el bug de IRAF.
   La solucion (espero que definitiva!) es crear el pool local en RS.reduceSeq()
   de forma que lo usemos para todas la operaciones que requieran IRAF, de forma
   que siempre habremos creado el pool con todo su espacio de nombres correcto
   antes de llamar a IRAF (bug detectado por V.Terrón)
   
2012-06-19
==========  

 - Estudion y/o migracion de los métodos que usan ExecTaskThread en QL;
 Me encuentro con un dilema al migrarlo todo y hacer que todas las operaciones
 pasen por el TaskManager y su cola, pues podría interesar que mientras se esté 
 ejecutando la reducción de un DS "largo" se pueda interactura con el QL para 
 realizar otra operación de "corta" duración (subtract_last_2, divide, etc...).
 En dicho caso, habría que tener dos colas o bien dejarlo como está con Threads.
 
 Mientras decidio sobre dicho dilema, me encuentro con un problema al migrar
 QL:processLazy, pues me da el famoso error :
 """
 Process Process-1:
Traceback (most recent call last):
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 232, in _bootstrap
    self.run()
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 88, in run
    self._target(*self._args, **self._kwargs)
  File "/home/panic/DEVELOP/PIPELINE/PAPI/trunk/QL/mainGUI.py", line 2610, in worker
    func, args = input.get()[0]
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 91, in get
    res = self._recv()
  File "/home/panic/DEVELOP/PIPELINE/PAPI/trunk/QL/mainGUI.py", line 100, in _unpickle_method
    for cls in cls.mro():
AttributeError: ("class ApplyDarkFlat has no attribute 'mro'", <function _unpickle_method at 0x2c937d0>, ('apply', <reduce.applyDarkFlat.ApplyDarkFlat instance at 0x2f153b0>, <class reduce.applyDarkFlat.ApplyDarkFlat at 0x1b48600>))
"""

2012-06-20
==========  

- Encuentro la solución al problema de pickle/unpickle --> el problema estaba
en que la clase ApplyDarkFlat no derivaba de Object, y por eso no tenia los
atributos que necesitan los métodos de serialization.

2012-07-11
==========  

- Videoconf PANIC

*) Le mando a JF lo siguiente:

Dear Josef,

sorry for the delay, but I forgot it.

Please, take next inputs (QL & Pipeline) for the videoconf :

- Talk presenting the PANIC Quick-Look tool at SPIE2012
- Implemented procedure that mix dome & sky FF
- Continue with endless debugging
 

And the AIs to be done in QL & Pipeline before send PANIC to CAHA:

- Add support for distinguished files (non integrated)
- Implement health-check routines of the instrument (copy from JF's)
- Complete the debugging and tests of QL and Pipeline (might need additional developments)
- Review the initial photometric calibration
- Complete the Verification and Validation of pipeline results (in progress)
- Write QL and Pipeline User's Guide doc (initiated)
- Decide if the whole software must run in single computer or separate on control & processing computers (depend on memory problem found in GEIRS)    
- Choose & buy the computer/s to be used at Telescope
- Install the computer/s and write installation document
- Test QL & Pipeline at HD (2nd. Software Integration)


For the moment these are the AIs I can remember, but for sure not the ones.

*) Como resumen de la videoconf:

- JF se ve abrumado por las 3 slides de SW, así que prefiere resumirlo en : SW is going on.
Sin embargo, le preguntamos por GEIRS y las tareas pendientes:

   - todo parece indicar que CS implementara el control de las ruedas de filtros (Agost-Sep), 
   pero que el resto de cosas (sensors, fast readout, windowing, ...) lo hará si le sobra tiempo.
   - le preguntamos a JF si sabe algo del problema de memoria en GEIRS, y nos dice que no sabe nada,
   pero que le preguntará a CS. Tambien le pido que aproveche y le pregunte por una fecha tentativa
   para la 2da.Software Integration.
   JF en el mail de resumen de la videoconf, incluye:
   """ 
   Computer/memory:
     - status of memory problem is as before (i.e.reason unknown)
     - this problem has to be attacked again, wtih updated operating system etc
     - CS sees no problem to run PANIC including GEIRS on 1 computer
  """

  - Ulli informa que el problema de movimientos relativos en el 3.5 ha sido resulto, por
  lo que el OT podría usarlo.

  - Tambien se habla de la documentacion(deseable para finales de 2012), en principio en PDF+source. Jens sugiere además
  un trouble shooting document en la Web de forma que puedan hacer copy+paste para solucionar
  problemas del software.


2012-07-17
==========

- Matilde me dice que mejor postponemos las KDD hasta después de vacaciones (septiembre?)

2012-07-18
==========  

- Subida al OSN para enseñarlo a César y Regina


2012-07-19
==========  

- Tras varios días intentando compilar la libreria plplot-5.9.4 para que SCAMP pueda generar los gráficos png, lo consigo !!!:
  
  Los pasos son :
    
    1) Descargar el fuente de gd-libgd (con zypper no consigo encontrar dicha libreria) de https://bitbucket.org/pierrejoye/gd-libgd/overview
    
      >hg clone https://bitbucket.org/pierrejoye/gd-libgd
      
    2) Compilar dicha libraria (libgd):
       
       > cd gd-libgd
       > mkdir build
       > cd build 
       > cmake -DBUILD_TEST=1  -DENABLE_PNG=1 -DCMAKE_LIBRARY_PATH=/usr/loca/gdlib/lib -DCMAKE_INCLUDE_PATH=/usr/local/gdlib/include ../../gd-libgd/
       > make
       > make install
       
    3) Descargar la plplot-5.9.4 (pues parece que es la que recomiendan en el foro de SCAMP  http://www.astromatic.net/forum/showthread.php?tid=761)
       aunque puede que con la 5.9.9 también funcionase.
       
       http://sourceforge.net/projects/plplot/files/plplot/5.0.1/
       
    
    4) Compilar plplot-5.9.4
    
       > cd plplot-5.9.4
       > mkdir build
       > cd build 
       > cmake -DCMAKE_INSTALL_PREFIX=/usr/local/plplot594 -DBUILD_TEST=ON ../../plplot-5.9.4 >&cmake.out
       > ccmake ..
         y editar a mano 
 
          GDI32_LIBRARY /usr/local/lib/libgd.so
          ENABLE_python OFF (pues da un problema al no encontrar un .h de numpy ??)
          PLD_png ON
    
        básicamente eso.
        
     > make 
     > make install
     
     IMPORTANTE: copiar /usr/loca/gdlib/libgd.so en /usr/local/plplot594/lib/ pues si no se quejará el PLPLOT de que no la encuentra.
     
     > export PLPLOT_LIB=/usr/local/plplot594
     
     y listo !!! SCAMP debe generar los graficos PNG sin problema (glup!).
     
     
     FAQ:
       My program exits with the error message Unable to either (1) open/find or (2) allocate memory for the font file

       The PLplot library can't find the font files plstnd5.fnt and plxtnd5.fnt. Set the environment variable PLPLOT_LIB to the directory where these files are, e.g. export PLPLOT_LIB=/usr/local/plplot/data. 
     
     
    HA costado lo suyo !!! lo ideal sería que SCAMP (E.Bertin) migrara a la libraría cairo para generar los PNGs !!!
    
    Sin embargo, si le digo a SCAMP que genere ficheros JPEG no lo hace (Requested device jpeg not available), pregunta cada vez por el tipo de fichero....por qué ?
    PDF's si lo genera bien, incluso con mejor calidad que los PNG !!
    PS: en B/N y no completos
    Recompilo PLPLOT library con PLD_jpeg ON y ya si genera SCAMP los JPEG's, pero de una calidad pésima, inservibles !!!
    
    
    
    


2012-07-20
==========  
    

2012-07-24
==========  

- Pruebas con PyQt4 (en openSuSE11.4)
 
   * instalo SIP 4.13.3 (requerido por PyQt4.9.4)
   * compilo PyQt4.9.4
   *

- Pruebas con Pyside (en openSuSE11.4)

   * Sigo las instrucciones de http://qt-project.org/wiki/Building_PySide_on_Linux
   y todo OK !
   
- Modifico PQL (mainGUI) para que no tenga que hacer uso de la clase RunQtProcess
pues sólo se usaba en un caso (Subtract own-sky), y no merece la pena tener 
una clase para sólo eso. 
Lo que hago es que llamo directamente de forma sincrona (sin hebras ni nada) a
la clase sextractor.
No puedo usar hebras pues sex.run() no devuelve nada, y ExecTaskThread necesita
de el fichero generado para poder mostrarlo.
Todo esto para refactorizar código y simplificar !!
Muevo temporalmente runQtProcess.py al directorio deprecated.


2012-10-01
==========  
- Después de un parón de dos meses en PAPI por estar con TCS2, retomo a PAPI.
- Añado la escritura de los valores del diccionario del config_file que usa el
ReductionSet en el log_file de cara a poder luego depurar la reduccion realizada
por PAPI en cada ejecución.

- Encuentro un Bug(?) al lanzar PAPI en el portatil, pues da un error al crear
un master_dark de conjunto de Alhambra....en cambio en udit43 no ocurre ???


2012-10-02
==========  

- Test: aplico una distorsión (applyDistort.py) a una imagen reducida del
dataset de ALHAMBRA. Después, le paso astrowarp.py y compruebo que el plot
distort_1.png que genera SCAMP coincide con el que patrón de distorsión aplicado
(dist_mat_K.txt, que me pasó hace tiempo Conchi de PANIC).
Luego, buscando como interpretar mejor los plots que genera SCAMP (ver http://www.astro.uni-bonn.de/theli/gui/astromphotom.html)
extraigo que los pixels más grandes (rojo en plot) son los que deben coincidir
con el eje óptico del instrumento, y el resto serán más pequeños y por tanto
generan la distorsión; pensado un poco, eso tiene sentido....


- Aniado a reductionset.py 

 >>> pyraf.iraf.prcacheOff()

que me reportó VTerron tras consultar en los foros de PyRAF y creer que era un bug.
Aunque creo que ya no la necestio, pues no se que hice para evitar los problemas....

No obstante, la añado también con la intención de solucionar el problema siguiente
ya conocido desde hace tiempo:


Exception in thread Thread-1 (most likely raised during interpreter shutdown):
Traceback (most recent call last):
  File "/usr/lib64/python2.7/threading.py", line 530, in __bootstrap_inner
  File "/usr/lib64/python2.7/threading.py", line 483, in run
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 272, in _handle_workers
<type 'exceptions.TypeError'>: 'NoneType' object is not callable


pero SIGUE dando el problema a pesar de deshabilitar la Cache.
Leo en un foro que a alguien le pasa algo parecido, y le encuentro la siguiente
respuesta interesante: 

"""
From: http://stackoverflow.com/questions/4079810/python-thread-exception-errors-when-exit-the-whole-program

The problem is caused by the use of threading.Thread.setDaemon. Threads set 
daemonic don't prevent the Python intepreter from exiting, but they still keep 
running. Because Python cleans up the environment before the process is 
terminated, the threads can run into trouble when stuff is removed from under 
them. That raises an exception, which the thread class tries to print for your 
convenience -- but that, then, too fails because the process is exiting.

You could try to silence the exception, but that's tricky (and if the thread 
does anything substantial, it might hide a real problem. Not the case here, 
though.) Or you could ask the thread to stop before exiting, and not set the 
thread daemonic. Or you can simply avoid using threads altogether. I do not 
remember if wxPython has a convenient mechanism for getting a process's output 
or even of doing asynchronous I/O, but many GUI toolkits do. And there's always
Twisted, which does it all for you.
"""


2012-10-17
==========  
- En busca del error que hace que falle PyRAF+multiprocessing (sin clases ni nada)
en python 2.6 ( HD, portatil, udit43), y que sin embargo funciona perfectamente
en python 2.7:


#!/usr/bin/env python

import pyraf.iraf
from pyraf.iraf import noao, imred, ccdred, mscred
from pyraf.iraf import images,imutil

import time
import multiprocessing
import sys

pyraf.iraf.prcacheOff()

def run_iraf():
    print "Start run_iraf"

    pyraf.iraf.unlearn("imstat")
    #import pdb; pdb.set_trace()
    pyraf.iraf.imstat(images = "/tmp/dark.fits", fields="mean")

    print "End run_iraf"

    return "Success!"

if __name__ == '__main__':
    #run_iraf()
    #sys.exit(0)
    pool = multiprocessing.Pool(processes=2)      # start 4 worker processes
    result = pool.apply_async(run_iraf, args=())   
    result.wait()
    #result = multiprocessing.Pool(processes=4).apply_async(f, [10])
    print result.get(timeout=5) 
    
    sys.exit(0)


2012-10-18
==========  
- Continuo buscando el problema de PyRAF; escribo a help@stsci.edu preguntando
sobre el problema.
- Lo pruebo en el ordenador de VTerron (python 2.6.6, PyRAF 2.0) y funciona 
perfectamente. El me recomienda pasar a PyRAF 2.0
- Instalo PyRAF 2.0, en udit43, pero siguen los problemas.
- Instalo Python 2.7 en un directorio a parte, pero no puedo probarlo pues
no encuentra PyRAF, etc ....
- Instalo en el portatil (/usr/local/python273) Python 2.7.3 y todos los 
modulos de python que necesita PAPI. Lo documento en el PAPI_Install.txt. 
Ahora todo parece funcionar correctamente en el portatil con la nueva version 
de Python273.

- comienzo desarrollo de check_papi_modules.py para incluyir al inicio de papi.py


2012-10-22
==========  
- Me doy cuenta de que calBPM y calBPM_2 no funcionan bien (temp_dir, master_dark, ...)
y además le actualizo el Parser de opciones de la CL.

2012-10-23
==========  
- añadidas bastantes mejoras a calBPM (incluso tenia un bug) y calBPM_2.
- buscando algo para sustituir STILTS para el cross-matching de catalogos,
encuentro un código de Sergio Pascual, 'gmatch' en

     https://bitbucket.org/sergiopr/gmatch/src

que habrá que probar.
   
2012-10-24
==========  
- Encuentro una implementación de un wrapper para Sextractor de un compañero
de Sergio Pascual, en :

    https://gitorious.org/~gruel   

- Astrometry.net: instalo y compilo la última version (0.38) en udit43/udit22 y 
le copio los index files en (/usr/local/astrometry/data) y la pruebo con una
imagen reducida y ya calibrada de O2k (Alhambra):

solve-field ~/reduced_SEQ.fits --scale-units arcsecperpix --scale-low 0.2 --scale-high 0.4 --overwrite

y lo hace aparentemente bien (aunque era una imagen ya calibrada astrometricamente por scamp!).

Observaciones:
   - SCAMP tardó 12 segundos en resolver el .ldac creado por SExtractor (6 secs),
   en total unos 19secs; 
   por otro lado Astrometry.net tarda 32secs en total (buscar fuentes y resolver 
   astrometría)
   Sin embargo, si ejecuto 'solve-field' con la opcion --no-plots, tarda 8secs !!!
   
   - Astrometry.net usa BD (/usr/local/astrometry/data/index-nnn.fits) local !
   
   - Astrometry genera un fichero reduce_SEQ.new con un WCS que usa proyección
   TAN-SIP (TAN (gnomic) projection + SIP distortions).

   - Si le paso una imagen no calibrada astrometricamente 
            
            /data/O2K/Matilde/120105/ferM_0065.fits
     
     entonces Astrometry.net empieza a buscar iterando sobre los indices y al
     final lo paro pues después de más de 30minutos no parece terminar ...
     Aunque le pase las coordenadas aproximadas, --ra 100.427917 --dec 9.522,
     tampoco resuelve.
     
    Sin embargo, con astrowarp.py (PAPI) si puedo calibrar la misma imagen 
    en bruto en 17secs:
    
    >> python reduce/astrowarp.py -s /data/O2K/Matilde/120105/ferM_0065.fits -o /tmp/astro_cal.fits

- Josef Fried me responde el mail en el que le pregunto por las rutinas de
Health-Check para PANIC, pero no entiendo, pues lo que me manda es muy parecido
a la rutina ana.prg que ya tenía (incluso parece más antigua) y además no concuerda
con lo que me comenta en el email ????

- Recibo nueva oferta de Belen de DELL sobre el R720 (16K€)



2012-10-29
==========  
- Escribo email resumen para enviar acerca del PANIC-computer (aún no lo envío)

- Inicio implementación de health.py ...sin saber aún muy bien que tengo que hacer !!!!

2012-10-30
==========  
- Sigo con el tema del health-check, y me pongo a probar manualmente la fórmula
de Janisky para calcular la ganancia(K) y el RON, pero no me salen resultados
congruentes.
Además encuentro lo siguiente:

"""
In CCD imaging, gain refers to the magnitude of amplification a given system 
will produce. Gain is reported in terms of electrons/ADU (analog-to-digital unit). 
A gain of 8 means that the camera digitizes the CCD signal so that each ADU 
corresponds to 8 photoelectrons.

The system gain of a Photometrics camera is typically set so that the full 
well of the CCD matches the full range of the digitizer (at 1x gain). The 
camera's gain can also be selected under software control to meet the needs of 
a given application. For example, the gain can be increased to 4x when the 
application is photon starved and a high-sensitivity mode is required. 
Alternatively, the gain can be reduced to 1/2x when the application is 
photon-shot-noise limited and a high SNR mode is required. Because gain refers 
to the amplification of a system and the gain reported in CCD imaging is 
actually inverse amplification, the meaning of gain is not entirely intuitive. 
As gain increases, the reported gain value decreases. For example, if the 
system gain (1x) is 8e-/ADU, then the high-gain (4x) mode would be 2e-/ADU.

A simple method to calculate the system gain is shown below:

    1-Collect a bias image (zero-integration dark image) and label it "bias".
    2-Collect two even-illumination images and label them "flat1" and "flat2".
    3-Calculate a difference image: diff = flat2 - flat1.
    4-Calculate the standard deviation of the central 100 x 100 pixels in the difference image.
    5-Calculate the variance by squaring the standard deviation and dividing by 2 (variance adds per image, so the variance of the difference image is the sum of the variance of flat1 and flat2).
    6-Calculate a bias-corrected image by subtracting the bias from one of the flat images and label it corr: corr = flat1 - bias.
    7-Obtain the mean illumination level by calculating the mean of the central 100 x 100 region of the corr image.
    8-The mean divided by the variance equals the gain: gain = mean /variance.

A more rigorous method is that of Mortara and Fowler (SPIE Vol. 290 Solid State 
Imagers for Astronomy (1981) pp. 28-33), which essentially involves repeating 
the above procedure for a series of illumination levels over the full range of 
the CCD full well. In addition, their method recommends collecting four or more
flat images at each exposure level and averaging them to improve the precision 
of the measurement. The authors also provide the theory supporting the method. 
Another rigorous, excellent method that can be used to calculate gain is the 
photon-transfer technique of Janesick et al. (Optical Engineering Vol. 26 (10) 
(1987) pp. 972-980).
"""


2012-10-31
==========  
- Continuo con health.py.


2012-11-05
==========
- Nos manda Matilde un mail pidiendo lo siguiente:

"""
Muy buenas a todos,

  como todos los annos, en la reunion del Comite Ejecutivo de Calar Alto presentaremos dos dispositivas sobre PANIC.
  Para preparar estas dispositivas, me podeis mandar un par de frases o tres sobre la situacion actual de lo que estais llevando cada uno?
  Alguien tiene alguna foto reciente o relevante?

Me gustaria montar esto el miercoles por la mannana.
 
"""
Yo le respondo con:


Hola Matilde,

te adjunto un párrafo que creo que resumen de forma general el estado
del pipeline. Modúlalo como tu veas más conveniente, y en su caso, **
completa ** algunos datos que faltan de tu proyecto.


"""
Concerning the Pipeline and quick-look tool, the development and
debugging was continued, making improvements to some processing
routines and adding new features. In addition, the pipeline was run
successfully with a observing campaign of the project <xxxxxxx>  of
<xxxxxx> nights with Omega2000 at CA.
Currently, the pipeline debugging and improvement are being continued,
the computer system is about to be ordered, and a second software
integration to be hold early next year is being prepared.
"""

2012-11-07
==========
- Encuentro información que me aclara bastante como hacer el calculo de la
Gain y RON de un CCD (o IR detector) en :

    http://spiff.rit.edu/classes/phys445/lectures/gain/gain.html

- A partir de la web anterior, pero ahora en :

http://spiff.rit.edu/classes/phys445/lectures/align/pipeline.html

encuentro el artículo:
    "FOCAS Automatic Catalog Matching Algorithms"
    
que describe como hacer el matching de catalogos de forma eficiente.

- Hablo con Jessica de DELL acerca de los problemas con openSuSE en el
equipo DELL y me dice lo siguiente:
    
    1) Probablemente no tengamos problema con la distribucion openSuSE (o 
    cualquier otra open), pero no nos pueden garantizar que no haya problemas
    con algún driver de alguna controladora, pues es por eso que no esta
    certificado.
    
    2) Incluso, tambien podriamos tener problemas con el soporte tecnico, pues
    en cuanto le digamos que tenemos openSUSE, pues incluso por el fallo de un
    disco nos pueden negar el soporte.
  
    3) Hemos quedado que maniana me pasara un presupuesto con el coste de la 
    licencia para SuSE entreprise para 3 y 5 anios.

- Hago mejoras en health.py :

    - estimacion del full-well
    - chequeo de tamaño ventana
    - rango de ficheros en el paquete
 
  Pero todo esto quedaría pendiente de probar con datos reales de PANIC o
  cualquier otro instrumento.
  
  Todo:
  ----
    - temporal_noise (cfr. vianak)
    - usar numpy en lugar de cubemean
    - implementar chequeo de rango y sigma-clipping  !
    
2012-11-08
==========
- implemento spatial_noise.py para calcular el RON a partir de la ganancia
y de una serie de parejas de imagenes con el mismo TEXP.
Esta basado en las rutinas que me pasó Josef Fried y en :
  
        http://bit.ly/YUdJsD

        Noise = stdDev(Darkframe1-Darkframe2)/sqrt(2)*AD-Factor/EM-Gain


2012-11-12
==========
- Continuo con la documentación con Sphinx de PAPI; me esta dado un monton
de WARNINGS que al generar el latex se convierten en un error. 
Todo es por estar usando la extensión de Numpy `sphinxext`.

- Envio a Josef para la videoconf lo siguiente:

    * Added some kind of detector health-check routines (gain and noise computation)
    * PAPI doc in progress (http://www.iaa.es/~jmiguel/PANIC/PAPI/html/)
    * Defined the PANIC computer ?

2012-11-16
==========

- Avanzo bastante con la migracion a PyQt4 !! al menos puedo lanzar el QL, aunque
hay bastantes metodos que aun hay que migrar y actualizar, y para ellos hay
que ir probando la GUI por completo !


2012-11-19
==========
- Encuentro buscando por la red como "silenciar" los warnings de sphinx con la 
extension numpydoc:

numpydoc_show_class_members = False

Con esto ya no da los warnings, y se genera el latex+pdf bien. 
No obstante, parece que para generar bien la documentación habría que usar
un generador propio en python, como hacen otros proyectos (incluido el propio
numpy) como:

    http://www.pymvpa.org/index.html
    http://scikit-image.org/docs/dev/

2012-11-21
==========
- Continuo con la migracion a PyQt4.
- Me surge la duda sobre si para los Master TwLight flats es imprescindible
un dark model o bastaría con un simple master_dark ?? Ahora mismo sólo
se calculan con un master_dark_model.
- Intento instalar en el portatil la version QL4, pero como no me deja instalar
PyQt4; parece que la version de PyQt4 no es compatible con la libreria Qt4 que
tengo instalada en el sistama ...
Lo mejor será esperar a migrar a openSuSE 12.2.


2012-11-22
==========
- Richard Mattar me manda una nueva version de geirs2Panic; la compilo, aunque
el '-Ofast' no me funciona (solo para GCC >= 4.7.x), pero con -O2 si compila
y se ejecuta en 1.5secs.

Lo pruebo aniadiendolo en en ~/GEIRS/scripts/QueueFiles

OJO: Geirs2Panic no puede ser lanzado aquí en background, pues si no GEIRS
se creería que ha terminado y continuaría con la secuencia que estuvise 
ejecutando ...

""
modify_fits_hdr -v -a ~/tmp/fitsheader_panic.txt $1 >>~/GEIRS/log/add_panic_fits.log
/home/panic/DEVELOP/GEIRS/geirs2Panic/src/geirs2Panic $1 $1_r.fits -r
export ret=$?
if [ $ret -eq 0 ]; then
    echo `date '+%Y-%m-%d_%Hh%Mm%S'` $1_r.fits   >>~/tmp/fitsfiles.corrected
else
    echo `date '+%Y-%m-%d_%Hh%Mm%S'` "ERROR $ret in modifying fits-header of $1"  >>~/tmp/fitsfiles.corrected
fi
exit $ret
""

y lanzo varias secuencias del OT con dicha modificación y perece que el QL
no se queja. Aunque habría que ver los efecto en el proceso de reducción....
De momento eso no lo voy a probar, pues no se muy bien si se usará el Geirs2Panic ....
 


- Decido quitar en ExecTaskThread.run el "raise e" pues no se como capturarla
después y la saca por la de forma fea por la stdout.
No creo que sea necesario elevar la exceptio, pues el error se detecta de todas
formas; parece que no tendrá efectos colaterales.
 

2012-11-23
==========

- Instalacion de todo el software de PAPI en openSUSE12.2
- Actualizo el documento de instalación
- Pruebo 'casi' todo, y parece que ve bien: QL4, reduccion de HAWK-I-3, photometric calib, ...
- SCAMP con soporte para graficos PNG : es lo que mas guerra me dió !!! la libraria plplot-5.9.9 y cia.;
se me habia olvidado copiar la nueva libplplotd a /usr/lib64 y por eso no me funcionaba; el PLPLOT_LIB no hace falta !!


2012-11-26
==========

- Instalo la ultima version de OT y la vieja de GEIRS para seguir con las
  pruebas.
- Le escribo a Clemens diciendole que igual es mejor comprar los equipos aquí
  para evitar que yo tenga que viajar a HD para la instalación.
- Bug fix.:
Al lanzar el designer, me da varios errores y no deja lanzarlo. Buscado en
  google encuentro una forma "chapucerilla" para que funcione, y es creado el
  fichero  ~/.config/ibus/bus.


"""
Every KDE and QT GUI application complains on startup:

QInotifyFileSystemWatcherEngine::addPaths: inotify_add_watch failed: No such file or directory
QFileSystemWatcher: failed to add paths: /home/allee-o/.config/ibus/bus

that very disturbing when working on the command line, e.g. with kate or okular etc.

Creating the directory ~/.config/ibus/bus makes the error go away. I installed ibus-daemon
"""

2012-10-27
==========  

- Instalo la nueva versioń de Eclipse (4.2.1 - Juno) junto con la extensión
para los Color Theme (Oblion).
De paso encuentro una versión "custom" de eclipse para Python (+php,web,ruby) : Aptana Studio 3!!
Habrá que probarla.

2012-10-28
==========  
- Modificación de photometry.py con la implementación de xmatching de catalogos
usando un modulo de python coords.py que encontre en :
   >>> https://bitbucket.org/nhmc/pyserpens/src/6e805f1f08ef/coord.py

Eché de menos el 'merge' de catalogos en AtPy, así que me tuve que buscar la vida
con otro xmatch para mezclarlos.
De esta forma me evito el tener que usar STILTS (java app), que aunque funciona 
muy bien, me crea otra dependencia externa a python.
Lo pruebo y parece que va bien, al menos obtengo identicos resultados que con
STILTS, y en un poco de menos tiempo de CPU.
De momento decido dejar las dos implementaciones de xmatching, con stilts y sin el.
Nota: habría tambien la posibilidad de usar gmatch, un modulo python de Sergio
Pascual de la UCM que usa KDTree, pero como coords.py es simple, funciona bien,y
en principio los xmatch serán con pocas estrellas y no nos preocupa mucha la 
eficiencia, para liar más la cosas con un module de la UCM ?
Si viesemos que la eficiencia es importante, entoces lo usariamos...


2012-10-29
==========  
- Instalación de PAPI_SW en portatil con openSuSE12.2; parece que todo OK.

2012-10-30
==========  
- Me pongo a ver por que el set Matilde-120103-27a31 en filtro Z no se reduce
bien. El problema está en el superFlat, que no se calcula bien, pues la normalización
que se hace con la "moda" da una normalizacion con valores >2 !!!
¿ habría que chequear eso en el calculo del SF normlizado ?
¿ es adecuada la normalización con la "moda" ? hago una prueba con la "mean" y
si sale bien.
También me doy cuenta que los umbrales para el calculo de los BP del gainmap que
hay en el fichero de configuracion no son del todo buenos, al menos para la 
secuencia en cuestion.
Los cambio tal que:

 mingain = 0.5 # pixels with sensitivity < MINGAIN are assumed bad (0.7) 
 maxgain = 1.5 # pixels with sensitivity > MAXGAIN are assumed bad (1.3)

El valos más sensible es el mingain !

TODO: Tengo que ver bien como afectan los BPM en todo el proceso de reducción !!!!!
 
2012-12-03
==========
- Dandole vueltas a como hacer la normalización de los flats, veo que en el
pipeline de HAWK-I hacen la normalización con la mediana, que es un estimador
"robusto", mientras que la "mean" no lo es !!!
Por tanto, me pongo a modificar la todas la rutinas que hacen normalización:
Sin embargo, encuentro unas rutinas para calcular un estimador "robusto" de la
media:
http://fornax.phys.unm.edu/lwa/subversion/trunk/lsl/lsl/statistics/robust.py

Comparando los resultados de robust.mean() y numpy.median() los resultados son
muy parecidos. De momento vamos a usar la mediana.
Modifico en todas las rutinas la normalización por la median en lugar de por la moda !!

Me surge la duda de si la campania de Matilde con O2k se redujo bien; miro las
imágenes reducidas y veo que al menos la secuencia 120103-27a31 "se ven estrellas";
esa se redujeron con flast de cielo, y por eso quizás el gain.fits no se calculó
del todo mal.
 

2012-12-04
==========

- Encuentro el paquete de reducción del LSST, y hay cosas muy interesantes:

    http://www.astro.princeton.edu/~bick/lsstdox/userLsst/mast-1413/python/lsst/

- Intentado usar la funcion robust.polyfit(), pero me doy cuenta de que tiene
un par de bugs, entre ellos que la funcion __processPoly() no está implementada...
De todas formas, puedo llegar a comparar el resultado vs np.polyfit(), pero en
el ejemplo que pruebo los resultados son muy parecidos.

Sin embargo, habría otra opción, y es usar fit.polyfitr() que es una copia
de la que encontré en pyserpens. 

2012-12-05
==========

- Continuo con la documentacion.
- A la vez voy mejorando algunos modulos (calDark, calDarkModel, ...) tanto
la documentacion/ayuda y actualizando para usar OptionParser que en algunos
no estaba actualizado aún.


2012-12-11
==========
Le envio a JF las notas para la videoconf:
"""
- QL: GUI migration from Qt3 to Qt4
- Pipeline & QL running on openSUSE12.2
- several improvements in (flats, photometry)
- documentation: in progress
"""


2012-12-17
==========
- Preparación de la demo de sw de PANIC:

En mi portatil (openSuSE12.2 x86_64) debo hacer lo siguiente:

$ rcrpcbind start
$ mount udit36.iaa.es:/home/panic/tmp /mnt/tmp/
$ mount udit36.iaa.es:/home/panic/DATA /mnt/DATA
$ ln -s /mnt/tmp /home/panic/tmp



2012-12-18
==========
- Demo de sw de PANIC:

A las 10.15 aprox. comenzamos, asistiendo : MF, JR, CC, VT, AG, JM

- Revisar los valores RA,Dec,Time offset del setup usados para el agrupamiento
de datasets no observados con el OT.
- Cambiar el color botón "Start Processing" y modificar la funcionalidad t.q.:
 "Process all, only new files, Cancel"

- Revisar agrupamiento de serie de darks; en 'Build Calibrations' parece que lo hace
de forma distinta.
- Añadir otro parametro 'max. número ficheros/grupo' para el agrupamiento de 
datos no observados con el OT;
- Intentar obtener la matriz de distorsión, bien a partir de SCAMP preguntando
a E.Bertín o bien implementando el procedimiento para calcularla.

- Revisar el procedimiento del cálculo del FWHM, psf, ...


2012-12-19
==========

- Rapaso notas tomadas de la demo-review de sw

2012-12-20
==========
- Empiezo con la implementación de sugerencias/bugs en el QL:

  * bug photometry
  
2012-12-21
==========
  * Soluciono BUG importante en RS::self.out_file que no permitía reducir 
  correctamente (se machacaba el fichero de salida) todo un directorio de datos
  con multiples secuencias.
  
2012-12-28
==========
  * Soluciono BUG en setEnabled's del popup menu del QL


2013-01-03
==========

FELIZ AÑO NUEVO !!!

  * Modifico DS::GetFilterFiles() para además de encontrar gaps temporal, poder:
     - limitar la distancia en AR,DEC máxima entre dos ficheros consecutivos de un grupo;
     si se supera dicha distancia (parametro) se 'parte' el grupo.
     - liminar el número máximo de ficheros dentro de un grupo.
  * Modifico QL::worker() y QL::checkDoneQueue() para atrapar excepciones de 
    errores que solo salian por la consola (terminal) y no en la pantalla del QL.

  * Modifico QL para que en el Tab 'Setting' el grouping tenga efecto


2013-01-04
==========
- Currently, this code will not distinguish between next
  dark sequences:
     - 2s 2s 2s  5s 5s 5s 10s 10s 10s 20s 20s 20s ...
     - 2s 5s 10s 20s ...
 both will be classified as dark_model sequences, but
 if max_nfiles=3, then they will be distinguished, although
 it will also affect the other sequences.

- Modifico RS::reduceSet() para poder reducir sequencias según su tipo;
  de esta forma corrijo RS::buildCalibrations() para que reduzca sólo las
  secuencias de calibracion; antes se usaba buildMasterDarks(), buildMasterDomeFlats(), etc
  que hacia su propio agrupamiento pero de forma incorrecta, sin atender
  a grouping por 'ot' ni 'filter'.
  Por tanto, buildMasterDarks() & cia. ya no son necesarias.
 
- Implemento QL:stopProcessing() para detener/abortar la reducción en el QL.
- Elimino la 'tab-Pipeline' de la GUI del QL, pues no hacia nada.


2013-01-17
==========
- Retomo modificaciones en QL:
  
   * cambio de sitio el TempDir, pues es algo no importante para el usuario;
   lo muevo a la pestaña Setup
   * elimino la opción "Stack-Frames" del Pop-up, y la "fundo" con "Quick-red",
   pues al fin las dos estaban haciendo lo mismo, excepto que Stack-frames
   buscaba los proximos en caso de solo seleccionar uno.
- Modifico RS:reduceSet() para que en caso de que fallen todas la secuencias,
lanze una excepción.

- Elimino el bug que provocaba que se insertaran dos veces algunos de los ficheros
generados por el QL, por ejemplo, al terminar de reducir se insertan en la outputDB,
y al hacer click en "OutDir" se revisa el outdir y se insertan todos los que hubiese
en dicho directorio, sin comprobar si ya habian sido insertados previamente.
Para solucionarlo, compruebo en DB::insert(filename) si el filaname ya está en 
la BD, de esta forma nunca podrá haber dos ficheros con el mismo nombre en la BD,
entendiendo como nombre del fichero (path+filaname). 

2013-01-18
==========
- continuo depurando checkQuality para homogeneizar y que lea los ficheros de
configuración de PAPI_CONF en lugar de irdr/conf/....
Importante: actualizo los ficheros de configuracion de Sex del config_files con
los que usaba checkQuality y que estaban dentro del directorio de IRDR de PAPI.

- Añado a RS::reduceSingleObject la opcion de calcular el FWHM al final de 
una quick-reduction; tb. lo añado como opción del fichero de configuracion de PAPI.

2013-01-21
==========
- Implementado refPixelCorrection.py para el tratamiento de los
'ReferencePixels' basado en el métido de la WIRCAM (http://goo.gl/zdLdC)
- Otra alternativa para eliminarlos (trim) completamente sería mediante
el geirs2Panic de Richard M.


2013-02-27
==========
- Retomo PAPI despues de varias semanas con el OSN (WeatherServer y nueva web meteo).
- Me pongo a mejorar la rutina astrowarp para poder calibrar las imagenes de
la CCDs del OSN (T150 y  T90). De entrada no funciona con ninguna, de queja SCAMP
con el tipico mensaje de :

    """
    > Fixing the degrees of freedom
    > WARNING: Not enough matched detections in instrument A1 
    """

  - Me doy cuenta de que la orientacion no sigue la norma de Norte arriba y Este
  a izquierda. Hay que hacer un FlipY(vertical) para que las imagenes estén bien.
  No se porque en los headers dice "Mirror/Rotate 90 CW", que es lo que está
  seleccionado en Maxim/DL. Le pregunto a Fran a ver que me dice.

- Instalo la ultima version de Astrometry.net en udit22 (opensuse12.2), pero
no va bien. Da un error de dependencias de librerias .... y auque sigue trabajando,
no es capaz de resolver los campos de Roper.


2013-03-01
==========

- Reanudo pruebas de astrometría con SCAMP & Astrometry.net de cara a implementar
la calibracion astrometrica en el archivo del OSN.


2013-03-05
==========
-- Me descargo el nuevo "catalogo" de la serie index-40XX-YY.fits.bz2 que
provienen de 2MASS:

    wget -c -r -A .bz2 http://broiler.astrometry.net/~dstn/4000/ -o log.txt

Des-cromprimidos ocupan 32GB !!!

 - Lo pruebo con RoperT90 y aunque tarda mas que SCAMP, lo resulve:
 
 solve-field --scale-units arcsecperpix --scale-low 0.7 --scale-high 0.8 /home/panic/as/90/new.fits --overwrite

El mismo campo lo resuelve más rápido SCAMP usando astrowarp !!


Astromatic.net (web service)
----------------------------
...get_or_create_image(df)
  File "process_submissions.py", line 469, in get_or_create_image
    img = create_source_list(df)
  File "process_submissions.py", line 548, in create_source_list
    raise e
TypeError: cannot perform reduce with flexible type

29-Abril-2013
=============
 
- Herramientas para medir prestaciones de la máquina:
  
* sysbench 
Nota: para compilarla puede ser necesario cambiar lo siguiente:
(http://www.randombugs.com/linux/compiling-sysbench-0412-debian.html)
   En el fichero configure.ca
    #AC_PROG_LIBTOOL 
   AC_PROG_RANLIB

Seeing this variable in configure.ca I just comment the variable and re run autogen.sh. This time all works flawlessly. After this I run

./configure && make && make install
with success.

In short. Edit configure.ca:

#AC_PROG_LIBTOOL
AC_PROG_RANLIB
and re-run

./autogen.sh
and your are ready to

./configure && make && make install



* Bonnie++
* IoZone


2013-05-02
==========
- Retomo la astrometría para ROPER del T150/T90:

1- Hay que darle una matrix CDi_j que se aproxime.
2- Probar con astrometry.net y astrowarp y ver cual funciona mejor


2013-05-13
==========
- Test con Bonnie++
"""
panic@panic1:~/SOFTWARE/bonnie++-1.03e> ./bonnie++ -d /data1/bonie/
Writing with putc()...done
Writing intelligently...done
Rewriting...done
Reading with getc()...done
Reading intelligently...done
start 'em...done...done...done...
Create files in sequential order...done.
Stat files in sequential order...done.
Delete files in sequential order...done.
Create files in random order...done.
Stat files in random order...done.
Delete files in random order...done.
Version 1.03e       ------Sequential Output------ --Sequential Input- --Random-
                    -Per Chr- --Block-- -Rewrite- -Per Chr- --Block-- --Seeks--
Machine        Size K/sec %CP K/sec %CP K/sec %CP K/sec %CP K/sec %CP  /sec %CP
panic1         126G 68870  86 87450  11 50864   8 103034  93 168632   7 442.5   1
                    ------Sequential Create------ --------Random Create--------
                    -Create-- --Read--- -Delete-- -Create-- --Read--- -Delete--
              files  /sec %CP  /sec %CP  /sec %CP  /sec %CP  /sec %CP  /sec %CP
                 16 +++++ +++ +++++ +++ +++++ +++ +++++ +++ +++++ +++ +++++ +++
panic1,126G,68870,86,87450,11,50864,8,103034,93,168632,7,442.5,1,16,+++++,+++,+++++,+++,+++++,+++,+++++,+++,+++++,+++,+++++,+++
"""


"""
panic@panic2:~/SOFTWARE/bonnie++-1.03e> ./bonnie++ -d /data2/prueba/
Writing with putc()...done
Writing intelligently...
done
Rewriting...

done
Reading with getc()...done
Reading intelligently...done
start 'em...done...done...done...
Create files in sequential order...done.
Stat files in sequential order...done.
Delete files in sequential order...done.
Create files in random order...done.
Stat files in random order...done.
Delete files in random order...done.
Version 1.03e       ------Sequential Output------ --Sequential Input- --Random-
                    -Per Chr- --Block-- -Rewrite- -Per Chr- --Block-- --Seeks--
Machine        Size K/sec %CP K/sec %CP K/sec %CP K/sec %CP K/sec %CP  /sec %CP
panic2         126G 116656  99 306223  40 122402  17 107048  93 343784  19 545.2   1
                    ------Sequential Create------ --------Random Create--------
                    -Create-- --Read--- -Delete-- -Create-- --Read--- -Delete--
              files  /sec %CP  /sec %CP  /sec %CP  /sec %CP  /sec %CP  /sec %CP
                 16 +++++ +++ +++++ +++ +++++ +++ +++++ +++ +++++ +++ +++++ +++
panic2,126G,116656,99,306223,40,122402,17,107048,93,343784,19,545.2,1,16,+++++,+++,+++++,+++,+++++,+++,+++++,+++,+++++,+++,+++++,+++
"""


21-Mayo-2013
============
- Sigo haciendo pruebas de las prestaciones de los RAIDs, ahora
con la herramienta filebench, que parece muy interesante.

22-Mayo-2013
============
-Parece que la herrmienta filebench no da siempre los mismos resultados,
es decir, fluctuan bastante.



23-Mayo-2013
============
-Actualización del documento de instalación de PAPI en openSuSE12.2, 
para instalarlo en panic1/2.iaa.es y hacer pruebas.

-Miro a ver si merece la pena instalar astropy pues integra PyFITS, pyvo, PyWCS, ...
pero parece que puede haber algún problema con los imports que tengo yo
en el código aunque se podrían solventar instalando los 'Compatibility packages'.
Pero de momento lo voy a dejar.


03-Junio-2013
=============
-Instalación de IRAF:

* IRAF
mkdir -p /iraf/iraf
cd /iraf/iraf
tar -xvzf /home/panic/SOFTWARE/PANIC/IRAF/iraf.lnux.x86_64.tar.gz 
/iraf/iraf/unix/hlib/install

* x11IRAF
x11iraf (xgterm)
----------------
mkdir x11iraf (temporal directory used only for packege installation)
cd x11iraf
wget http://iraf.net/ftp/iraf/x11iraf/x11iraf-v1.5DEV-bin.redhat.tar.gz 
tar xfz x11iraf-v1.5DEV-bin.redhat.tar.gz
ln -s bin.redhat bin.suse
ln -s lib.redhat lib.suse
mkdir /usr/lib64/X11/app-defaults
sudo ./install

STSDAS And TABLES (v3.16)
-------------------------

cd /iraf/iraf/extern
wget http://stsdas.stsci.edu/download/release_2013-03/stsci_iraf-3.16.redhat.tar.gz

04-Junio-2013
=============

- Continuo con la instalación de PAPI en panic2 y comienzo pruebas de PAPI
con datos de O2k.

- Me doy cuenta de que la app kate vía ssh con panic2 va muy lenta; busco en
la red y encuentro una solución:

 > ssh -Y panic2.iaa.es  kate -graphicssystem native

(http://lists.fedoraproject.org/pipermail/users/2012-May/417786.html)

- Encuentro un bug en la version de pywcs (pywcs>=1.10.2) que usa stsci_python_2.14,
respecto las keywords PV que genera SCAMP:

""
[PAPI]: 2013-06-04 19:01:06,044 ERROR    clfits:584: Error reading RA keyword :ERROR 6 in wcsset() at line 1561 of file wcslib/C/wcs.c:
PV1_5 : Unrecognized coordinate transformation parameter.
""
-->https://github.com/astropy/astropy/issues/299

Parece que de momento no hay parche, aunque con la pywcs_1.11 que yo usaba antes 
también aparece el problema (comprobado en udit22).

- Hago un :
 
 > pip install pywcs --upgrade 
 
 y se instala la ultima version de pywcs (1.11-4.7) pero el error sigue apareciendo!!!
 
  """PV1_5 : Unrecognized coordinate transformation parameter"""


07-Junio-2013
=============
- Instalo OPTPCI-e en panic2
- Instalo driver  PlxLinux_v6.50_modified.tar.gz; con el warning del kernel ya conocido
  La version PlxSdk_v6.50_modCL.tar.gz además del warning, da un error por asm/system.h.
  En principio, comentandolo compila sin problemas, pero he optado por usar la 
  version PlxLinux_v6.50_modified.tar.gz.
  
- Hago las pruebas que me dijo U.Mall según el punto 2.15.4 del documento CARMENES-FDR-04C2-NIR-Channel-ROE.pdf,
pero no veo que el LED parpadee rapidamente como dice el manual cuando hacemos
un (rotype dgen + read);

- Además tengo algunas dudas sobre como instalar el driver para que lo lea
en el arranque del sistema. La documentación no está completa, no encuentro
el admin/plxload, aunque si hay un Plx_load/Plx_unload + argumento.
Habrá que preguntar como se instala correctamente.

 
12-Junio-2013
=============
- Videoconf de PANIC:
  Sobre el sw, basicamente hablamos del problema detectado con las pruebas
  de la OPTPCIe; sólo está Richard M., y dice que en un par de semanas
  depurará el problema.
 
- Ulrich me manda una rutina para que la compile y la pruebe en panic2 y le
mande los resultados.
 
13-Junio-2013
=============
- Pruebo la rutina de Ulrich M. con la version PLX_6.5 del driver. Antes tuve
que aniadirle al fichero  OptPCI.h la siguiente linea:

    typedef PLX_STATUS RETURN_CODE;

pues la rutina que me mandó por lo visto era para la version PLX_6.31.

- Le envio los resultados a Ulrich M. y me dice que son correctos, y que por
tanto parece que la tarjeta está funcionando correctamente.
Sin embargo, yo le comento que con la version PLX_7.00 no funciona su programa
de pruebas. Me dice que lo depurará en la próxima semanas.


14-Junio-2013
=============
- Encuentro bug importante en astrowarp debido a los cambios que estuve haciendo
para la astrometría de la imagenes del OSN.


17-Junio-2013
=============
- Encuentro una posible solución al problema que tiene pywcs con las keywords
PVi_j:
"""
Error reading RA keyword :ERROR 6 in wcsset() at line 1561 of file pywcs/wcslib/C/wcs.c:
PV1_5 : Unrecognized coordinate transformation parameter.
"""

La solución pasaría por usar el modulo wcsutil.py de http://code.google.com/p/esutil/.
y usar image2sky/sky2image.
Esta es la opción que finalmente he adopatado hasta que publiquen algún parche para la PyWCS.
V.Terrón me comentó (24-Jul-2013) que el también había encontrado dicho problema, o 
Javier Blasco, el que está usando LEMON.


- Otra opción sería convertir el modelos de distorsion de SCAMP (PVi_j) a la 
proyección SIP, como describe el articulo "More Flexibility in representing
geometric distortion in Astronomical Images", de David L.Shupe.
Le escribí un email para ver si me podrían dejar el source de pv2sip/sip2pv pero
me dijeron que no; que si quería que les mandase yo mi rutina y me dirían si
estaba bien o no comparando los resultados.


18-Junio-2013
=============
 
19-Junio-2013
=============
-Dejo mas o menos operativo astrowarp tras modificar clfits.py con image2sky.

-Intentando reducir el HAWK-I_3 (cualquier sequencia) veo que no hay manera !!!!
Miro las notas de mi libreta, y parece que ya me dió problemas en su día, pero
parece que el S3 si conseguí reducirlo sin problemas, pero no hay manera tampoco
de reducir dicha secuencia. 
Haciendo una busqueda en google, me doy con un post ***muuuy interesante *** en
el foro de astromatic.net (http://www.astromatic.net/forum/showthread.php?tid=759)
sobre esto. Parece que tengo que mejorar algunas cosas en PAPI !!!!!!!!!!!!!

20-Junio-2013
=============
- Encuentro el problema que me traia loco con pixeles saturados en el catalogo
que genera SExtractor. Todo venía porque las imagenes en cuestion tenian
la keyword SATURATE 100000, y dicha variable mayor prioridad que SATUR_LEVEL,
incluso si la damos por la linea de comandos a sextractor.

- VTerron me anuncia que los coadds deberian tener en el header el NCOADDS para
poder hacer la estimacion del limite de saturacion.


- Encuentro el problema que impedia reducir el HAWK-I-3 (cualquier secuencia): 
todo radicaba en los parametros siguientes del fichero de configuracion:


    astrometry::mask_thresh = 5   # default 1.5
    astrometry::mask_minarea = 20 # default 5

Tras establecer esos nuevos valores, se reducen sin problemas todos las 
secuencias de HAWK-I-3.

El problame esta ahora en como "parametrizar" eso de forma "automatica" para
todos los datasets (HAWKI, PANIC, O2k, ....). Quizás un fichero de configuración
distinto para cada instrumento !!!! 
Además habrá que leer bien los comentarios de E.Bertin en el foro :

    http://www.astromatic.net/forum/showthread.php?tid=759


21-Junio-2013
=============
- Me pongo a solucionar el problema de la propagacion de la key NCOADDS y 
establacer en el fichero de configuracion cual es el SATURLEVEL que se debe
usar.

  * Propagacion NCOADDS/NDIT:
     - dithercubemean - copia el header de la primera imagen, y por tanto
     propaga bien para PAPI y O2k, pero no para HAWK-I, pues el split no
     copia la key NDIT.
     Lo soluciono, pero parece que sería mejor crear una variable dentro
     del fichero de configuracion con las keywords que habría que copiar,
     pues aparece en varios sitios (mef.py, astrowarp, reductionset.py).
     
     
  * El SATUR_LEVEL ahora es multiplicado por el NCOADDS.
  
  (P) ---> Sería tambien conveniente propagar NCOMBINE, aunque eso no afecte
  al SATUR_LEVEL necessariamente !!!
  



26-Junio-2013
=============
- Modificación de astrowarp.py para que el pix_scale lo lea del fichero
de configuración en lugar de ser un parametro de la CL o algo por defecto.
Por tanto, cuando se llama a AstroWarp en reductionset.py, ya no es necesario
indicarle el pix_scale, pues lo tomará (como otros parametros) del fichero
de configuración.


27-Junio-2013
=============
* Definicion de los DATASETS de pruebas para PAPI:

  - O2K:
      - ALHAMBRA 
      - Matilde
      - Foco
      - STDs
  - HAWK-I
      - DS1 - pipeline sample
      -  


28-Junio-2013
=============
- Me doy cuenta de un problema que me trajo de cabeza probando astrowarp !
Resulta que si al ejecutar SWARP -IMAGEOUT_NAME /tmp/coadd_tmp.fits ....
existe un fichero /tmp/coadd_tmp.fits.head de una calibracion (fallida?)
anterior con SCAMP, entonces SWARP falla pues intenta aplicar en primer lugar
ese .head al fichero de salida antes de hacer el resampling+combine, por lo 
que todo falla. Tardé mucho en darme cuenta !!! no había manera !!!

Por este bug?, modifico astrowarp para que antes de lazar SWARP borre cualquier
posible fichero .head que coincida con el fichero de salida.

- Pruebas con Astrowarp en reductionset:
  
  Hago varias pruebas activando astrowarp en reductionset para el modo single,
  pero no hay manera de que funcione bien con HAWK-I, aunque si con ALHAMBRA.
  SCAMP no es capaz de calibrar Q0X (X=1,..,4); juego con varios valores de
  sextractor (threshold, minarea) pero no hay manera...!!

  La cosa es que SCAMP no se queja, pero las líneas salen en rojo, indicando
  que no ha conseguido una buena calibración !!!
  Esto me ocurre tanto con DS3-1, como con DS3-2 de HAWK-I.
    
05-Julio-2013
=============
- Termino la primera versión de la nueva web de PANIC, que salgo la cabecera, 
incluye todo lo de la anterior version.
- Falta que Matilde le de el visto bueno antes de preguntar a J.Fried si le parece
bien que la publiquemos.
- Me doy cuenta de que tengo un lio de versiones de GEIRS y que no todas funcionan igual!
Incluso, hay alguna que no funciona bien !
Intento actualizar/sincronizar todas para tener una única version.

  
08-Julio-2013
=============
- Me doy cuenta que la version de GEIRS que habia probado con el patch para 
el 'Data Generator' era con la version 6.5 del driver.
- Cargo la version 7, y me doy cuenta de que GEIRS no funciona con 'rotype dgen'.
Eso es porque el interfaz de la version 7 ha cambiado un poco.
Intento compilar GEIRS con la version 7 (actualizo el link PlxLinux -> PlxLinux_v7.00),
pero no compila, pues no tengo la versión correcta de GEIRS para la version 7 del driver.
Tras varios email, Richard Mathar me manda la nueva version.


12-Julio-2013
=============

- Soluciono un bug en RS:makeObjects()
- Encuentro bug en calDark.py:
   - iraf.mscstat no funciona !! ademas esta funcion se usa en más sitios de PAPI !!! (PENDIENTE)

   === > ERROR: Bad extension version range list


- Cambiamos a la nueva web de panic (www.iaa.es/PANIC ---> panic.iaa.es)
- Me pongo a terminar de compilar la última version de GEIRS que me mandó RM
  y que está preparada para el PLX_SDKv7.0.
  Tras instalar el jdk17-javac compilo sin mayores problemas.
  Sin embargo, al probarla no funciona bien, ni en modo offline ni en modo dataGenerator;
  tras varios read's da un SF y deja de leer.
  Sin embargo, la version GEIRS.funciona que yo hice actualizando sólo los
  ficheros que se veian afectados por el nuevo interfaz del PLX_SDK7.0, y tras
  compilarlo, dicha version si va bien, y no casca tras varios reads !!!
  Parece que hay algo en la version de RM que no termina de ir bien.
  Le mando un mail a RM informándole del problema.


16-Julio-2013
=============
- Encuentro la solución al problema de iraf.mscstat en calDark.py.
Parece que es un bug en la nuevas versiones de IRAF, según he visto en el foro
de IRAF, que tiene que ver con el nuevo esquema de image filaname template:

    https://github.com/joequant/iraf/tree/master/sys/imio/imt



mscred> mscstat @darks.txt
ERROR: Bad extension version range list
  "usigma=usigma, binwidth=binwidth, format=fmt)"
     line 81: mscsrc$mscstat.cl
     called as: `mscstat (images=@darks.txt)'
     
 
 Se soluciona desactivando el nuevo 'image template' de IRAF:
 
 """
 I think this is a problem in the new image template code. 
 You can disable this and go back to the old code by doing 

   cl> reset use_new_imt = no

  If this fixes the problem, you can make the change permanent by editing 
  the hlib$zzsetenv.def file where it is set, or by putting the above in your 
  login.cl before the final 'keep' statement.
     

mscred> reset use_new_imt = no
mscred> mscstat @darks.txt
#               IMAGE      NPIX      MEAN    STDDEV       MIN       MAX
 /data1/HAWK-I/DS1/raw/DARK/HAWKI.2008-12-02T09:09:08.909.fits[CHIP1.INT1]   4194304     743.9    29018.  -254660.   7.946E6
/data1/HAWK-I/DS1/raw/DARK/HAWKI.2008-12-02T09:09:08.909.fits[CHIP2.INT1]  4194304  820.4796  36062.24  -432327.  8688904.
/data1/HAWK-I/DS1/raw/DARK/HAWKI.2008-12-02T09:09:08.909.fits[CHIP4.INT1]  4194304  779.2797  34449.6  -315826.  8637139.
/data1/HAWK-I/DS1/raw/DARK/HAWKI.2008-12-02T09:09:08.909.fits[CHIP3.INT1]  4194304  797.3586  34720.7  -270844.  9214170.
/data1/HAWK-I/DS1/raw/DARK/HAWKI.2008-12-02T09:14:16.855.fits[CHIP1.INT1]  4194304  737.1  28678.22  -256921.  7796999.
/data1/HAWK-I/DS1/raw/DARK/HAWKI.2008-12-02T09:14:16.855.fits[CHIP2.INT1]  4194304  818.1779  35988.99  -434112.  8686048.
/data1/HAWK-I/DS1/raw/DARK/HAWKI.2008-12-02T09:14:16.855.fits[CHIP4.INT1]  4194304  779.1926  34424.16  -310828.  8622859.
/data1/HAWK-I/DS1/raw/DARK/HAWKI.2008-12-02T09:14:16.855.fits[CHIP3.INT1]  4194304  795.9526  34707.82  -273819.  9179541.
/data1/HAWK-I/DS1/raw/DARK/HAWKI.2008-12-02T09:19:24.807.fits[CHIP1.INT1]  4194304  734.7043  28655.27  -260967.  7762370.
/data1/HAWK-I/DS1/raw/DARK/HAWKI.2008-12-02T09:19:24.807.fits[CHIP2.INT1]  4194304  818.5728  36061.81  -431137.  8676647.
/data1/HAWK-I/DS1/raw/DARK/HAWKI.2008-12-02T09:19:24.807.fits[CHIP4.INT1]  4194304  778.5738  34418.44  -309162.  8672125.
/data1/HAWK-I/DS1/raw/DARK/HAWKI.2008-12-02T09:19:24.807.fits[CHIP3.INT1]  4194304  795.5871  34785.65  -274652.  9242492.




Finalmente, hice la modificación en  /iraf/iraf/unix/hlib/zzsetenv.def:

set     use_new_imt     = no



* Para solucionar el problema de la lentitud de la GUI del QL cuando es
ejecutada remotamente (ssh -X), añado al QL4/compile.sh la variable siguiente
para modificar el 'graphicssystem':

QT_GRAPHICSSYSTEM=native
export QT_GRAPHICSSYSTEM

(The "native" graphics engine uses regular X11, which will probably
always be best over SSH.)


Otra forma de llamar a las aplicaciones podría ser tal que:

    > ssh -Y panic2.iaa.es  kate -graphicssystem native
    
pero para el caso del QL no se como se podría llamar; mejor con la variable
de entorno.




17-Julio-2013
=============
- Vamos a ver si PAPI puede contamplar el caso que necesitaría Conchi para las
pruebas de laboratorio:

   --> I1 = (Raw - Dark) / FF
   --> FWHM = computeFWHM(I1)
   
   
Implementación con PAPI:
  
  1- en el fichero de configuracion,  apply_dark_flat = 1
  2- el MasterDark y MasterFlat hay que dárselo ? si !
  

Probado con el DataSet de O2k :

> ./papi.py -s /data1/O2K/Jan.2012/120103/  -S 0 0  -g filter
> ./papi.py -s /data1/O2K/Jan.2012/120103/  -S 45 45  -g filter
> ./papi.py -s /data1/O2K/Jan.2012/120103/  -S 30 30  -g filter -M lab

y parece que funciona. Habrá que ver si con eso basta para los test de laboratorio.
   
  

- Encuentro un BUG importante en applyDarkFlat; basicamente consiste en que
no se por qué, numpy encuentra valores NaN en imagenes (simuladas con GEIRS)
que con el DS9 son valores = 0 !!!
Lo que hago para 'solventar' dicho problema es sustituir los NaN (que parecen 
que corresponden a 0s) con valores 0.0 y seguir pa lante !


- Modifico CheckQuality para que se pueda especificar edge_x y edge_y. La idea
era poder indicar un 'box' específico para la estimación del FWHM, pero de 
momento lo vamos a dejar así.


18-Julio-2013
=============
- Añado chequeo de instrumento en header (validación);

Added checking of INSTRUME keyword; first key must match with
'instrument' value in config file(case-insensitive), and secondly all files 
must match the same keyword.

- ver headers (WCS) actuales de GEIRS y crear documento ???
Parece que en la última version de GEIRS, ya no aparecen los keywords para
el WCS (CTYPE, CDELT, CRVAL, ...) con valores incorrectos (=1).
Ahora, no aparecen ninguna key de WCS, salvo RA y DEC.
Sin embargo, dichas keys si la añadir el programita geirs2Panic.
 

TODO> Habrá que ver en que más lugares de PAPI puede ocurre el problema de los NaN
en los calculos con numpy (cfr. applyDarkFlat).


19-Julio-2013
=============
- Me responde RM a la pregunta de incluir WCS keys. Básicamente me dice que 
podemos usar su solucion con el fichero $CAMTMP/geirsPhduAdd.panic, aunque el
piensa que la WCS es una tarea para el Pipeline, pues con los gap de 167px no
se puede establecer una astrometría correcta. Sin embargo, yo le respondo
que una WCS básica (scale + orientacion) es necesaria no solo para PAPI, sino 
también para los usuarios que no usen el pipeline.

Al hilo de esto le pregunta cual es la diferencia entre el Clemens' workaround:

Escribir en ~/tmp/fitsheader_panic.txt la keys y en el fichero 
GEIRS/scripts/QueueFiles tenemos una linea tq:

   modify_fits_hdr -v -a ~/tmp/fitsheader_panic.txt $1 >>~/GEIRS/log/add_panic_fits.log

También el pregunto que opina de la posibilidad de MEF files.

- Le escribo a Armin/Fried preguntándole que le parece la página de AIV, por
si hay algún error. También le sigiero a Armin, que si quiere el podría ser
el editor de la parte de AIV.



26-Julio-2013
=============
- Continuo con web PANIC; primera version ETC de JF
- Pruebo el nuevo método sugerido por RM para añadir keywords a los header de PANIC (geirsPhduAdd.panic)
y aviso a AGS para que lo implementemos en el OT.
- Subo nueva version de GEIRS con las ultimas modificaciones y compilada con PLX_SDK7

29-Julio-2013
=============
- básicamente con problemas del archivo del OSN, pero también probando
el QL en panic2.


30-Julio-2013
=============
- Añado chequeo de instrumento al insertar datos en BD; esto mejoró el
comportamiento del pipeline y QL evitando la mezcla de ficheros de distintos
instrumentos, lo cual me ocurria a veces con O2k, PANIC y HAWKI.
Modifico por tanto el QL y PAPI en lo referente a esto.

- Añado pix_scale en las llamadas a CheckQuality que hay en el QL.


31-Julio-2013
=============
- Pruebo de nuevo las subwins en GEIRS: aunque dan mensajes de errores, funcionan (RM)
- Investigo un poco por el tema de las multiples hebras que crea el OT.
Parece que es una cuestion de la JVM (JVM System Threads) segun leo en internet:
http://blog.jamesdbloom.com/JVMInternals.html

Incluso creo una programilla tonto de java y ocurre lo mismo, creo un montón de hebras (24)
y usa mucha memoria (17.9G) !!
Podríamos instalar jconsole para depurar las aplicaciones de java o ver que 
recursos consumen.

- Encuentro un problema en el OT (o eso parece) al lanzar una secuecia de OBs:
OB1 - dark_serie1
OB2 - dark_serie2
OB3 - domeflat_serie1

En la segunda imagen del OB3, el header no contenia las keys propias del OT,
aunque el resto de las imagenes si. Parece algun tipo de condición de carrera
que se produce si no se actualiza a tiempo el fichero ~/tmp/fitsheader_panic.txt.
Repito el test 2 veces y no ocurre el problema, pero en una tercera vez vuelve
a ocurrir !!! y luego otra vez incluso el PQL no leyo "a tiempo" el fichero .fits
y lo descartó !!!! a dicho fichero también le faltaba la cabecera del OT.

Hago otra prueba, pero esta vez configura como destino de los datos a /data1/PANIC/LabTest,
pues dicha particion no tiene la cache de escritura en disco; sin embargo, el
problema ocurre de nuevo, y de forma evidente cuando esta corriendo el Pipeline
reduciendo datos HAWK-I-DS3 !!!!! hay una correlación directa !!!

Hago una prueba con ~/tmp/geirsPhduAdd.panic haciendo simplemente un enlace a 
~/tmp/fitsheader_panic.txt y comentando la linea de GEIRS/scripts/QueueFiles para
que no actue el modify_fits_hdr y no se producen errores !!! (hago 4 o 5 secuencias todas OK)
Quizás la solucioń esté ahí, pues evidentemente la solucioń de RM es mucho 
más eficiente.
Regreso al método original de CS ~/tmp/fitsheader_panic.txt y vuelven a aparecer
los errores en la cabeceras_OT de los FITS.
De nuevo activo el método de RM y todo OK !!! 
Parece que ~/tmp/geirsPhduAdd.panic es la solución, lo que no se es si sería
necesario que se actualizara el fichero de log ~/tmp/fitsfiles.corrected ?
(bueno, eso parece que lo sigue haciendo QueuFiles, pues el .log se sigue actualizando)


Escribo a AGS para que lo veamos a la vuelta.


01-Agosto-2013
==============
(Gracias MM !)

- Continuo haciendo pruebas de integracion (OT-GEIRS-PQL-PAPI)
- Encuentro bug en dh.isFromGEIRS() porque ha habido un cambio en la keyword
'SOFTWARE' por 'CREATOR' en la nueva version de GEIRS.
Este bug hacia que no se hiciera el split() de los frames para el procesamiento
en paralelo.

- Encuentro un "bug" que en realidad no es tal; en caso de que PAPI y QL esten
reduciendo datos usando el mismo directorio de salida (out), se produce una 
colisión y las reducciones fallarán. Por tanto, la solución simplemente pasa
por configurar dos directorios distintos en el fichero de configuración para
PAPI y para el PQL !!! por ejemplo: out_papi / out_pql

- Modifico RS para que al hacer el RS.split() de los ficheros, los .Q??.fits
se creen en el directorio temporal configurado a tal efecto en el fichero 
de configuración. Al final de la reducción, se borra dicho directorio al
hacer el purgeOutput().
De esta forme evitamos que en el QL aparezcan los .Q??.fits en la BD de outs y
por tanto en la vista de OUTS.
Realmente outs debería ser PRODUCTS !!




-Encuentro un ejemplo para reproducir sonidos (mp3) con PyQt4:

from PyQt4.phonon import Phonon

será para aniadir sonidos al PQL !!


02-Agosto-2013
==============
- Pienso en implementar el PQL alguna opcioń para histogramas y "cortes" en las
imágenes, pero me doy cuenta que todo eso lo hace DS9, así que es mejor no
reinvertar la rueda.

- Añado boton 'Aladin' a la toolbar del QL.
- Modifico en QL el #Seqs. por #Tasks y le añado la tarea actual que se esté
procesando.
- Modifico QL para que muestre cursor-reloj durante la "lectura" de un 
directorio de entrada.
- Encontrado un bug en RS.getCalibFor() en la búsqueda de darks



05-Agosto-2013
==============
- Hago pruebas con HAWK-I-4, un DS con 18 imagenes, y da un error al calcular
los offsets. Intento averiguar por qué ocurre...
Quizás haya que ampliar la ventana de búsqueda y por ende el MAXNCC en IRDR.


06-Agosto-2013
==============
- Siguiendo con los problemas con HAWK-I-4, modifico los valores de Sextractor
de DET_THRESHOLD, MIN_AREA para tener más estrellas.
La cosa va algo mejor, pero sigue dando falsos offsets, pues el corr_fraction
es muy bajo, y como tenía MINFRAC=0.001 pues siempre pasaba el "filtro".
Por tanto, restauro MINFRAC=0.1, un valor más sensato (originalmente era 0.15),
y ahora pues da errores por no superar dicho umbral MINFRAC !!

Cambio la cte. MAXNCC de 300 a 1024 en correlate.h
 
#define MAXNCC 1024      /* max dimension of cross-correlation image [pixels] */


- Tras hacer esos cambios, ahora si hace bien el stack (coadd1.fits); sin embargo
al hacer la astrometría, SCAMP no puede y falla. En primera instancia, pienso
que un error importante puede estar en la astrometría inicial de la cabecera, que
corresponde con la de la imagen0 del stack, y que no tiene por qué coincidir 
con la astrometría de la coadd1.fits generada, dependerá de como hayan sido
los offsets del dithering. Por tanto, habría que corregirla ....
Quizás con SWARP esto se podría resover...
Quizás añadiendo el "border" a CRVALn se corriga el error ??

Habraía tambien que hacer el "trim" de la image coadd1.fits para quitarle el 
marco negro que genera dithercubemean().

(P) A las imagenes de coadd1.fits le falta el END (pues ahora no pasa ??)
(P) Hay que añadir el border (=NAXISn_orig-NAXISn_new) a CRVALn --> Hecho !


07-Agosto-2013
==============
- Sigo con la pruebas en HAWK-I-4, pero no hay manera de que SCAMP
los calibre !!! he probado de todoas formas, pero no hay manera. Sin embargo,
Astrometry.net si lo hace a la primera sin problemas !!
Incluso si le doy una imagen calibrada con Astrometry.net a SCAMP, este tampoco
es capaz de calibrarla !!! No se si será por la falta de objetos, por el cambio
de ejes (no creo pues para eso tiene la WCS) o por la escala tan baja.

- Pruebo a reducir HAWK-I-DS3-3 y tampoco puede ! falla en la astrometría !

08-Agosto-2013
==============
- Modifico los parametros del fichero de configuracion:

    mask_minarea = 10   # sex:DETECT_MINAREA used for object masking
    mask_thresh = 7.0

pues son **críticos** para la calibración correcta con SCAMP !!!
Y con esos valores ya si se reducen DS3.

TODO: ¿ cómo encontrar unos valores  **universales** para dichos parametros ?

- Modifico misc/imtrim.py pues tenía un bug importante y ademas no estaba muy
python styled. Le añado el parametro 'step', sin embargo aún no hace del todo 
bien el trimming, pues deja un marco, pero es debido a filas/columnas ruidosas
que no de pueden detectar facilmente !! imtrim.py sólo busca filas/columnas
constantes.
Además compruebo que iraf.imcopy() hace la actualizacion correspondiente
a WCS debida la recorte de la imagen !


- Añando el imTrim en RS tambien en el caso de single_reduction, justo
despues de crear el coadd1.fits


09-Agosto-2013
==============
- Modifica el RS.reduceSeq() para que al final se haga el imTrim(); sin embargo
esto provoca un "error", pues iraf.imcopy() modifica el WCS_header, eliminando
los valores CDi_j que son cero, lo que provoca luego que clfits de un error 
pues wcsutil.py (E.Sheldom) necesita todos los CDi_j.
De momento lo voy a dejar así, pues aunque podría modificar el wcsutil.py, no
me quiero meter en eso de momento (a ver si mientras astropy lo soluciona).

- Leyendo el documento "DR01/02 Topical Report:
Background subtraction from imaging data" (http://bit.ly/17bykKb), leo un par
de cosas interesantes:

   (1) Parece que SCAMP podría también trabajar sin un catalogo de referencia ---> SOLVE_ASTROM = N
   (2) SWARP hace el combine mediante un algorimo de media/mediana con 
    pesos o sin pesos, pero no es capaz de hacerlo con un algoritmo de 
    rechazo (sigma clip). Quizás sea mejor usar otro app (IRAF.imcombine)
   (3) Es dificil conseguir unos parámetros universales  para cualquier 
    data set. Sin embargo, podemos intentar tener unos parametros "robustos"
    que funcionen para la mayoría de los casos, y también los parámetros 
    "optimos" serán específicos para cada DS.
   (4) Habría que "limpiar" el catalogo de Sextractor antes de pasarlo a SCAMP,
    para quitarle objetos con baja SNR, CR, estrellas saturadas, etc ...
 

(P) Ver el error en las cabeceras de las coadd1.fits !!! NO veo que está mal,
de echo los coadd1.fits tienen su 'END'

- Intento hacer con IRAF el stick del mosaico final calibrado con SCAMP, pero 
no hay manera; pruebo con imcobine, combine, pero no lo hace bien, de echo
crea una imagen que no se correspondo en nada con la que crea SWARP.
Todo esto es a raiz del punto (2) de arriba para encontrar una alternativa
a SWARP.
Tendremos que seguir por tanto con SWARP.

- Compilo la nueva version que me mandó RM el 31-Jul con soporte para MEFs.
Le envio un mail con los siguientes comentarios:

"""
I have just tried your new version supporting MEF files. I am not sure if the 
save command need some special parameter, but what I get when 
run 'read' + 'save' is a MEF FITS file with:

1-Primary header
2-extended header with a not complete WCS (CRVALn need CRPIXn values)
3-the 4kx4k image

However, when sub-windows are used as you suggested, then a MEF file with 
primary + 4 (extensions+image) is generated.

I think that an extra parameter for the 'save' command (eg, -M) could be 
used to produce MEF files without needing to define previously the sub-windows. 
what do you think ? 
"""


- Le hecho un vistazo a Distribute for Python para instalar paquetes de python;
en principio no parece obvio....

http://pythonhosted.org/distribute/index.html

Abrá que verlo con más detalle.



13-Agosto-2013
==============
- Instalación de astrometry.net en panic2 y todo el catálogo (index) para
porder hacer pruebas y construir una rutina de astrometría robusta para el
OSN y para PANIC.

-Sobre Astrometry.net y la distorsión, encuentro en el foro lo siguiente de 
Dustin: (https://groups.google.com/d/msg/astrometry/Ky1er5VpY3c/xkS6IWtvwfAJ)

A couple of ideas for the distortion:

1.  You could try increasing the matching distance: say, "solve-field -c 0.02" or 0.03 or whatever, to let the shape-matching be more accepting.

2.  You could try taking the WCS from the central region (which solves) and using it as an initial guess for the whole image.  The "tweak" process then might be able to find matches in the middle part and "grow" the matching region out to the edges.  The only complication doing that is that when you plug the solved WCS back into the whole image, you will need to adjust the "CRPIX" values to compensate for the offset of the subimage.  That is, if your central subimage starts at pixel 1000,1000, then you want to add 1000 to CRPIX1 and CRPIX2 in the WCS FITS header before plugging it back into the whole image; you might want to use the "new-wcs" program to plug the WCS header into (a copy of) the original image.

3.  More work: You could try to try to figure out the functional form of the distortion and remove it.  With a fish-eye lens, the distortion is probably all radial (you would hope!).  Try grabbing the largest sub-image that still solves and produces a good-looking "-indx.png" plot (red circles and green circles aligned).  In the ".corr" file you have a list of the X,Y,RA,Dec positions of stars in your image, and reference stars, that we think matched.  Plot the sqrt((field_x - XC)**2 + (field_y - YC)**2) vs sqrt((index_x - XC)**2 + (index_y - YC)**2), where XC,YC is the image center.  That is, plot the radial difference in the image stars and index stars.

The catch is that by default we try to correct the distortion with SIP coefficients, so either turn that off with "solve-field --no-tweak", or try using wcs-rd2xy with the "-t" flag to ignore the SIP terms, to project the RA,Dec coordinates in the .corr file into (distorted) X,Y coordinates, and then make the plot as above.



> However, I cannot find a way to open those FITS BINTABLEs. I just want to extract the coordinate, RA and DEC, as well as the magnitude from both the image and index files to get a ASCII file, such as .dat or .txt, but I cannot find a way to do that. Would you please to help me?

Try the "tablist" program, eg     "tablist out.rdls"



> Besides, when I tried to use: wcs-xy2rd -w wcs-file -i xy-list -o radec-list To convert a list of pixel coordinates to RA,Dec coordinates, it says that: 

anwcs.c:957:anwcs_open_wcslib: Wcslib support was not compiled in anwcs.c:979:anwcs_open_wcstools: WCStools support was not compiled in wcs-xy2rd.c:57:wcs_xy2rd: Failed to read WCS file "wcs-file", extension 0 wcs-xy2rd-main.c:168:main: wcs-xy2rd failed

You shouldn't need wcstools or wcslib.  Probably the "wcs-file" you told it to use doesn't exist.  What is the exact command-line you are using to run wcs-xy2rd?


14-Agosto-2013
==============
- Probando HAWK-I-4 con Astrometry.net (v0.42) encuentro un bug y se lo mando a
code2@astrometry.net:
"""
I think there is a bug in file (v0.42):

astrometry/util/fits2fits.py , line 56

it concerns 'cards' variable, what should be 'hdr.cards'.

I hope it helps.
"""

Tras resolver yo el bug, Astrometry.net resuelve los campo de forma muy rápida
sobre todo si le das RA, DEC,radius,scale como parémetros de entrada.


(P) añadir from __future__ import division a PAPI


19-Agosto-2013
==============
- Pruebo la nueva version que me mandó Dustin de 
http://astrometry.net/downloads/astrometry.net-23260.tar.gz
y ya soluciona el problema en fits2fits.py.

- También pruebo el nuevo catálogo (index-42xx) para astrometry.net
que me bajé en panic2, y parece que también funciona. 
La actualizacion del catálogo fue realizada porque la serie 4000 tiene un bug.
http://astrometry.net/doc/readme.html#getting-index-files

- Continuo con la implementación del nuevo solver de astrometría basado
en Astrometry.net:


22-Agosto-2013
==============
- Continuo con implementación de solver con astrometric.net.

23-Agosto-2013
==============
Ficheros no resueltos:
['/data1/OSN/RoperT150/11_12_13/PG2213-006-001B.fit', '/data1/OSN/RoperT150/11_12_13/PG2213-006-001U.fit', '/data1/OSN/RoperT150/11_12_13/PG2213-006-003V.fit', '/data1/OSN/RoperT150/11_12_13/SA110-266-002U.fit', '/data1/OSN/RoperT150/11_12_13/PG2213-006-001I.fit', '/data1/OSN/RoperT150/11_12_13/SA110-266-003B.fit', '/data1/OSN/RoperT150/11_12_13/PG2213-006-001R.fit', '/data1/OSN/RoperT150/11_12_13/SA110-266-003U.fit', '/data1/OSN/RoperT150/11_12_13/PG2213-006-002V.fit', '/data1/OSN/RoperT150/11_12_13/PG2213-006-003B.fit', '/data1/OSN/RoperT150/11_12_13/SA110-266-001U.fit', '/data1/OSN/RoperT150/11_12_13/Campo GRB130606A-001I.fit', '/data1/OSN/RoperT150/11_12_13/PG2331-003U.fit', '/data1/OSN/RoperT150/11_12_13/SA110-266-002B.fit', '/data1/OSN/RoperT150/11_12_13/PG2213-006-003I.fit', '/data1/OSN/RoperT150/11_12_13/PG2213-006-002U.fit', '/data1/OSN/RoperT150/11_12_13/PG2213-006-003R.fit', '/data1/OSN/RoperT150/11_12_13/PG2331-001U.fit', '/data1/OSN/RoperT150/11_12_13/PG2213-006-002R.fit', '/data1/OSN/RoperT150/11_12_13/PG2331-002U.fit', '/data1/OSN/RoperT150/11_12_13/Campo GRB130606A-001R.fit', '/data1/OSN/RoperT150/11_12_13/PG2213-006-003U.fit', '/data1/OSN/RoperT150/11_12_13/SA110-266-001B.fit', '/data1/OSN/RoperT150/11_12_13/PG2213-006-001V.fit', '/data1/OSN/RoperT150/11_12_13/BE90_campo3-005U_600.fit', '/data1/OSN/RoperT150/11_12_13/PG2213-006-002B.fit', '/data1/OSN/RoperT150/11_12_13/PG1633-003U.fit', '/data1/OSN/RoperT150/11_12_13/PG2213-006-002I.fit']

26-Agosto-2013
==============
- Implemento la version Multiprocessing de solve-roper.py; hago pruebas
y en principio funciona.


29-Agosto-2013
==============
- Básicamente sigo haciendo mejoras y pruebas con solve-roper.py
- Modificación a script para imagenes de Radar del OSN.


30-Agosto-2013
==============
- Encuentro la herramienta Redmine como la mejor candidata para las 
incidencias del OSN.

- Básicamente sigo haciendo mejoras y pruebas con solve-roper.py

- Intento resolver unas image de O2k que me bajo del archivo de CAHA,

/data1/O2K/tests/o2k-20080121-23:05:03-sci-0801.fits
/data1/O2K/tests/o2k-20080121-23:06:26-sci-0801.fits
/data1/O2K/tests/o2k-20080121-23:10:43-sci-0801.fits
/data1/O2K/tests/o2k-20080121-23:17:51-sci-0801.fits
/data1/O2K/tests/o2k-20080121-23:19:16-sci-0801.fits
/data1/O2K/tests/o2k-20080121-23:36:09-sci-0801.fits
/data1/O2K/tests/o2k-20080121-23:38:52-sci-0801.fits
/data1/O2K/tests/o2k-20080121-23:40:13-sci-0801.fits
/data1/O2K/tests/o2k-20080121-23:42:56-sci-0801.fits
/data1/O2K/tests/o2k-20080121-23:49:44-sci-0801.fits

Pero solve-roper no puede resolverlas de ninguna manera y aparentemente no
veo ningun error.

Sin embargo, subo una image al servicio de Astrometry.net y si es capaz de 
resolverla pero usando el index-205-quad.fits.

http://nova.astrometry.net/status/62246

Como no se porqué pasa eso, copio algunos index-20xx.fits que tengo para que 
también los use solve-field, pero tampoco es capaz de resolver el campo.

Entonces, pregunto en el foro (Google) de Astrometry.net para ver por qué ocurre
eso.


- Luego, también me doy cuenta de que no se resuleven los siguientes imagenes:

['/data1/OSN/RoperT150/11_12_13/SA110-266-002U.fit', '/data1/OSN/RoperT150/11_12_13/biasbin1-018.fit', '/data1/OSN/RoperT150/11_12_13/SA110-266-003B.fit', '/data1/OSN/RoperT150/11_12_13/SA110-266-003U.fit', '/data1/OSN/RoperT150/11_12_13/SA110-266-001U.fit', '/data1/OSN/RoperT150/11_12_13/Campo GRB130606A-001I.fit', '/data1/OSN/RoperT150/11_12_13/PG2331-003U.fit', '/data1/OSN/RoperT150/11_12_13/SA110-266-002B.fit', '/data1/OSN/RoperT150/11_12_13/PG2331-001U.fit', '/data1/OSN/RoperT150/11_12_13/flat-009V.fit', '/data1/OSN/RoperT150/11_12_13/PG2331-002U.fit', '/data1/OSN/RoperT150/11_12_13/Campo GRB130606A-001R.fit', '/data1/OSN/RoperT150/11_12_13/SA110-266-001B.fit', '/data1/OSN/RoperT150/11_12_13/BE90_campo3-005U_600.fit', '/data1/OSN/RoperT150/11_12_13/PG1633-003U.fit']

y 

02-Sep-2013
==============
- Tras la respuesta de Dustin (Astrometry.net) sobre downsample=2, pruebo
con otra imagen de O2k, y ahora ni en el Web ni en local se resuelven:

http://nova.astrometry.net/status/62794

Sin embargo, en el archivo de CAHA me bajé también la misma imagen calibrada
astrometricamante !! no se como pudieron hacerlo ???? realmente no hay casi
fuentes !!!


Por otro lado, encuentro un problema reduciendo el DS de O2k:

/data1/O2K/tests/o2k-20080121-23:05:03-sci-0801.fits
/data1/O2K/tests/o2k-20080121-23:06:26-sci-0801.fits
/data1/O2K/tests/o2k-20080121-23:10:43-sci-0801.fits
/data1/O2K/tests/o2k-20080121-23:17:51-sci-0801.fits
/data1/O2K/tests/o2k-20080121-23:19:16-sci-0801.fits


no puede calcular bien los offsets !!!!
Modifico en el fichero de configuración los valores para la sección [skysub]

# Object mask
mask_minarea = 10   # sex:DETECT_MINAREA used for object masking
mask_thresh = 1.5   # sex:DETECT_THRESH used for object masking (1.5)

dejando para la sección [offsets] 5 y 4.5 respectivamente. Ahora SI calcula 
bien los offsets !!! Pues no tiene falsos objetos que es lo que ocurría antes,
pero al subir mask_thresh= 4.5 no quitamos falsos objetos. En [skysub] si nos
interesa por el contrario eliminar todos los objetos posibles, por eso lo dejamos
más bajo ....

Otro problema con este DS es que hay muchas "sombras" de objetos, es decir, que no
los enmarcara bien para la resta del cielo !!! 
Pruebo con varios parametros de [skysub:mask_thresh] = 1.5, y mejora, pero aún
se notan sombras.
(P) Probar con los ficheros de calibración (DARK, FLATS) para ver si lo
se reducen mejor.


16-Sep-2013
===========
- Modificacion en dataset.py para eliminar la restricción de max_ra_dec_offset
en los ficheros de calibracion (dark, flats), pues o tendría mucho sentido.



17-Sep-2013
===========
- Modificación (menor) de modFITS.py para que pueda ser utilizado para
actualizar los headers del OSN por los operadores.

- Bug: elimino el Trim de los productos de PAPI que sean calibraciones (master_dark, master_flats, etc),
pues no tiene sentido hacerles un trim/crop. Eso solo tiene sentido en images
de ciencia con dithering.
 
- Reduciendo un DS de O2k que me bajé del archivo de CA, encuentro problemas
con la identificacion de los MASTER de calibracion. Para solucionar el problema
tuve que modificar clfits.py para que reconozca bien PAPITYPE y IMAGETYP.

 IMAGETYP ---> lo 'escribe' el OT, GEIRS no lo genera
 PAPITYPE ---> lo 'escribe' PAPI cuando genera ficheros de calibracion (MASTER_DARK, etc ...)
 
- Encuentro (de nuevo) el problema de dividir por cero en applyDarkFlat.py.
Para solucionarlo, se me ocurre que a igual que hace iraf.ccdproc con minrepl=1.0,
sustituir los valores menores que un cierto __epsilon por 1.0 para evitar
divisiones por cero.

#sci_data = (sci_data - dark_data) / flat_data
# To avoid NaN values due to zero division
__epsilon = 1.0e-20
flat_data = numpy.where(numpy.abs(flat_data)<__epsilon, 1.0, flat_data)

Otra forma de hacerlos sería como sigue:
 sci_data = numpy.where(flat_data==0.0, 
                                     (sci_data - dark_data), 
                                     (sci_data - dark_data) / flat_data )

O tambien con máscaras, pero me gusta mucho menos:

result = np.empty_like(data) 
  mask = (data == 0) 
  result[mask] = 0 
  result[~mask] = 1.0/data[~mask] 

Nota:
iraf.ccdproc(...)  
 minreplace = 1.
        When processing flat  fields,  pixel  values  below  this  value
        (after  all  other  processing  such as overscan, zero, and dark
        corrections) are replaced  by  this  value.   This  allows  flat
        fields  processed  by  ccdproc  to be certain to avoid divide by
        zero problems when applied to object images.

__fin_nota__

Lo probé y funcionó correctamente, o al menos no hubo fallos y el Warning
de división por cero desapareció.

(P) Ver dónde más es necesario solucionar la division por cero.
    Me queda la duda de ver como lo soluciona iraf.imarith(...)

(P) Ver si sería conveniente usar 'expand_mask' en la mascara de objetos.



24-09-2013
----------

- Conversion repositorio de SVN a GIT
- Limpieza de irdr/makefile para que solo se compile lo que es necesario para PAPI
- Encuentro (o reencuentro) la rutina irdr::nlinmap.c para el calculo de la no-linealidad;
no obstante no se que entradas necesita dicha funcion.

- (P) Pensar si merece la pena hacer el dilate de la mascara de objetos !!! 

- Creo un branch llamado 'limpia' para tener una version para distribuir y 
limpia de todas mi cosas personales o de pruebas/demos/etc...
Habrá que ver como puede luego hacer el merge de 'limpia' con 'master'


25-09-2013
----------
- Consigo hacer el merge de 'limpia' con 'master':

    1) nos movemos al brach 'limpia'
       > git checkout limpia
    2) hacemos el merge de 'limpia' con 'master'
       > git merge master
    Esto nos añade/mezcla todos los cambios realizados en master en los ficheros
    que sean comunes con limpia, pero no añade los que no existan.
    
    En caso de conflicto, deja el fichero que haya en 'limpia': con esto evitamos
    que los ficheros modificados de master que no esten en limpia den un conflicto.
    Para mas detalles sobre el tema: http://goo.gl/GA73zM
    ---> 'Prevent merging a file from master with Git'

      > git merge master --strategy=ours

      Realmente eso no funciona, y hay que borrar (git rm) lo que se haya
      añadido de la rama master (git mergetool). No he encontrado otra forma...
      

- Comienzo la mejora del chequeo del numero de argumentos de la CL, que no lo 
hacia del todo bien.

26-09-2013
----------
- Continuo con la depuración del chequeo del número de argumentos de la CL de
todas las aplicaciones principales.

- Añando "main" a remove_cosmics.py para que pueda ser llamado tambien desde la
CL.

- Undo a Git merge? --> http://goo.gl/We5IhI


* Create a new repository on the command line

touch README.md
git init
git add README.md
git commit -m "first commit"
git remote add origin git@github.com:ppmim/PAPI.git
git push -u origin master

* Push an existing repository from the command line

git remote add origin git@github.com:ppmim/PAPI.git
git push -u origin master


01-10-2013
----------

- Añado opción de "Focus Evaluation" al QL
- Modifico PAPI para que reconozca los ficheros de serie de foco de O2k (OBJECT=contain(focus)) 
y en principio de PANIC tambien (IMAGETYP=FOCUS); sin embargo el Pipeline
como tal no los "reducirá" pues no tiene sentido. Si se procesarán para calcular
el foco óptimo desde la opcion "Focus Evaluation" del QL:Popup-menu, y por 
supuesto desde la linea de comandos > eval_focus_serie.py

- Soluciono problema con valores por defecto de max_diff_ra_dec, ... en Setup
del QL.


02-10-2013
----------
- Retomo las pruebas con GEIRS+OT para ver como tratar los datos en formato 
MEF y/o con subwindows.
Me doy cuenta que con la actual implementación, si definimos una subwindow para
simular los MEF (solución que sugirio RM), tq:

subwin clear
subwin SW 1 1 1 2048 2048
subwin SW 2 2049 1 2048 2048
subwin SW 3 1 2049 300 300
subwin SW 4 2049 2049 2048 2048
subwin SW on
read
save

Al hacer el 'save -i' (como hace el OT), se graban como ficheros independientes 
e integrados los coadds, es decir, no un MEF, sino 4 ficheros terminados en _winX.fits; 
pero si hacemos 'save' a secas, entonces se graba un único MEF con un cubo sin
integrar con tantos planos como NCOADDS.
(para más detalles ver mail de 12-Agosto-2013)

Lo ideal sería poder obtener un MEF 'integrado', sin cubo, pero parece que RM
no está por la labor....

Una opción sería usar geirs2Panic para convertir las _winX.fits en un sólo fichero,
y además permite hacer alguna otra cosa, como eliminar los ReferencePixel, etc.

- Resumiendo:

  1) si tenemos MEF, hay que sumar el cubo de cada extensión
  2) si no tenemos cubo, pero si subwin, hay que conseguir que PAPI reconozca
  dichos ficheros (algo complicado), o bien usar geirs2Panic ?? voy a ver


IMPORTANTE: 

- Aclarar muy bien que tipo de datos (FITS) aceptará PAPI & QL !!!

- Implemento collapse_mef_cube en collapse.py y lo pruebo desde la CL y con una
secuencias de DARK MEF cubes y PAPI lo hace correctamente !!!!
Parace por tanto que PAPI trata correctamente los MEF incluso cuando son calibraciones !!


03-10-2013
----------
- Encuentro BUG grande en PAPI: las imagenes de ciencia de PANIC en formato 'single' 
extension, es decir, no MEFs (aka. CStorz type) no se 'parten' con el metodo 
split() pues no son MEFs. Como consecuencia no se hace procesamiento paralelo de
cada cuadrante !!!! sólo se hacia con las images de HAWK-I !!

- Modifico metodo RS:slipt() y mef.doSplit() para que se haga correctamente !

- Encuentro un problema en IR::offsets.get_wcs() pues intenta leer de las
cabeceras de PANIC la keyword ROT-RTA, que no existe, sólo existe en las imagenes
de O2k. 
Le pregunto a RM, pues encuentro el siguiente comentario en la documentación:

"""
A second set of telescope and optics related variables which is not useful in the LBT context consists
of WPOS, FILTER, FILTERS, T FOCUS, CASSPOS, POLPOS, TEMP A, TEMP B, PRESS1, PRESS2, ROTSTAT,
and various ROT *, all of which stem from CAHA methods and all of which should also be deleted
unless the instrument is PANIC. 
"""

Esto se descubre ahora pues es la primera vez que el PAPI pasa por ahí con imagenes
de PANIC !!

- Despues de todas las modificaciones, hago pruebas en panic2 con DS de HAWK-I y
de PANIC, y O2k


04-10-2013
----------

(P) Ver por qué ocurre este error al final de la reducción de HAWK-I o de O2k.
Parace una tonteria, pero mejor verlo con detalle !

    [PAPI]: 2013-10-03 18:32:10,858 WARNING  clfits:574: ITIME keyword not found
    [PAPI]: 2013-10-03 18:32:10,859 WARNING  clfits:595: READMODE keyword not found
    [PAPI]: 2013-10-03 18:32:10,859 WARNING  clfits:607: DATE-OBS keyword not found
    [PAPI]: 2013-10-03 18:32:10,860 ERROR    clfits:632: Error reading RA keyword :'cd1_2'
    [PAPI]: 2013-10-03 18:32:10,860 DEBUG    clfits:635: RA = -1
    [PAPI]: 2013-10-03 18:32:10,861 ERROR    clfits:658: Error reading DEC keyword : 'cd1_2'

- Soluciono ese "error"/bug modificando en wcsutil.py el método WCS::ExtractFromWCS
donde se hace la lectura de la matriz CDi_j. Debido a que el standard FITS no
obliga a que aparezcan todos los terminos y suponer =0 aquellos que no aparezcan.


- Encuentro explicación interesante sobre el background modeling en la 
documentación de THELI:
http://www.astro.uni-bonn.de/theli/gui/aboutbackground.html#about-background-label


07-10-2013
----------
- Pruebas con subwin no-full-frame: se graban como MEF no integrados. El modo integrado no esta soportado.

  1) serie de DARK igual tiempo - parece OK, no error
  2) serie de SCIENCE - en princopio OK, no error, pero no pude llegar al final por que no son imagenes reales (se quedó en los offsets !)

- Le escribo a RM para preguntarle por algunas cuestiones que parece
que no funcionan correctamente en GEIRS:

   > save without parameters, always produce cubes 
   > crep < 5 rrr-mpia mode or <2 lir mode


11-11-2013
----------
- Instalo la nueva version de GEIRS (r709M) en papi2, que finalmente resuelve
los problemas con el 'camera.texi'.
La nueva version, entre otras, incluye:
 - nuevo comando lamp
 - soporte para MEF con 'save -M'
 - limpieza en los headers
 - mecanismo mejorado para añadir keywords a los headers --> new FITS-header update scanner ( ~/tmp/geirsPhduAdd.panic_[1-5]) 


14-11-2013
-----------
- Actualizo las web con las correcciones de Richard Mathar.
- Escribo email a Enrique de Juan (CAHA) sobre el tema del archivo. Finalmente
hablo con el por email para aclarar algunas cosas:

   - no me pueden pasar un "cliente-FTP" para pruebas del archivo; lo haré yo
   - en cuanto a la frecuencia en la que se ejecuta dicho cliente, Enrique no
   me supo concretar, dijo eque depende del instrumento (cada 5', 30',...)
   Incluso, si diese problemas con la adquisición de datos, se podría lanzar
   el procedimiento de copia al final de la noche (esto es lo que hacen
   en O2k, pues la GEIRS no va bien si está a la ves el FTP activo)

   - le paso los ejemples de los ficheros de PANIC (headers, MEF, etc); los probará 
   y ya nos contará
   - en cuanto a la cabina de discos para el archivo, lo consultará a ver que pasa.

- encuentro una utilidad que me puede servir para simular la copia de datos
del archivo de datos, aunque necesitará mejoras y modificaciones:

   https://github.com/jererc/sftpsync-py (SFTP)

   pero como lo que usa CAHA es FTP, usaré :

http://svn.python.org/projects/python/trunk/Tools/scripts/ftpmirror.py
   


18-11-2013
-----------
- Me m
- Encuentro un programilla en Python para simular el comportamiento del Archivo
de datos de CAHA, que accede al repositorio de datos de la máquina de PANIC
vía FTP de forma periódica para copiar los últimos ficheros que haya.
Dicho programilla es: ftpmirror.py

http://svn.python.org/projects/python/trunk/Tools/scripts/ftpmirror.py

y para la simulación habrá que ponerlo en el crontab para que se ejecute por 
ejemplo cada 5minutos (?, CAHA no me supo dar un valor para dicha frecuencia; 
incluso me dijo que podría activarse al final de la noche si hubiese problemas):

>> python ftpmirror.py -v -l panic -p panic1 udit22.iaa.es /home/panic/DATA/pruebaRS /data2/pruebaRS

19-11-2013
-----------
- Mirar este método de estimación de offsets en imágenes:

   https://github.com/t-brandt/acorns-adi


20-11-2013
-----------
- RM me dice (muy correctamente) que la velocidad de lectura depende de varios
factores:

      The image rate is a function of
      - the pixel read time (basically), usually called pread
      - the cycle type (which defines frame versus image rates)
      - the size and location of the subwindows (if defined as HW windows)
      - multisampling parameters (EMS)
      and possibly other factors.


- Encuentro la forma de cambiar al "modo de lectura rapida" (fast readout mode)
o "pixel readout rate". Esto se hace mediante el comando sigueinte:

> roe pread 10000 (ns, 100kHz)
> roe pread 1000  (ns, 1Mhz)

FALSO !!! eso no es fast-readout-mode del que habla el documento PANIC-ELE-TN-04,
pues no está implementado aún en GEIRS.
Con el pread cambiamos el 'pixel clock' que afecta al FTE y por tanto al nivel
de ruido. Para cualquier de los modos de lectura actuales (lir, rrr, ...), un
valor mayo de 150 kHz no tiene sentido, pues la imagen es muy ruidosa.
Para más detalles ver email de U.Mall del 20-Nov-2013.


- Enrique de Juan (CAHA) responde de nuevo con un mail sobre los FITS; entre 
otras cosas, lo más destacado es que a petición de RM, sugiere el siguiente
formato de nombre de ficheros:

pan-YYYYMMDD-HH:MM:SS-sci-juaE[-x].fits

Instrument:    "pan"  from PANIC
Date:              YYYYMMDD-HH:MM:SS
Image Type     "sci", "cal" or "tst"
IP (not observer)    "juaE" from Enrique Juan, for example
[-x]  Opcional, use it if is needed, for example in order to solve the problem of two images with the same date.

Además, dice quen no se permiten subdirectorios en el directorio de la noche.

- Enrique de Juan dice que siguen trabajando con la imágenes que le pase de PANIC
para ver como las procesa el archivo de datos de CA.

- U.Mall escribe un email en el que aclara el tema del slow/fast readout mode 
del detector de PANIC. Como conlusión:

   "Todos los modos de lectura que actualemente están implementados en GEIRS están
    en modo slow. El modo fast no está actualmente implementado.
   "

U.Mall deja indicado el documento PANIC-ELE-TN-04 para los detalles de 
implementación de Fast-Readout-Mode.
Con el roe->pread cambiamos el 'pixel clock' que afecta al FTE y por tanto al nivel
de ruido. Para cualquier de los modos de lectura actuales (lir, rrr, ...), un
valor mayo de 150 kHz no tiene sentido, pues la imagen es muy ruidosa.
Para más detalles ver email de U.Mall del 20-Nov-2013.


- E. de Juan (CAHA) me dice que ha probado el network-bounding y que es fácil y
que lo podremos usar en PANIC para la conexión con el Archivo de CAHA.
http://es.opensuse.org/Bonding


21-11-2013
-----------
- Actualización de TN sobre los FITS headers
- Compendio de todas las notas del las revisiones del SW de PANIC (OT y QL),
para tenerlas como guia para la integración de software con AGS


22-11-2013
-----------

- Encuentro en el NOT cosas muy interesantes sobre:

  a) Linearity correction --> http://www.not.iac.es/instruments/notcam/calibration.html#nonlin
  b) Image distortion --> http://www.not.iac.es/instruments/notcam/calibration.html#dist 
     Usa IRAF:geomap

- También encuentro esto interesante sobre la distorsion del campo de ISAAC:

http://www.eso.org/sci/facilities/paranal/instruments/isaac/inst/field_distortion.html 


- Además, encuentro el paquete alipy, para alinear imagenes :

http://obswww.unige.ch/~tewes/alipy/index.html


25-11-2013
-----------
- Encuentro un bug en GEIRS que hace que los FITS no se graben correctamente,
pues cada vez que se hace un 'save -i', el fichero tiene un tamaño distinto.
Le escribo RM y reconoce el problema.

Así no hay manera de hacer pruebas, pues PyFITS salta por todos lados, incluso
en clfits.py la rutina fits_simple_verify.

- RM me manda a ultima hora de la tarde la version 710 de GEIRS que se supone
solucina el bug.
Parece que si está solucionado, pero el QL falla en la imagen 2 de una secuencia
de 5 darks,  dice que la 2da. imagen está corrupta !!! quizá sea problema de 
sincronización ...que intenta leer la imagen antes de tiempo !!



26-11-2013
-----------
- NTP Config:
  - Añado los servidores (incluido IAA) a /etc/npt.conf
  -Añado el servicio NTP al initd para que arranque con la máquina:
     >chkconfig --add ntp
     >service ntp status|start

- Pruebas nueva version GEIRS + OT + PQL:
  
  * Detecto aún problemas de sync con PQL y FITS generados; lo suyo sería
  usar (CHECKSUM & DATASUM)
  * Detecto que hay veces que el FITS no contiene los keys del OT, incluso
  aunque use /home/panic/tmp/fitsfiles.corrected. Por tanto no es problema
  del OT el que no incluyan, aunque el OT debería detectar el problema
  y avisar en lugar de tragarse la imagen y clasificarla como SCIENCE !!

  Despues de hablar con AGS, me dice que no hace un 'sync save' pues
  en su día Clemens le dijo que el read y save se pueden hacer a la vez
  para ahorrar tiempo. 
  Entonces, lo que va a hacer es postponer el 'vaciado' del fichero ~/tmp/geirsPhduAdd.panic
  para más tarde:

   a) se va a grabar una nueva imagen, antes del save
   b) se termina un OB o se aborta
   c) se sale del OT
  


27-11-2013
-----------
- Comienzo pruebas con nueva version de OT que tiene el 'vaciado' del fichero
sólo cuando:

   a) se va a grabar una nueva imagen, antes del save
   b) se termina un OB o se aborta
   c) se sale del OT

Aún así, si el OT hace un crash se podría quedar 'no-vaciado' el fichero ~/tmp/geirsPhduAdd.panic
y si se toman imagenes con GEIRS se le añadiría a la cabecera el contenido de 
dicho fichero. Esto pueda causar problemas !!! Lo suyo sería 'vaciarlo' justo
despues de un 'sync save'.


1) Activacion servidor FTP en panic2

  > /etc/init.d/vsftpd
  > /etc/init.d/SuSEfirewall2_setup stop

- Hago varias pruebas con OT+PQL+SimuArchivoCAHA: aun encuentro un error 
en los header del OT, en concreo, alguna vez deja sin copiar el header del ultimo
fichero de la secuencia. AGS está informado, y lo solucionará tq:
"Me aseguraré de hacer un sync antes de 'vaciar' el fichero."


- Que hacer con las secuencias incompletas, por ejemplo, le falta el primero, 
el último, o algunos del medio, etc .... 
Debería haber alguna forma de poder reducirlos ?? en modo group_by='filter' si !!!
Alguna otra solución ???
Se me ocurre dejarlo como esta, y además de la opción de group_by_filter,
añadir una opción al PQL para re-enumerar/construir secuencias dado una 
lista de ficheros.
==> Además se podría añadir al Troubleshoting 


28-11-2013
-----------
- Modifico en dataset.py la funcion GetSeqFiles() para que los ficheros
no agrupados correctamente los agrupe en una secuencia de tipo 'UNKNOWN'

- Probado el QL con OT+GEIRS veo que da muchos errores/warnings al intentar
leer el fichero antes de que GEIRS haya terminado. Para solucionar eso, probé
multiples cosas, como ir comprobando si cambia el tamaño del fichero (no funcionó
y creo que es muy lento pues hay meter delay), meter directamente un delay antes
de leer el fichero (lo ralentiza tambien mucho sobre todo cuando se leer todo
un directorio con ficheros ya existentes). Finalmente, compruebo que el tamaño>2880*4
y algo muy interesnate que convierto los warnings de PyFITS en Excepciones para
poder detectarlas y así no ralentizar/lentificar la lectura de los FITS.

==> http://pymotw.com/2/warnings/


- Encuentro BUG al crear un Dark de 100 ficheros, pues la keyword COMMENT tiene
un tamaño demasiado largo (contiene todos los nombres de los ficheros).
Era debido a que los warnings de PyFITS eran todos convertidos a Exceptions.
Lo que hago es restablecer el filtro de los warnings en clfits.py despues
de leer el FITS para evitar problemas durante la creación de FITS.


29-11-2013
-----------
- Encuentro una web interesante con el seguimiento de las observaciones 
reducidas de WFCAM --> http://casu.ast.cam.ac.uk/surveys-projects/wfcam/data-processin

- Básicamente revisamos AGS y yo las notas sobre el OT de la cosas que había
pendientes, aclarando dudas y viendo que está implementado. AGS tomó bastantes
notas y yo algunas pocas.

- Finalmente no tuvimos la integración 'interna' del Software; AGS no tenía
preparado el OT.


20-01-2014
----------
- Retoma de contacto con PAPI, para ver seguimos depurando y mejorando ....
- Pruebo con DS ALHAMBRA_1, y da muchos errores ....


22-01-2014
----------
- Añado solveAstrometry.py (Astrometry.net) a PAPI, con los 4200-series 
index files (2MASS).


23-01-2014
----------
- Hago pruebas Astrometry.net VS Astrowarp en PAPI, y parece que Astrometry.net
es más rápido, y más fialble (falla menos) !!!
La unica razón para mantener SCAMP es para el calculo de la distorsion !


- (P) Comprender bien el valor (unidades) de ASTRRMS1 que da SCAMP, pues parece que 
son arcsec, pero me parecen valores muy pequeños (4.731352954E-05)


27-01-2014
----------
- Implemento una version de Astrowarp que usa Astrometry.net como motor (engine)
de calibración astrométrica. Básicamente basta con llamar al run(engine=...) 
con el parámetro adecuado.
Hago pruebas para ver que tal va: (DS de 6 imagenes Ks de O2k modo quick)

En cuanto a tiempo:

  a) ĺógicamente Astrowarp tarda más que un simple coaddStackImages:
       50sec vs 100sec con Astrowarp+Astrometry.net

  b1) Astrowarp con SCAMP: 69sec 
  b2) Astrowarp con Astrometry.net: 100 sec

En cuanto a exactitud del resultado:

  a) ??


- Añado un nuevo parámetro de configuración en la sección de Astrometria: engine
para indicar si queremos que se use SCAMP o Astrometry.net.
Esto va al marge de usar Astrowarp.run() con SCAMP o Astrometry.net

- (P) Quizás habría que añadir otro parametro para indicar si queremos que la
distorsión del campo se elimine antes del coadd (a nivel individual en cada imagen
del dithering) o bien despues del coadd final. Yo creo que se con hacerla al final
debería bastar, pues la diferencia de distorsión en cada uno de las imagenes
de dithering no debe ser grande, y por tanto el coadd no se verá afectado mucho.

28-01-2014
----------
- Pruebas con PAPI+Astrometry.net con DS de HAWK-I:
1) HAWK-I-DS3-01:

1.1) Astrowarp(engine='Astrometry.net') -- falla en SCAMP
1.2) Astrowarp(engine='SCAMP') -- falla en SCAMP
1.3) sin Astrowarp() + AstroEngine=SCAMP -- OK (116s)
1.4) sin Astrowarp() + AstroEngine=AstrometryNet -- Astrometry.net se atranca en Q04 !!!
Pero el problema es que ese cuadrante (4), por la razón que sea no es capaz de
calibrarlo Astrometry.net, ni en la imagen en bruto tampoco (en bruto no resuelve ninguna).
Los otros tres sin problema (el coadd1); no se cual puede ser la causa.



- Gracias a un email de VTerron, me doy cuenta de que los paquetes mscred y nmisc
daban un warning. Era debido a que desde IRAF v2.15 no es necesario declarar
en el fichero hlib$extern.pkg los paquetes externos. Añado la modificación al
documento de instalación.


"""
Dynamic package loading is a new feature in v2.15 that allows for
package directories created in the iraf$extern directory to be automatically
defined when the CL is started.  The means that external package installation
no longer *requires* that the hlib$extern.pkg file be edited to define the
package, although that remains an option for packages which somehow cannot
conform to this new scheme.
""" 



29-01-2014
----------
- Para evitar los problemas al convertir los warning en excepciones, 
modifico clfits.py para que tenga un parametro check_integrity que indique
si quiremos comprobar la integridad de los datos a nivel básico, es decir, si 
el tamaño es multiplo de 2880 y si es mayor que un cierto tamaño y si las keyword
son válidas conforme al standard. Para el QL check_integrity=True.

- Añado soporte a MEF en Astrowarp, aunque solveAstrometry no tiene soporte para
MEF. Añado las comprobaciones correspondientes. Actualmente Astrometry.net (solve-field)
no soporta MEF, aunque tiene la opción --extension para indicar que extensión queremos
calibrar.

- Ahora Astrowarp también puede hacer la astrometría de un fichero individual 
con Astrometry.Net.


03-02-2014
----------
- RM descubre por fin el problema con crep>3. El problema estaba en el valor de
CAMSHMSZ=512 en GEIRS/scripts/GENERIC. 
Ahora el valor es calculado en funcion de la memoria total del sistema, como 
indica el manual de GEIRS:

   setenv CAMSHMSZ `cat /proc/meminfo | fgrep MemTotal | awk '{printf "%d",$2/3072}'`

Además, tambien con la sugerencia de RM, reviso los valores del sistema para los
bloque de memoria compartida, que inicialmente tenian los valores (creo que
según CS):

kernel.shmall = 128000000000
kernel.shmmax = 4000000000
kernel.shmseg = 40960

Unos valores mas razonables creo que serían:

kernel.shmall = 15728640   # 60 GB
kernel.shmmax = 4294967296  # 4 GB
kernel.shmseg = 40960

> sysctl -p  (para re-leer dinamicamente los nuevos valores)

GEIRS ahora parace funciona correctamente con crep, aunque el valor que crítico
que lo ha solucionado ha sido CAMSHMSZ.



04-02-2014
----------
- Mando email a JF con la info que me pidió sobre el Pipeline para la Web.

"""
* Pre-procesing

Once the the data grouping and preparation of a data set is done, the data reduction can start. Data reduction of the scientific frames includes the usual standard steps: dark subtraction, flat-fielding and sky subtraction. The sky subtraction is done in a double pass algorithm. In first pass for each image (dark and flat corrected), N nearby neighbouring images (>3) from the same observation sequence are selected to obtain a initial sky estimate. Then for each sky subtracted image an object mask is defined and used to exclude those regions from a second pass of sky estimation and subtraction. Finally, the second sky subtracted images of the same observation sequence are combined in a stacked image (registering).

* Astrometric calibration

Astrometric calibration can be done by using two different tools: SCAMP or Astrometry.net. Currently, the most commonly used tool in PANIC is SCAMP (Bertin 2006), which uses the initial WCS header and the stored information about detectors' relative orientation. SCAMP matches the object catalogues obtained with SExtrator (Bertin & Arnouts 1996) to the astrometric reference catalogue selected, eg. 2MASS for most of the times. The astrometric solution is stored in separate FITS headers, which are read by SWarp (Bertin et al 2002) during the image co-addition and distortion correction. The internal accuracy of the resulting  astrometric solution with SCAMP is on the order of 0.1-0.3 pixels.
Once the astrometric solution is obtained, SCAMP also can determine relative photometric zero-points for the exposures.

A complementary tool to SCAMP is a local implementation of the Astrometry.net algorithm (Lang et al. 2010). Matching is done based on quadrilaterals in the reference (local 2MASS index) and the object catalogues created by the own Astrometry.net tool (image2xy), although SExtractor catalogues as created for SCAMP could also be used.
The different matching techniques used by SCAMP and Astrometry.net complement each other for problematic fields. Currently Astrometry.net (v0.46) is not able to calculate photometric zero-points and also has little control over field distortion.
Hence Astrometry.net is currently used mainly for catalogue matching, while SCAMP is run afterwards (with matching deactivated) to calculate the distortion maps and relative photometric zero-points.


* Photometric calibration

One the data are flat-fielded, gain corrected to place all four detectors on a common system, and sky subtracted, the photometric calibration can be done. The per detector magnitude ZP is then derived for each frame from measurements of matching stars in the 2MASS catalog that fall within the same observed frame. Thus, calibration stars are not needed with this calibration procedure.
We assume that there is a simple linear relation between the stellar 2MASS and PANIC colours. For each star in 2MASS observed with PANIC, the pipeline derive a ZP (at airmass unity) from:

ZP = m_2mass + C(J_2mass-H_2mass or J_2mass - K_2mass) - m_inst + k(X-1)

where ZP is the zero-point in that passband, m_inst is the aperture-corrected instrumental magnitude (-2..5 x log10[counts/sec], where counts are obtained by SExtractor with fixed or auto apertures), C is the colour coefficients for each passband (to solve during commissioning), k is the default value for the extinction (0 for the moment) and X is the airmass.
The 2MASS sources used for the calibration for PANIC are selected to have an extinction-corrected colour 0.0 < =J_2mass-K_2mass<=1.0 with a 2MASS signal-to-noise ratio > 10 in each filter. If fewer than 25 sources are found within the field of view of the detector, then the colour cut is not applied.
For a single pointing, for each detector, the zero-pointing is then derived as the median of all per-star zero-point values. A single photometric zero-point for the pointing is calculated as the median of the detector zero-points over all four detectors. The associated error (a robust estimate of the Gaussian sigma) is computed as 1.48 times the median absolute deviation (MAD) of the detector zero-points around the median.

"""

- Al hilo de lo de antes, veo un resumen interesate de los pasos a seguir para la fotometría de VISTA (http://goo.gl/FrhCpT):

The VISTA Photometric System
VISTA Photometry is on the VISTA system, tied to (but different from) 2MASS, calibrated via colour equations between the two systems (below). Briefly the following steps are followed to calibrate a single VISTA pawprint.

1. All detectors are normalised to the same approximate gain using the flatfield exposures.

2. The catalogue of sources detected (via imcore) on each VISTA detector is crossmatched against the 2MASS catalogue (this is also used to refine the astrometric solution).

3. The 2MASS magnitudes for all matching stars are converted to expected VISTA magnitudes using the colour equations (below), including terms to account for interstellar reddening.

4. The offset between the median 2MASS and VISTA magnitudes is the Zeropoint of the detector(corrected to airmass unity under the assumption of a default extinction value for the filter)

5. A single preliminary median (of all 16 detectors) Zeropoint is written to the FITS header (keyword: MAGZPT), while the scatter in the measurements (the median absolute deviation MAD*1.48, a robust estimate of the Gaussian sigma) forms a measure in the error in the Zeropoint (keyword: MAGZRR).

6. A final stage to the photometric calibration takes account of systematic differences between the 16 detectors, measured on a monthly basis. The residuals from all 2MASS stars used in the frame zero-point determination (i.e. J, H, Ks signal:noise >10:1) are also computed on a per pointing basis together with their standard coordinate location with respect to the tangent point of the telescope optical axis. The residuals are stacked and used to generate delta-Zeropoints per detector (the value of MAGZPT is actually updated for each detector).

7. At the time of writing, no significant spatial residuals (above the detector-to-detector offsets) are seen (e.g. that could arise from scattered light). More details below.

VISTA-2MASS colour equations
2nd pass (improved) colour equations and zeropoints, derived from to 2MASS from a compilation of data measured on good (photometric) nights, with good seeing, and for fields with E(B-V)<0.1. The nominal ZPs are unchanged, but the colour equations have been adjusted slightly to give robust fits to the data.  Earlier colour equations are reproduced at the bottom of this page for completeness.


- Actualizo Astrometry.net v0.46 en panic2. Parece que todo OK.



10-Feb-2014
-----------
- Le mando a Josef (fuera de tiempo) lo siguiente para la videoconf:

"""
I am sorry Mr. Fried, but I am quite busy last days.

Please, take the next info from the Pipeline:

- TN about 'FITS headers' updated and reviewed
- Integration of Astrometry.net with SCAMP for astrometric calibration and distortion correction
- Simulated simultaneous running of GEIRS acquisition + data reduction + data archiving. No problems detected.
- Fixed problem with 'crep' command (memory configuration!)
- Testing new MEF file-saving feature of GEIRS (r712M)

(at least) Things not done by PAPI:

- Second pass of sky-subtraction for extended objects
- Support for non-integrated frames as individual frames (not as cubes),ie. detection/grouping and coadd
- Support for sub-windows (not tested, but probably does not work properly)
- Non-linearity computation ( fac = a0 + a1*I + a2*I^2 ) and correction. In progress.
- Method to empirically determine the geometric distortion based an auto-calibration
approach analogous to the one described in Anderson et al. (2006, A&A, 454, 1029)
- Photometry: currently only 2MASS filters (J, H, Ks) supported. No colour
coefficients neither extinction taken into account.
- Data Quality Control (frames to reject, ...) 
"""

11-Feb-2014
-----------

- Josef Fried me envía como hacer el cálculo de la Non-Linearity:

"""
thanks for your mail. WRTO the non-linearity corrections the procedure is:

determine the coefficients:

  1. take a series of exposures with the same illumination but
     increasing exp.time
  2. calculate a polynomial fit to these data pixel by pixel
  3. store the coefficients of these polynomials in frames, so you have
     a frame for each coeff.

apply the corrections:

   for each pixel in the frame to be corrected compute the polynomial, add the 
   difference between poly. and linear relation to measured flux.

We can talk about this during software integration. 
"""

Además, en la web del NOT encuentro la siguiente información:

NOT
---

The non-linearity of the array can be corrected pixel by pixel using the two 
coefficient images "ba" and "ca". 
The coefficients were determined from sets of dark-corrected lamp flats obtained 
using the ramp-sampling readout mode with 10 integration times 
notcam.frames 4.2 10, i.e. spanning 10 intensity levels from roughly 
5000 to 50000 adu. For each pixel a 3rd order polynomial (y = ax + bx2 + cx3) 
was fitted to the 10 values, obtaining the three coefficients a, b, and c, 
which are reduced to ba = b/a and ca = c/a.
The correction must be applied to the raw images as a first step in the data 
reduction procedure. 
The raw image (x) is to be corrected as follows using the correction 
coefficient images ba and ca:

y = x * (1 + ba * x + ca * x**2)



17-Feb-2014
-----------

- Teleconf sobre la integracion del SW de PANIC (ver documento de minutas)

- Pruebas MEF de PANIC con PAPI:

1) calDarkModel no funciona con MEF; comienzo modificaciones para que funcione
con MEF.


18-Feb-2014
-----------
- Termino implementar calDarkModel.py con soporte para MEFs.
- Modifico en PAPI la estructura de los DarkModel, ahora plano_0=bias, plano_1=dark_current
  Se ven afectados applyDarkFlat y calTwFlat.

- Continuo con pruebas de secuencias de MEF para DM; parece que va bien.


19-Feb-2014
-----------
- Sigo con la implementación y pruebas de calNonLineriaty.py con soporte para MEF
Parece que funciona, aunque no tengo datos reales para probar !!! y la corrección
no tengo aún claro cual es la correcta, la que hay implementeda ahora no es la 
correcta

- Prueba de DOME_FLAT_ON/OFF con MEF en PAPI --> OK
- Prueba de DARK serie (lineal) con MEF en PAPI --> OK
- Prueba de Dark serie (fix) con MEF en PAPI --> OK
- Prueba de SuperFlat con MEF --> OK
- Prueba de TwFlat con MEF --> 
- Prueba de combineFF con MEF -->
- Prueba de applyDarkFlat con MEF --> 
- Prueba de FocusSerie con MEF --> 
- Prueba de CheckQuality con MEF -->
- Prueba de BPM_2 con MEF --> FALLO !!!! --------------------------- Solved
- Prueba de BPM con darks de Bernhard !! (OK, MEF and single) 
- Prueba de astrowarp con MEF
- Prueba de solveAstrometry con MEF 

20-Feb-2014
-----------
- Modicando BPM_2 para MEF

21-Feb-2014
-----------
- Modicando BPM para MEF
- Prueba de BPM con flats de PANIC de Bernhard ---> OK (MEF and single)
  pero --> >>STD= nan ???
  pero --> umbrales no correctos, pues no detecta bien el chip malo !!!

- Prueba de BPM_2 con PAPI-MEF --> OK 
- Prueba de BPM_2 con PAPI-single --> OK 


24-Feb-2014
-----------
(BUG QL)-> No se muestran bien en el QL+ds9 las imágenes MEF--> 
Informo a RM, quien consulta en el foro (http://listmgr.cv.nrao.edu/pipermail/fitsbits/); parece un bug en DS9;  

(BUG QL)-> No permite mostrar (ds9) cubos de los MasterDarkModel !!!


Muy interesante: --http://www.astrobetter.com/manipulating-and-viewing-fits-files-in-python-with-pyds9/

(P) Añadir al manual del QL como hacer para QL-photometry tal que: 

http://casa.colorado.edu/~ginsbura/ds9tips.htm#body8

"""
Quick-look Aperture Photometry

In ds9 7.1 (released in late 2012), there is a new "Region Statistics" feature. In most regions, you can now double-click on the region, then go to the region's analysis menu and click "Statistics". It will pop up a window showing basic stats (sum, mean, stddev, etc.). 

If you're looking for something a little more complex and flexible, try ds9_phot from agpy. WARNING: pyds9 currently (10/27/2012) does not work with astropy! You'll need pyfits, pywcs, pyregion, and pyds9.
"""


25-Feb-2014
-----------
- Pruebas SW-AIV_001 con save_mode=single_integrated (not MEF) --> OK
- Pruebas SW-AIV_001 con save_mode=MEF_integrated (MEF) --> OK
- Pruebas SW-AIV_001 con save_mode=MEF_cube (MEF) --> OK, pero problema con directorio de salida de collapse.py

- Intersante sugerencia de RM sobre el fichero de log de los ficheros generados
por GEIRS:


#!/bin/bash
#
# removing and or adding luci instrument lab-fits to fits-data-file
#
#
echo `date +%FT%H:%M:%S` $1 $2 >> ~/tmp/fitsGeirsWritten
#modify_fits_hdr -v -a ~/tmp/fitsheader_panic.txt $1 >>~/GEIRS/log/add_panic_fits.log
export ret=$?
if [ $ret -eq 0 ]; then
    echo `date '+%Y-%m-%d_%Hh%Mm%S'` $1   >>~/tmp/fitsfiles.corrected
else
    echo `date '+%Y-%m-%d_%Hh%Mm%S'` "ERROR $ret in modifying fits-header of $1"  >>~/tmp/fitsfiles.corrected
fi
exit $ret


27-Feb-2014
-----------
- Instalacion de openSUSE13.1 en panic1. Sin problemas, excepto que inicialmente
intenté instalar con el CD-.NET y no pude, creo que debido al DHCP, aunque intenté
también fijar la IP a mano, tampoco me dejó.



03-Mar-2014
-----------
- Continuo con la instalación del SW de PANIC en openSUSE13.1
- Finalmente instalo todo lo de PAPI, y la primeras pruebas (muy preliminares)
parece que todo va OK.
- Instalo también GEIRS: Plxsdk + GEIRS_713. Falta instalar la OPT PCIe board !!!
- Instalo tambien el OT, junto con el JDK7u51


(P) - La compilacion de IRDR en openSUSE13.1 da muchos warnings !!!!, y no compila del tirón !!
(P) - Configurar los sonidos !!!
(P) - Falta instalar la OPT PCIe board !!!
(P) - Probar FWHM routines with MEF !!!
(P) - Probar eval_focus with MEF !!! 
(P) - Probar IRAF:starfocus !!! y actualizar TN !!


04-Mar-2014
-----------
- Continuo con las pruebas de PAPI: secuencias de foco:
   -> Ahora PAPI reconoce las secuencias y las procesa, generando un PDF.
   -> El QL la reconoce y las procesa también, pero mostrando el PDF.
      Además, en el QL, desde el Pop-up menu, se puede selecionar una lista 
      de fichero y hacer el análisis de foco. Lo ficheros selecionados no tienen
      por que ser una secuencia completa, eso no lo comprueba de esta forma.

- Lanzo la reducción con PAPI de toda la campaña Jun.2012 de Matilde con O2k.

05-Mar-2014
-----------
- Encuentro un bug en la reducción de un directorio completo (un conjunto de 
secuencias de una noche), pues se borraban (RS.cleanUpFiles) los datos de la secuencia
anterior. Modifico RS:cleanUpFiles() para que no borre .fits ni .skysub.fits.
- Además modifico RS para que en el modo LEMON se creen ficheros con nombres 
aleatorios terminados en '.panic_output'

- Encuentro problema en el calculo de los offsets en Matilde-120103_s40; cambio
en la configuración single_point = False y se soluciona el problema !!!
Por tanto, el single_point en algunos casos no es muy bueno usarlo..., pero no
termino entender por que ???

- Lanzo de nuevo la reducción de Jan.2012 de Matilde a ver que pasa ahora ....


(B-P) IRAF:starfocus no funciona ni con el ejemplo de O2k !!! Por qué ????
(Solucionado)l problema era que no estaba seleccionando estrellas buenas, eran más bien
rayos cósmicos o ruido.


06-Mar-2014
-----------
- Soluciono bug en photometry.py, pues en el caso de que por ejemplo la imagen
no estuviese calibrada astrometricamente, entonces no puede hacer el XMatch; bueno,
puede hacerlo, pero sale [][] y no trataba ese caso concreto.

(BUG) - Encuentro un problema en QL/PAPI: si se "atranca" for ever en algun procesamiento en el QL,
debería tener un timeout para que no deje al QL colgado. 
(P) -Probar a reducir imagenes con mascara de PANIC !! ver si quita "cielo"
(Bug) - Los dark no los muestra bien el display.py !! ==> SI TIENEN INFORMACION WCS los dark de PANIC 


07-Mar-2014
-----------
* No se copia la key FILTER/1 en los datos de HAWKI: la debí quitar sin darme cuenta
--> solucionado en redunctionset.py

(PPPP) - (Bug?) No se por que en udit22 no se reduce el HAWKI-DS3-0 !! da un error
de keyword no compatible !! sin embargo en panic1 no da ningún problema !!!
--> es cuestion de versiones de pyfits ('3.1.0' en udit22 y 3.1.3dev en panic1, y
en la 1.3.1 tampoco ocurre, está solucionado). Es un warning, pero como en
clfits los convierto a errores, por eso se queja.
Además, fitsverify los da por la keyword.
La solución es poner por defecto el clfits.check_integrity=False y sólo activarlo
en el QL !!!


10-Mar-2014
-----------
- (P) Sigo con problemas al mostar los Dark/DModel en DS9.



12-Mar-2014
-----------
- JM Inputs for videoconf:
""
- software migrated to openSUSE13.1 and being tested with it: no major problems found up to now
- OPTPCIe board not installed yet
- tested and debugged  PAPI with new MEF files
- non-linearity correction: pending definition of algorithm 
""

Results from videoconf:
- Due to BD and JF illness, SW integration postponed until new date for 
first-window (cold-down) what was planned for end of March. Even it could be 
delayed until second-window.
- Computer shipment will be planned when we get new date for sw-integration
- JM will deliver an update of technical note.


14-Mar-2014
-----------
- (B) Encuentro un BUG en photometry.py; parece que las coordenadas de búsqueda
del conesearch en 2MASS no están bien, pues si "pinto" los dos catalogos (Sextrator) y
el resultado de conesearch en 2MASS, hay claramenete un offsets !!!!
Por eso el XMatch da muy pocos objetos !!!


17-Mar-2014
-----------

- Encuentro el problema del offset del XMatch de photometry: viendo los .xml
que se generaban, he comprobado que había un offsets de 10' en AR y que por eso
no se estaba haciendo el xmatch con las mismas regiones.
El problema estaba en clfits.py, pues buscaba 'RA---TAN--SIP' en CTYPE1, y el
fichero que crea Astrometry.net contiene RA---TAN-SIP !!!
Soluciono el bug en clfits.py buscando sólo por 'TAN'. 
Habría que probar que también funciona con la astrometría de SCAMP --> Si, también funciona bien !!!

No obstante, lo ideal sería usar en el futuro astropy.wcs tal que:


http://docs.astropy.org/en/stable/wcs/index.html

si embargo me daba problemas con los ficheros raw de O2k, generaba un error!!



18-Mar-2014
-----------
- Matilde me pregunta por la integración de SW para la semana despues de 
Semana Santa. Yo le digo, tras preguntar a AGS, que okay.

- Modificacion en mef.py para migrar el PyWCS a astropy.wcs; además le añado
la parametrización con PIXSCALE y que tenga en cuenta el CHIPGAP, que no lo tenía
en cuenta en la conversion de splitGEIRSToSimple().

- Modificación en mef.py para forzar la escritura de los FITS con BITPIX=-32

- Pruebo a reducir imagenes con mascara de PANIC que me mandó Bernhard (exp_xxx.fits)
 para ver si quitan "cielo".
 Primero le modifico la cabecera con fedithead para crear la secuencia válidad para PAPI.
 Descubiertos algunos bugs colaterales en mef.py.
 Sin embargo, la prueba falló como era de esperar en el cálculo de los offsets, pues
 no encuentra estrellas. Eso es normal, pues las imágenes no tienen dither, y por
 tanto en la skysubtraction se eliminan también los "holes" de la máscara.


19-Mar-2014
-----------

- Reviso calBPM, y veo que no tiene mucho sentido el dividir las imágenes por 
el flat normalizado, pues estamos "arreglando" los pixeles malos !!!
Hay que revisar bien el algoritmo....

20-Mar-2014
-----------
- Encuentro la documetacioń de EMIR muuuuy interesante:

http://pythonhosted.org/pyemir/index.html

- Encuentro un conjuto de rutinas den Python muy interensate sobre tratamiento
de datos:


http://www.astro.umd.edu/~msk/computing/python/src/mskpy1-1.7.0.tar.gz

- Duda:

 ¿ debería de haber una rutina para "arreglar" los píxeles malos ? (IRAF.fixpix)

- Añado al config_file las secciones pare BPM y NLCorrection; las añado tambien
en misc/config.py
- Comienzo también a añadirlas en reductionset.py ....


21-Mar-2014
-----------
- Continuo con las modificaciones para añadir el tratamiento con BPM y NLCorrection
en PAPI:
  - applyDarkFlat: ahora deberá tambien considerar el BPM
  - reductionset.py: 
  - 

Now, with BPM we have two options:

 - To Fix: replace with a bi-linear interpolation from nearby pixels.
 - To add to gainmap:  to set bad pixels to bkg lvl 
 In principle, both options are incompatible.

- Añado a applyDarkFlat.py el procesamiento con el BPM, y encuentro un bug 
gravísimo, pues no se hacía nada!!!!!, pues estaba comentada la linea siguiente:

   sci_data = (sci_data - dark_data) / flat_data

- Añado NonLinearityModel.applyModel() a reduceSingleObj(); pendiente probar



24-Mar-2014
-----------
- ETC de CIRSI: interesante para hacer la ETC de PANIC-->

http://www.ast.cam.ac.uk/~rgm/cirsi/signal_cirsi_help.html

- Pruebas de la NLC embedida en PAPI (enabled/disabled en papi.cfg).
Fueron bien, salvo que encontré un error colateran en irdr::skyfilter.c,
pues para valores negativos de bckg o valores muy grandes en las imágenes
el irdr::readdata() no funciona bien. Habría que revisarla.

- Comienzo pruebas de BPM en PAPI: parece que OK en modo fix, pero hay que probar
con mask=0, y el modo 'gain'...


25-Mar-2014
-----------
- Continuo con pruebas de BPM-Fixpix en PAPI:

  Modo fix:
  - con o2k--> OK (con una artificial y con otra con todo a 1's y otra con 0's)
  - con PANIC (MEF) -->  OK !!

  Modo gain:
  - con o2k--> OK (con una artificial y con otra con todo a 1's)
  - con PANIC (MEF) --> OK !! 

- Probado NLC con MEF; me doy cuenta que no puede estar en reduceSingleObj(),
pues la NLC debe hacerse a **todos** (incluidas calibraciones) los ficheros y 
antes de nada. Además en reduceSingleObj() debería llegar ya 'partido'.
Por tanto, la NLC lo hago al principio en RS:reduceSeq().


27-Mar-2014
-----------
- Paralelizo calNonLinearity.py--> applyMultiNLC() vs applyNLC();
Se reduce el tiempo a menos de la mitad !
Lo pruebo y va bien.


30-Mar-2014
-----------
- Pruebas pendientes o que hay que revisar:

1) Astrowarp con engine=Astrometry.net con O2k y HAWK-I !!!
2) MEF con todas las calibraciones
3) QL !!


- Hago pruebas con _astrowarp=True y O2k (testCAHA_Arch) y va bien !!!
- Pruebas de _astrowarp=True + engine=Astrometry.net


21-Abril-2014
-------------
- Empaquetado de PANIC1 para enviar a HD. La máquina va instalada con openSuSE13.1,
y con el /home/panic tal cual estaba. En los directorio /data1 y /data2 hice
alguna limpieza, pero también los dejamos.



22-Abril-2014
-------------
- Finalmente sale el paquete con panic1 para HD, a través de la compañia DHL.
- Instalación de openSuSE 13.1 en panic2, manteniendo los /data1 y /data2. Los
más destacable de la instalación fue:

 IP panic2.iaa.es --> 161.111.164.102
 Netmask              255.255.255.128
 DNS                  161.111.164.2
 GW                   161.111.164.3

 Particiones (con tres VirtualDisks):

 /dev/sda1      swap   2 GB
 /dev/sda2      /      120 GB   ext4   RAID 1  VD1
 /dev/sda3      /home  343 GB   ext4   RAID 1  VD1
 /dev/sdb1      /data1 1.8 TB   ext4   RAID 1  VD2
 /dev/sdc1      /data2 3.64 TB  ext4   RAID 10 VD3 

 Automatic login = off
 GRUB2, boot from MBR = no
        boot from /   = yes
 Default run-level = 5
 Enable sshd en Firewall

 Language: English (US)
 Keyboard: Spanish
 KDE Desktop
 
 Software: básicamente todos los paquetes de desarrollo, linux-src, file-server

 Además, para probar la iDRAC7 configuro la tarjeta con la IP de panic1:
 
 F2->Enable->Configu --> 161.111.164.101 
 http://panic1.iaa.es (root/el_de_siempre_empezando_mayusculas)

 Quedaría pendiente reconfigurar el VD3 con RAID5 para tener más espacio, al
 igual que se hizo con panic1.

 La configuración de las particiones de panic1 para HD fue:

 /dev/sda1      swap   2 GB
 /dev/sda2      /      450 GB   ext4   RAID 1  VD1 (incluye home)
 /dev/sdb1      /data1 1.8 TB   ext4   RAID 1  VD2
 /dev/sdc1      /data2 5.4 TB   ext4   RAID 5  VD3 



23-Abril-2014
-------------
- Termino instalación SW (GEIRS_714), sin poder compilar la version 715M por un
problema de compilación del que informamos a RM y KM y MF.

24-Abril-2014
-------------
- Finalmente, debido aun problema con el acuerdo entre IAA-ViajesTema, me veo
obligado a suspender el viaje. AGS irá sólo. 

25-Abril-2014
-------------


02-Mayo-2014
------------
- Soluciono bug en display.py, pues no se detectaba bien si estaba ejecutandose
el ds9 en startDispla(). Ahora, el lugar de usar pidofproc, uso xpaaccess.
- Encuentro problema en QL al intentar "leer" un directorio con 6000 ficheros
de PANIC !!!
- Le cuento a AGS lo básico del QL para que él lo pueda usar/demostrar en HD.
En dicha presentación encuentro los siguientes problemas:

  - las rutinas de IRAF no funciona correctamente, se queja de que no encuentr
  el login.cl ni uparam. (ejem. imarith, imstat, etc ...)

  - Desde el Menu-pop-up no funciona la reducción por dark-series, aunque 
  en modo automático si funcionan.

  - Una vez pulsado el boton "Build Calibrations" (help), no hay forma de pararlas ???
  - Depurar la actualización de ListView cuando hay >6000 ficheros, pues va muy lento...
  - Avisar cuando hay > 1000 ficheros al leer un directorio.
  - Aladin no está instalado ...; INSTALADO !! en panic1 (ya instalado) y panic2.




05-Mayo-2014
------------
- Configuro en .bashrc la variable http_proxy en panic1 (MPIA) para que 
funcione cdsclient (no probado !!).
- Modifico mainGUI:createMasterDark_slot() para que use processFiles() en lugar
de llamar directamente a calDark.py.
Esto habría que hacerlo para otras funciones _slot_ del QL !!!


14-Mayo-2014
------------
- Videoconf: El QL debe mover el foco, previa confirmación, después de analizar la serie de foco.


19-Mayo-2014
------------
- Comienzo modificación a QL para que despues de análisis de Serie de Foco pregunte
si se desea realizar el correspondiente ajuste del Foco del telescopio.

Finalmente, en lugar de crear desde el QL un interface con el telescopio a través
de GEIRS:

  snd_panic_new -p 8501 COMANDO [PARAMETROS]

lo cual es alto "anti-natural", AGS y yo acordamos que sea el OT sea el que 
cambie el valor del foco. El procedimiento será:

 1-OT se pausa al final de la ejecución una serie de foco y muestra un mensaje
 al usuario diciendo que compruebe en el QL el resultado del procesamiento de la
 serie de foco.

 2-QL una vez detecta una serie de foco, la procesa y además de crear un .pdf
 con la curva 2do. grado ajustada, escribe en el fichero:

          $HOME/tmp/ql_focus

 el valor de mejor fococ calculado, en formato entero y en micras, tal que: 
  

          DDDDD

 3-Una vez el usuario ha comprobado que el QL ha procesado correctamente la
 serie de foco, el usuario pulsará OK en el OT. A continuación el OT leerá del
 fichero $HOME/tmp/ql_focus el valor del mejor foco y lo mostrará al usuario,
 pidiendo confirmación para mover el foco de telescopio al valor calculado.
 Una vel leido el valor del foco, el OT borrará el fichero $HOME/tmp/ql_focus.

 Además el OT permitirá al usuario que modifique el valor de mejor foco a enviar al
 telescopio.

 4-Si el QL no estaba funcionando o bien se produjo algún error durante el 
 procesamiento, el OT mostrará un mensaje diciendo que no se pudo obtener el
 valor del foco y que se revise la configuración del QL.


- Probado funcionamiento correcto en el QL; pendiente de probar con OT.


- Intento solucionar el problema que aparece al lanzar PAPI/QL sin conexión
a internet, debido a IRAF:

      cannot access host 'iraf.noao.edu:80'

Todo parece que podría ser debido al paquete iraf.noao.astcat, 
y en concreto al fichero:

/iraf/iraf/noao/astcat/lib/catdb.dat


-- Como no encuentro soluciones en internet, envío pregunta a help@stsci.edu.

Obtengo las siguientes respuestas:

PyRAF: (help@stsci.edu)
Pyraf is not doing that itself, but it does run IRAF commands that are found in login.cl, extern.pkg, and so on.  That message is probably coming from IRAF 2.16.1.  I would guess that you might find something in login.cl that causes IRAF to "phone home" when you run it.
 
Your best chance of a solution is to ask in the web forum at www.iraf.net .

iraf.net
--------
The web connection is being done with the 'chkupdate' command in the login.cl file, which you can comment-out if you have one in the local directory, and/or comment out the system template version in iraf$unix/hlib/login.cl. Pyraf does use the ".iraf" global login mechanism, however CL users using the person install option should comment out their $HOME/.iraf/login.cl file as well.

Comentando 'chkupdate' se soluciona en problema (comprobado en panic @ MPIA).
Sin embargo, parece que no es como dicen, pues PyRAF usa "$HOME/iraf/login.cl" y
IRAF-CL usa ""$HOME/.iraf/login.cl" por defecto.


- Activo en Astrometry.net en el fichero /usr/local/astrometry/etc/astrometry.cfg
el parametro 'inparallel'. Se supone que así irá mejor.




20-Mayo-2014
------------
- Resuelvo el problema del  "cannot access host 'iraf.noao.edu:80'" tras la
respues en iraf.net (ver arriba); lo añado al documento de instalación.
- Simplifico algunos de los imports que tengo de iraf (imred, ccdred), parece
que no son necesarios.


21-Mayo-2014
------------
- Comienzo revisión (por n-ésima vez !!) del calBPM.py;


22-Mayo-2014
------------
- Sigo probado e investigando sobre BPM:
    
   -- calBPM.py no hay manera que lo haga bien, se suele quedar muy corta para Q1
   -- ccdmask de IRAF se pasa !! da una mascara muy rara, con muchas bandas verticales !!!

- Sin embargo,  encuentro un documento muy interesante sobre BPM para NIR en:

http://www.gemini.edu/sciops/instruments/gsaoi/calibrations?q=node/11900

- Además, respecto al cálculo del ZP, también encuentro algo
interesante:

http://www.gemini.edu/sciops/instruments/gsaoi/calibrations?q=node/11538


26-Mayo-2014
------------
- Depurando nueva rutina de BPM (calBPM_3.py), basada en:

http://www.gemini.edu/sciops/instruments/gsaoi/documents/GSAOI_BPM_forweb.pdf,

aunque no totalmente, pues los umbrales no me daban buenos resultados.



27-Mayo-2014
------------
- Continuo depurando nueva rutina de BPM; 
(P)- No entiendo como podemos tener los DARKs tan malos de PANIC !!!! --> preguntar BD
    -- Done

- FAQ interesante:

* How can we reach hundredth of magnitude accuracy in photometry?
The best way to accurately photometrically calibrate HAWK-I images is to use 2MASS stars in the field itself to derive the photometric solution. The accuracy strongly depends on the number of bright 2MASS stars within the filed of view, but ranges from a few 1/100th of a magnitude to 0.1 magnitudes if only faint stars are contained in the field. Additionally, observing supplementary standard star fields can be asked for when preparing the observations. The new pipeline to be released in 2014 will automatically perform 2MASS photometric calibration on all images. 

* How good is HAWK-I astrometry and how are PSF variations corrected?
At present the pipeline applies a correction for PSF distortions based on a distortion map derived during HAWK-I commissioning back in 2008. Distortion images are regularly taken, but not processed. At present, the solution is to extract photometry on a chip-by-chip, exposure-by-exposure basis, derive astrometry from 2MASS on each single chip and single exposure, and the merge all the frames together.
Most of the present HAWK-I pipeline limitations will be cured in an upcoming release of the pipeline.

- Compara los resultados de calBPM_3.py con darks de HAWKI y son bastante
consistentes, aunque obtengo un valor parecido para MEDIAN de hawki_cal_dark,
no obtengo un valor parecido para la STD !!! Por mas vueltas que le doy no se 
como lo calcula. Incluso he comparado con el MAD, pero tampoco.


28-Mayo-2014
------------
- Adaptación de calBPM_3.py para soportar MEF.
- Mejora de calBPM.py para ser más consistente con algun bugfix.
- Reviso de nuevo los umbrales de calBPM_3.py; la rutina parace consistente con
los valores de BPM que da el pipeline de HAWK-I.
En cuanto a los valores de BPM de Bernhard D., aún no consigo obtener sus mismos
BPM, pues el problema que encuentro es encontrar un umbral bueno para los darks,
que están hechos un desastre, y la Median y STD no terminan de convencerme,
al menos para Q1.

En cualquier caso, debería escribir a BD y preguntarle como calcula él la BPM,
pues parece que la suya es más conservadora.

- Otra pregunta importante es, y como usar el BPM en PAPI ???? 
(P) --> ahora está claro en paso 0 de reduceSingleObj() ---> añadir a la documentación !!!!

29-Mayo-2014
------------
- Probar y mejorar rutina health.py ; migrar IRDR:cubemean a IRAF:imcombine !!!


02-Junio-2014
------------
- Comienzo reducción de datos de 3er. ciclo de FOCUS de PANIC, después de que el
segundo ciclo resultare no válido por una mala instalacion del detector y/o 
anillo de "enfocado". Los datos están en:

  /data1/PANIC/3rd_OPT_FOCUS

- Mejora de la rutina applyDarkFlat.py, pues además de tener algún bug, no 
contemplaba todos lo casos para la BPM.

03-Junio-2014
------------
- Continuo con la reducción e los datos de 3er. ciclo de FOCUS de PANIC, y 
observo que en algunas imágenes de SCI (3,4,7, ...) y en los darks de 1.5s hay 
un canal que ha dado una señal mala.

Le envío a Conchi e Irene los datos reducidos para todos los angulos:

/data1/PANIC/3rd_OPT_FOCUS/Conchi

junto con los siguientes comentarios:

"""
- hay un canal (64x2048) en el detector 3 (arriba a la derecha) que a veces ha 
dado valores malos en todo el canal; eso ha provocado que en algunas imágenes 
(3,4, 7, ...) una fila de puntos de la máscara se vean afectados, llegando a o 
"verse" bien. No se como llegará a afectar a las medidas, no obstante en la 
imagen 1 (Tilt 0) eso no ocurre, por lo que podréis lanzar iraf:psfmeasure 
sin problemas.

- he creado el fichero all_files.txt por si queréis analizar todas las imágenes
 del tirón con psfmeasure.

- he mantenido la misma mascara de BadPixels que en el 1er. y 2do. ciclado 
(la que obtuvo BD), aunque creo que dicha máscara es bastante conservadora, 
pues creo que hay más píxeles malos. Intentaré hablar con él para ver como la 
calcula.

- sin ánimo de sugestionaros, mi impresión es que el foco de esta serie es peor.

- las "imágenes" se mueven conforme se rota el instrumento, y al volver a su 
posición original (Tilt 0), la "imagen" no vuelve a su posición original.

- en general, sigo pensado que las imágenes están bastante "sucias", con mucha 
cosmética y efectos (crosstalks, ghosts, ...) y no se muy bien si los detectores
 no están bien "configurados", están dañados o bien el dañado soy yo...
"""


- Incio de mejora en health.py, para :

1) usar IRAF:imcombine en lugar de IRDR:cubemean  --> no se si merece la pena....
la idea es no depender mucho de IRAF ...


Ejecuto health.py con los FLATS del 2do. ciclo de OPT_FOCUS, tal que:

./health.py -i /data1/PANIC/2nd_OPT_FOCUS/2014-05-12_flat_2_0/lir_all_flats.txt -s 0 -e 6 -p 6 -o /tmp/health.pdf

donde lir_all_flat.txt es un fichero con toda la serie de flats en modo LIR 
con ITIME incremental, NCOADD=1, y 6 exposiciones por ITIME.

* Observo que en la secuencia comienza a incrementar la STD, pero llega un momento
en el que empieza a bajar y ya no sube más !!! eso hace que no se pueda ajustar
una recta, sino una parábola !!! con lo cual el calculo de GAIN y RON no es correcto !!!



04-Junio-2014
-------------
- Modificación en papi.py para que se tenga en cuenta el master_BPM de la linea
de comandos y se "mezcle" con el posible valor del fichero de configuración.
Siempre tendrá preferencia el valor de la linea de comandos.


Bad Pixels (BPM_3 vs Bernhard's mask):
-------------------------------------

SG1 [2048:4096, 0:2048] => 655647 + 38619 = 694266  vs BD= 109596
SG2 [2048:4096,2048:4096] => 320465 + 44910 = 365375 vs BD = 62014 
SG3 [0:2048, 2048:4096] =>   62509 + 35031 = 97540  vs BD= 37625
SG4 [0:2048, 0:2048]  =>  814735 (hot) + 38935 (cold) = 853670  vs  BD= 432479  (BD: Bernhard Dorner values)


- Creo una etiqueta para la version de PAPI usada en la 2nd. SW-Integration en HD:

> git tag -a v2.0 -m 'version 2.0 - Second Sw integration at HD May-2014' 486347ded964585f7756993c88dc126e938d1e46
> git push origin v2.0

que corresponde al commit :

commit 486347ded964585f7756993c88dc126e938d1e46
Author: jmiguel <jmiguel@iaa.es>
Date:   Mon May 5 13:52:43 2014 +0200

    - Updated QL for a large directory of data (> 6000 files); modified datacollector with __last__ suffix.
        - Modificado mainGUI:createMasterDark_slot() para que use processFiles() en lugar
        de llamar directamente a calDark.py.
        - Added the requirement of creating $HOME/iraf directory to run PAPI or QL.


- Para ir a una version correspondiente a una etiqueca concreta:

>git checkout v2.0

y para "salir" de dicha version:

>git checkout master

A partir de una version/tag podríamos crear una rama y seguir desarrollando esa version ...

(desde el tag correspondiente)
> git checkout -b new_branch_name


05-Junio-2014
-------------
- Estudio el método de BPM que me ha enviado BD(ver mail 4-Jun-2014); 
la gran diferencia con BMP_3 estriba en el punto 2)Super-Hot pixels / Hot pixels; 
BD usa un valor absoluto de 25000e-/s para darks lo mas cortos posibles.
Yo con BPM_3 consegui valores parecidos si pongo un limite absoluto a los darks
de 1.3s de 2390 ADU aprox.
Creo que el umbral mediana+N*sigma es muy variable y no muy robusto debido a los
darks tan "sucios" que tenemos.
Por tanto, creo que deberíamos esperar al commisioning para final allí los umbrales
de la rutina de BPM_3, o ver que procedimiento usar exactamente.


- Verificado que el BPM de los parámetros de entrada de papi.py en la CL se "fusiona"
correctamente con el valor del fichero de configuración.

- Elimino la opcion -verbose de papi.py, pues no se estaba usando para nada ...




**GEIRS_718M**
- Despues de rsync de panic.mpia.de:/home/panic/DEVELOP/GEIRS, intento compilar
la version 718; me dió un error con el libtool, pero era por que antes hay
que hacer un "make distclean" (no basta con make clean).
Despues de compilar y hacer el enlace de start_panic_new a GENERIC, arranca bien,
pero al intentar hacer un read da un error. Como vi un error reference al fichero
INFO/roe_init_ch32.panic ... decidí compiar mi antiguo directorio INFO en la
version copiade (rsync) de panic.mpia.de. Tras hacer eso, GEIRS arranco bien y
ya pude hacer read+save sin problmas --> Fixed !! , faltaban un par de links tq: 

roe_init_ch32.panic -> roe_init.panic
roe_init_ch4.panic -> roe_init.panic


- Ahora el script GENERIC contiene dos nuevas keys de configuración:

CAM_DETROT90 = 0,1,2,3
CAM_DETXYFLIP = 0,1


- Pruebo la nueva definicion de los MEF con SGi, y resulta que :

 con CAM_DETROT90=2 (=180, default segun RM) tenemos:


ext1 - [0:2048, 0:2048]      - SG4
ext2 - [2048:4096, 0:2048]   - SG1
ext3 - [0:2048, 2048:4096]   - SG3  
ext4 - [2048:4096,2048:4096] - SG2

con CAM_DETROT90=0, tenemos entonces:

ext1 - [0:2048, 0:2048]      - SG2
ext2 - [2048:4096, 0:2048]   - SG3
ext3 - [0:2048, 2048:4096]   - SG1
ext4 - [2048:4096,2048:4096] - SG4

06-Junio-2014
-------------
- Escribo email a RM preguntando como identifica los SGi en los single FITS 4kx4k
cuando no vienen en formato MEF.

Me responde en mail 6/6/2014 lo siguiente:

""
We could just wait for the next release of the FITS keyword TN
of PANIC and implement the specificatation that is in there .

Beyond this:
i) of course everything would start at 1, not 0 (as in FITS)
ii) For sufficiently small windows, there is a
    set of 2 keywords, DET_ID and DETSEC for either the primary
    headers or the extension headers. The "save -M" is a subcase of this.
iii) For the large windows (including the full frame) that sort
    of rotation is indeed not yet available. DETROT90 would
    be insufficient to document the layout, because there is also a keyword
    DETFLIPXY which swaps detectors and images left-right or up-down.
    So basically CHIP_SGi looks fine to me. I am not sure when this
    can be implemented (removal of bugs has preference over implementation
    of desired but essentially superfluous features.) 
"""

así que habrá que esperar a que lo implemente...


- Encuentro problema al salvar los subwindows en r716,r717 y r718, pero en r715
si funciona bien. --> RM lo soluciona ---> r719M


- Ver por qué el directorio INFO no es correcto --> fixed, faltaban un par
de links tq: 

roe_init_ch32.panic -> roe_init.panic
roe_init_ch4.panic -> roe_init.panic

(P) - Ver como reflejar los SGi en PAPI !!! y QL !!!

10-Junio-2014 (feliz. PP)
------------------------
- Corrijo el siguiente WARNING en mef.py :

"""
WARNING: AstropyDeprecationWarning: The wcs_pix2sky function is deprecated and may be removed in a future version.
        Use wcs_pix2world instead. [__main__]
"""
- Además cctualizo la rutina mef.py para que los métodos splitGEIRSToSimple y 
convertGEIRSToMEF tenga en cuenta la definicion de los SGi, y además que el
WCS sea consistente con el que crea GEIRS con los MEF (los simple no tienen
WCS pues no "tiene sentido" segun RM).

- Nota: ahora al hacer un split, los ficheros que se generan siguen esta 
relacción: 

                     DETROT90=2     DETROT90=0
        .Q01.fits --> SG4             SG2
        .Q02.fits --> SG3             SG1
        .Q03.fits --> SG1             SG3
        .Q04.fits --> SG2             SG4

y en el caso de los MEF (DETROT90=2), 

        ext1 - [0:2048, 0:2048]      - SG4
        ext2 - [2048:4096, 0:2048]   - SG1
        ext3 - [0:2048, 2048:4096]   - SG3  
        ext4 - [2048:4096,2048:4096] - SG2


De forma que en principio si en el split que hace PAPI, podremos distinguir los
detectores para el procesamiento y tener en cuenta diferentes parámetros para
la calibración...

- Modifico BPM_3 para que tenga en cuenta el DET_ID y lo muestre y lo escriba
en el MEF del BPM creado. (pendiente probar !!)

- Comprobado que eval_focus_serie.py soporta MEF, pues checkQuality.py también
los soporta. No obstante, no distingue o separa valores de FWHM de cada 
extensión/detector, pues lo que da checkQuality es el valor medio del FWHM
de las N extensiones en caso de un MEF.
Quizás habría que separar/distinguir entre detectores ...¿ como se haría una
secuencia de FOCO , con todo el FPA o con sólo un detector ? quizás en comissioning
lo averiguiemos ....
O quizás habría que limitar el cálculo del FWHM a una ventana/detector concreto,
teniendo en cuenta que SExtractor soporta ficheros de entrada tal que:

 /data1/PANIC/testJM/focus_eval0001.fits[i] (i=1,2,3,4)

- Debido a todo lo anterior, añado soporte para procesamiento de un detector
concreto en checkQuality.py, con la opcion -W (--window)

11-Junio-2014 
-------------
- Traslado la misma opcion -W de checkQuality.py a eval_focus_serie.py.
- Implemento la opción de procesar un determinado detector del FPA de PANIC.
Para ello añado al fichero de configuración el parámetro 'detector', tal que:

#
# detector: detector to reduce/process (Q1,Q2,Q3,Q4,all)
# For O2k, this parameter has no effect.
# Q1=ext1 - [0:2048, 0:2048]      - SG2 (for CAM_DETROT90=0)
# Q2=ext2 - [2048:4096, 0:2048]   - SG3
# Q3=ext3 - [0:2048, 2048:4096]   - SG1
# Q4=ext4 - [2048:4096,2048:4096] - SG4
#
detector = all

- Lo pruebo con HAWK-I y funciona bien.
- Compilo la r719M-bis y pongo el mismo INFO que en panic.mpia.de con los 
correspondientes enlaces y todo OK.


12-Junio-2014 
-------------
- Le escribo a RM preguntadole por los valores de DETXYFLI, pues aunque parece
que =1 para Flip horizontal (intercabiar izq. y derecha), =2 Flip Vertical 
(intercambiar arriba con abajo), hay un tercer valor =3 que no se para que puede
ser....

- NOTA: **nunca** se deberían mezclar en la reducción imagenes con diferente valor
para DETROT90 y DETXYFLI.


08-Julio-2014 
-------------
- Descargo los datos del 4th OPT_FOCUS_CICLE (3rd según BD) y lo reduzco para
que lo analice Conchi.
Les indico que a mi me da la impresión de que la "estrellas" están aplanadas, y
algunas parecen un cacahuete.

09-Julio-2014 
-------------
- Videoconf de PANIC: nada relevante; BD está trabajando sobre la rutina de NLC
y cuando la tenga me la pasará para que la implemente en PAPI.


11-Julio-2014 
-------------
 - Conchi me pregunta sobre algún procedimiento del QL para ver en "tiempo-real"
 el FWHM de una estrella mientras se está tocando el foco del StarSimulator.

 Temas a ver:
  - pre-reducción Dark y FF
  - funcionar con subwindows
  - Mostar el FWHM de cada fichero: la rutina actual usa la keyword T-FOCUS y
  dará una estimación del mejor TFOCUS en función del FWHM de la imagenes.

  Por tanto, parece que lo mejor es modificar eval_focus_serie.py para que 
  no opcionalmente no USE TFOCUS y simplemente diga el FWHM de cada imagen.

14-Julio-2014 
-------------
- Modificaciones en checkQuality.py (edge>20 y MIN_GOOD=0) y en eval_focus_serie.py
para las pruebas que quiere hacer Conchi con el StarSimulator.

(P) Pendiente ver como puede afectar a otros procedimientos dichas modicicaciones ....


18-Julio-2014 
-------------
- Creo correctNonLinearity.py a partir de la version de BD (correct_nonlinearity.py)
Lo pruebo un poco y va bien, pero falta:

 - hay un warning de calculo...

21-Julio-2014 
-------------
- Continiuo con la adaptación y mejora de la NLC de BD a PAPI; entre otras,
añado lo siguiente:
 
   - conversion a MEF cuando los ficheros de entrada son single; tuve
   que modificar/actualizar mef.convertGEIRSToMEF()
   - paralelizar cuando hay una lista de ficheros a corregir; se hace en la
   propia clase  NonLinearityCorrection() con runMultiNLC()
   - incluir (sustituir mi rutina) en PAPI en reductionset.py de forma que 
   si en el fichero de configuración se dice que se aplicar la NLC, se aplicará
   en PAPI. 


22-Julio-2014 
-------------
TODO:
  - probar NLC en una reducción completa de PAPI - probado y OK !!
  - ver como pueden afectar los NaN que crea NLC en PAPI (IRAF, Sextractor, ...)
  - aniadir NLC a doc
  - probar el modo "force" de la NLC  - probado y OK !!


23-Julio-2014 
-------------
- Modificación a NLC para que admita cubos de imagenes y así poder tener 
FITS con crep>1 pero COADD=1.

24-Julio-2014 
-------------
- Encuentro un BUG al intentar hacer un masterDark desde QL o con papi.py;
da el siguiente error:"Error in parameter 'imcmb' for task combine\n'

[PAPI]: 2014-07-24 18:41:35,939 ERROR    reductionset:2327: [reduceSeq] Some error while creating master DARK: "Error in parameter 'imcmb' for task combine\n'Key imcmb not found'"

Si embargo la misma secuencia con calDakr.py funciona correctamente !!!!
Parece que es por usar el multiprocesing !!!! pyraf Cache o yo que se !!!


28-Julio-2014 
-------------
- Soluciono el bug de "Error in parameter 'imcmb' for task combine\n'.
Era debido a varios import innecesarios en misc/imtrim.py, pues

   from iraf import noao
   from iraf import imred
   from iraf import ccdred

pues aunque no se usaban, estaban incluidos de forma innecesarea, y al se importados indirectamente
por reducetionset.py, y eso causaba confusion en calDark.py cuando era llamado
desde reductionset.py, a pesar de que la llamada en calDark.py es bien clara:

    iraf.mscred.darkcombine

Supongo que será algún timpo de bug en PyRAF !!!

NOTA: El login.cl que se carga al importar pyraf, por defecto incluye los paquete
noao, images, tv, ..., por lo que no es necesario hacer el import de noao, imred, ccdred ????

- Actualizo la nueva version de PAPI/QL en panic@panic.mpia.de para los test
con el StarSimulator de Conchi en HD.


- Resuelvo el siguiente DeprecationWarning (ver debajo) que se producia en mef.py al borrar
algunas keywords (keys_to_del). Lo soluciono comprobando que existe el keyword
antes de borrarla.

"""
/usr/lib64/python2.7/site-packages/pyfits/header.py:229: DeprecationWarning: Deletion of non-existent keyword 'CRPIX1': In a future PyFITS version Header.__delitem__ may be changed so that this raises a KeyError just like a dict would. Please update your code so that KeyErrors are caught and handled when deleting non-existent keywords.
  key, DeprecationWarning)
"""




30-Julio-2014 
-------------
- Revisado y mejoradas las opciones del modo "Lazy" del QL; además encontré
varios errores.


31-Julio-2014 
-------------
(P)- Revisar opciones (checkboxes) del modo "Pre-Reduction" en QL

01-Agosto-2014 
--------------
(P)- Las primeras imágenes (Darks MEF) que le llegan al QL no las muestra bien en el DS9 !!! testLazy.xml

Parece que los dark MEF se pueden leer sin problemas con la opción -mosaicimage
del DS9 pues los darks ahora también tienen WCS !! 

 > PENDIENTE implementar en display.py !!! 

PANIC computers installation
============================
0) Introduction

The aim of this document is 


1) System configuration

The PANIC computer system is composed by on server computer with the next features:

 - System boards (OPT-PLX PCIe)
 - Network configuration:
     1) Configuring Network Bonding with YaST
     2) Configuring NTP service
        > chkconfig --add ntp
        > service ntp start | status
        > ntpdc --> peers


2) RAIDs definition
 
The system is designed to have the next RAID disk configuration:

  * OS system disk - no 

3) OS installation

4) PANIC software installation and configuration

4.1 GEIRS installation

See document R. J. Mathar, PANIC - Generic Infrared Software - Graphical User Interface, PANIC-SW-DCS-01.pdf
URL http://www.mpia.de/~mathar/public/PANIC-SW-DCS-01.pdf

4.2 OT installation

4.3 PAPI & QL installation



FOR NEXT VIDEOCONF
==================
- Implemented procedure to set telescope focus after QL-processing; confirmation
required by user on the OT.
- Reviewed of BPM and compared with BD procedure.
- Taken into account new flags CAM_DETROT90 y CAM_DETXYFLIP (bueno, este aún no)
en BPM_3 and split of MEF for processing, so specific values for calibration
of each detector can be used.




OLD_NEXT_VIDEOCONF
==================
- New version of TN about FITS headers
- Fast vs slow readout mode --> Fast-readout not implemented in GEIRS
- Disc array for PANIC at the CAHA Archive
- Network bounding for CAHA Archive link
- Data Quality Control/Assesment (when data processing must not be done ?)
- DUDAS LEMON:
   - quieren que las imagenes tengan la astrometría ?
   - quieren que elimine la distorsion del campo ? (si no, todas tendrán la misma distorsion, y yo creo que no importa ???)
   - esto enlaza con la eterna pregunta de cuando hacer la correción de distorion, 
   antes o despues del coadd (hubo un tipo que decia que era mejor después, pues 
   tienes menos errores, pues al fin y al cabo, todas la imagenes tienen la misma distorsion
   y para sumar no importa siempre que el dither-offset sea pequeño )


IMPORTANTE: Aclarar muy bien que tipo de datos (FITS) aceptará PAPI & QL !!!
- SATUR_LEVEL parametrized with NDIT
- New 'lab' reduction mode: dark, flat and FWHM. 
- Check of INSTRUME keyword added and now checked on QL and PAPI: only
data files from INSTRUME=config.instrument will be added to PAPI DB.
- Next basic WCS keywords should be added by default by GEIRS. Currently,
only added by external program geirs2Panic:

    CUNIT1  = 'deg     '           / WCS units along axis 1                         
    CUNIT2  = 'deg     '           / WCS units along axis 2                         
    CTYPE1  = 'RA---TAN'           / WCS axis 1                                     
    CTYPE2  = 'DEC--TAN'           / WCS axis 2                                     
    CRVAL1  =                   0. / [deg] RA in center                             
    CRVAL2  =                   0. / [deg] DEC in center                            
    CRPIX1  =                 2047 /  RA and DEC center along axis 1                
    CRPIX2  =                 2047 /  RA and DEC center along axis 2                
    CD1_1   = -5.84166664339136E-05 /  [deg/px] WCS matrix diagonal                 
    CD2_2   = 5.84166664339136E-05 /  [deg/px] WCS matrix diagonal                  
    CD1_2   = 3.57687104420465E-21 /  [deg/px] WCS matrix outer diagonal            
    CD2_1   = 3.57687104420465E-21 /  [deg/px] WCS matrix outer diagonal   

- New 'workaround' to add keywords to headers --> ~/tmp/geirsPhduAdd.panic 
- MEF are going to be finnaly implemted ? RM says is in 'experimental'
(see RM's email by 29-Jul-2013)
- Finally, will GEIRS add basic WCS keywords (see above) ?
It might need to implement MEF, because we need 4 separate WCS headers due
to gaps!
- Focus eval added to QL
- PANIC hardware equipment is ready ? (see mail 23-Sep-2013 from JM)
- New astrometric module with astrometry.net (under optimization/debuggin) - much more robust, blind computing.


Questions:
- Linearity values --> 15K ADUs for saturation
- Readout modes for PANIC
- How many serial ports are required ? or MOXA NPort (serial-ethernet converter) ? should also be tested !
- is there any other interface/s ?
- Ask CA about Archive interfece (run tests !)
- what should be the kind of FITS files/modes supported by PAPI ?
  Currently are supported next types:
     - integrated full-frame in single FITS (1 header + 1 data chunck) --> save -i
     - no-integrated full-frame cube in single FITS (1 header + 1xN planes data chuck planes ) --> save -1
     - no-integrated full-frame cube in MEF file (with or without windows definition) (1 primary header + 4x(1h+1 dataxN planes)) --> save -M -1
    
     Currently, GEIRS is not supporting 'save -M -i' to produce integrated MEF 
     files, but PAPI can handle the non-integrated MEF doing the integration (collapse).






KDD con MATILDE (15-May-2012)
=============================

 1) integration of cubes/individual files (add or mean)
   -->Si; sumatorio "simple" del cubo/ficheros sin mas.
   individual, quizás el OT me pueda ayudar, al menos para PAPI (ot?)
 2) integration of single-images (individual files) --> keyword FRAMENUM
   (ver arriba)
 3) how to proceed with windowed/binned images ? 
   --> MF preguntara a la gente de Barcelona sobre las ventanas 
   y como se podrian reducir (sky, astrometry, etc). (pendiente)
   --> JM Preguntara CS sobre el binning: CS responde que no, que en IR no hay binning
 4) JF: must be possible to check the photometry of a specific star selected in the display. Imexam ?? how ? 
   --> MF le preguntara a JF que quiere exactamente; MF no ve muy interesante el ir viendo la Mag de cada
   estrella al marcarla en el display. Es mucho más útil la grafica de magnitud instrumental VS magnitud catalogo.
   --->JM mirara si con Aladin de puede hacer lo de leer un catalogo+imagen para consultar la magnitud, y tambien
   con imexam.
   --> JM : con > aladin /tmp/reduced_SEQ.fits /tmp/reduced_SEQ_zp.xml se puede hacer !! y haciendo click sobre una 
   objeto no muestra los valores de catalogo leido (/tmp/reduced_SEQ_zp.xml) y generado con SExtractor con el MAG_ZEROPOINT 
   calculado previamente con photometry.py
   --> JM : ademas, "Quick-look Photometry with Imexamine" 
   --> JM: Además, imexam te muestra con 'a' la magnitud (MAG), teniendo en cuenta el ZP que se puede modificar con (epar rimexam)
   
   #   COL    LINE     COORDINATES
   #     R    MAG    FLUX     SKY    PEAK    E   PA BETA ENCLOSED   MOFFAT DIRECT 
     2243.31 2888.93 2243.31 2888.93
     28.92  13.82  29750.   1.239   70.36 0.18  -77 1.14    13.63    15.59   9.68
   ( en este ejemplo ZP=25)
   
 5) how to reduce 'other' readout modes (rrr-mpia, lir, mer, srr, cntsr) or only work for lir (line-interlaced-read)
   MF preguntara a CS, pues no sabe a priori de que diferencias puede haber pero tiene "curiosidad" por ver que quería decir CS 
   (aunque JF dijo que no había diferencias)
 6) how to remove the stripe/quadrant background offsets in dxtalk.py 
    --> MF no se le ocurre a priori como eliminarlo; 
 JM preguntara al Chino (WIRCAM); Otra opcion es ver si se puede restar solamente 
 la estrella, lo estudiará JM.
 JM--> Wei-Hao me responde:
   """
   How about a simple background subtraction in each stripe after
   the subtraction of the median?  Maybe this will solve the problem.
   """
   Lo que dice Wei-hao (restar a cada stripe su propio cielo) podría funcionar, 
   pero nuestra "triste" realidad (imagenes con gradiente en el background), 
   no puede funcionar.
   
KDD con MATILDE (29-May-2012)
=============================
 
 - repasamos los punto de la ultima KDD; MF no ha podido hacer sus "deberes", por lo que lo dejamos 
 para la proxima KDD.
 - JM comenta sus "deberes" y muestra el ejemplo : aladin /tmp/reduced_SEQ.fits /tmp/reduced_SEQ.xml
   que a MF le parece bien.
   NO obstante, MF no está muy conforme con la dispersión (STD=RMS=0.105950) que tenemos en el ejemplo que le muestro (o2k-120105).
   MF pensará sobre ello, y yo probaré con MAG_APER, qphot, a ver que diferencias hay.
   
 - comentamos la respuesta de Wei-Hao:
   How about a simple background subtraction in each stripe after
   the subtraction of the median?  Maybe this will solve the problem.
   """
   Lo que dice Wei-hao (restar a cada stripe su propio cielo) podría funcionar, pero nuestra "triste" realidad (imagenes con gradiente en el background), 
   no puede funcionar.
   
   Matilde sugiere restar al stripe-mediana el su propio background antes de restarlo a los N stripes de la imagen a
   corregir, de forma que "solo" restesmos los artefactos ->"estrellas de crosstalk".
   Quizas es background podría ser la "moda" de la imagen.
 
 - "significado" de MagInstrumental negativa ? 
   MF: bueno, no tiene importancia, pues el resultado es el mismo; lo que pasa es que normalmente hace
   el ajuste con una estimación inicial ZP=25 de forma que no salgan valores "negativos".
   
    mag_instrumental = zmag - 2.5 * log10(flujo/tiempo_integracion)

  - En cuanto al problema de identificar los grupos/secuencias cuando se graban en modo "individual",
  MF comenta que quizás con la información extra del OT se pueda hacer.
  JM lo pensará, pues quizás para el Pipe sirva, aunque no para el QL.
  
  - JM le comenta a MF que para la proxima sesion le dará un "tutoria" sobre como usar PAPI.
  
  - MF pensara sobre cual puede ser el origen de la dispersion "tan grande" en la estimacion de fot. absoluta.
JM probar con qphot con MAG_APER, etc ...


KDD con MATILDE (19-Jun-2012)
=============================
- Le enseño brevemente un poco del CL de PAPI, y la primera pregunta fué:
  
  ¿ cómo reducir toda una campaña ? - TODO !!! buscar en todos los subdirectorios 
  de un directorio, pero crear logfiles distintos ??? yo creo que sería mejor.

- Luego pasamos a ver las series de dark y le extraña el gran numero de pixeles 
  calientes !! ¿ cómo podría afectar a la reducción suya ?
  
  MF investigará sobre el tema. JM buscará como los trata PAPI.
  
- Le enseño el procedimineto para combinar domeFF y skyFF. Le parece interesante, 
pues ellos (VT y MF) están intentado algo parecido en LEMON. MF estudiará la 
utilización de esta mix de Flats.

- MF me pregunta cómo se tratan los BadPixels en la sky_subtraction ? TODO !!!

Respuesta JM:

Los pixeles malos(BP) se comportan de la siguiente manera:

  a) en la primera iteracion de sky_subtraction (sin mascara de objetos):
  
     - los pixeles malos de dejan con el valor del background medio (moda) de
     dicha imagen
  
  b) en la segunda iteracion de sky_subtraction (con máscara de objetos):
  
      - los pixeles malos o enmascarados por SExtractor como objeto, se les
      deja su propio valor, es decir, no se modifican.
     

- MF me pregunta si he cambiado algo en PAPI desde la reducción de sus datos en Febrero. Le digo
que tengo que mirarlo en los logs, pero que lo que puede que haya cambiado es el fichero de configuración !!!

- TODO: implementar en PAPI algo para hacer una copia del fichero de configuración 
usado en cada reducción, quizás incluirlo en el logfile !!! - DONE !




DOUBTS FOR MATILDE (next)
================================
- subwins ?? como reducirlas ??? pueden ser cada ventana de tamaño distinto !!!
- la raw_photometry() sólo esta disponible para los filtros de 2MASS (J, H, Ks), 
pero, ¿ se podría hacer otra aproximación con los filtros que vaya a tener PANIC ??

- ¿ que valor usar para la normalización ? y tenía la moda, pero he visto
que me puede dar problemas (filtro z), y en HAWK-I usan la mediana.
Lo he cambiado todo par ausar la mediana.

- Reference pixel, ¿ algún tratamiento ? de momento descarto.
  (ver como "quitar" los "Reference pixel"  en (http://bit.ly/YP5heF))
  Implementado !! en refPixelCorrection.py, pero pendiente revisar resultados.


- Me surge la duda sobre si para los Master TwLight flats es imprescindible
un dark model o bastaría con un simple master_dark ?? Ahora mismo sólo
se calculan con un master_dark_model.

- New module for mix dome & sky FF : calCombineFF()
- show MF PAPI CL interface:

> papi.py -s /data/O2K/2012-Matilde/20120103/ -g filter -p
> papi.py -s /data/O2K/2012-Matilde/20120103/ -S 15  -g filter 
> photometry.py -i /tmp/reduced_SEQ.fits -z 26.821570
> aladin /tmp/reduced_SEQ.fits /tmp/reduced_SEQ.xml
> papi.py -s /data/O2K/Matilde/120105/ -S 0  -g filter -R lemon
> cp /data/out/mDark_EXRfly.fits /data/calibs/mDark_serie.fits
> papi.py -s /data/O2K/Matilde/120105/ -S 4  -g filter -R lemon -D /data/calibs/mDark_serie.fits
> papi.py -s /data/O2K/Matilde/120105/ -S 28 -g filter -R lemon -D /data/calibs/mDark_serie.fits -F /data/calibs/mTwFlat_J.fits 


FAQ:
===
1) ¿ para que se usa en PAPI los gainmap ? 
   - skyfilter
   - dithercubemean

2) Como funciona el workaround the Clemens para keys del OT: (esto ya no es así)

Escribir en ~/tmp/fitsheader_panic.txt la keys y en el fichero 
GEIRS/scripts/QueueFiles tenemos una linea tq:

   modify_fits_hdr -v -a ~/tmp/fitsheader_panic.txt $1 >>~/GEIRS/log/add_panic_fits.log


DEPENDENCIAS DE IRDR
====================
- skyfilter
- dithercubemean
- offsets


ASTROMETRIA con Astrometry.net 
==============================

Varias formas de hacer astrometría:

1)IRAF: user-friendly!

2)Aladin: interactivo

3)Astrometry.net: completamente automático

Astrometry.net
--------------
(http://astrometry.net)

- Devuelve la astrometría en el WCS

- Nunca da falsos positivos 
    (quizás falso negativos)

- Tanto con imágenes fits como con tablas de SEXtractor

- Capaz de trabajar sin ninguna indicación
     > solve-field images.fits

- Necesita “licencia”

- Está en desarrollo

Requisitos:
----------
  * gcc
  * cairo
  * netpbm
  * libpng
  * libjpeg
  * python (probablemente ≥ 2.4)
  * numpy
  
Resultado
---------
   <base>-ngc.png : an annotation of the image.
   <base>.wcs : a FITS WCS header for the solution.
   <base>.new : a new FITS file containing the WCS header.
   <base>-objs.png  : a plot of the sources (stars) we extracted from the image.
   <base>-indx.png  : sources (red), plus stars from the index (green), plus the skymark ("quad") used to solve the image.
   <base>-indx.xyls : a FITS BINTABLE with the pixel locations of stars from the index.
   <base>.rdls : a FITS BINTABLE with the RA, Dec of sources we extracted from the image.
   <base>.axy : a FITS BINTABLE of the sources we extracted, plus headers that describe the job (how the image is going to be solved).
   <base>.solved : exists# Note: skyfilter could fail if corrected image has wrong values 
                # (e.g.: negative mean, very big/small float values) and contains (binary) 1 if the field solved.
   <base>.match : a FITS BINTABLE describing the quad match that solved the image.
   <base>.kmz : (optional) KMZ file for Google Sky-in-Earth. 
   
Trucos
------
- Darle la escala de la imagen:
    > solve-field  image.fits --scale-units degwith --scale-low 1 --scale-high 2
    > solve-field  image.fits --scale-units arcsecperpix --scale-low 0.3 --scale-high 0.4
 
- Darle la posicion aproximada y radio en grados (o en hh:mm:ss y dd:mm:ss)
    > solve-field  image.fits --ra 20 --dec –85 --radius 2

- Que no pinte las plots 
    > solve-field  image.fits --no-plots

- Utilizar tabla de SEXtractor
    Configurar SEXtractor          
        CATALOG_TYPE        FITS_1.0
        CATALOG_NAME    tabla.xyls
        PARAMETERS_NAME xylist.param (X_IMAGE, Y_IMAGE, MAG_ISO

    > solve-field  tabla.xyls --x-column X_IMAGE --y-column Y_IMAGE  sort-ascending --sort-column MAG_ISO --width 2000 --height 1500

PIPELINE
---------
1-Obtengo la tabla con SEXtractor.

2-Lanzo Astrometry. Utilizo la posición aproximada que esta en la cabecera.

3-Utilizo las ftools para incluir las WCS en la imagen de BUSCA.

4-Nueva tabla de SEXtractor con la astrometría corregida.

5-Utilizo Aladin para comparar con los catálogos USNO-B1 y 2MASS

6-Hago la estadística usando IDL

7-Incluyo la estadística en la cabecera de la imagen con las ftools

 
NEXT TODOs
==========
- Las primeras imágenes (Darks MEF) que le llegan al QL no las muestra bien en el DS9 !!! testLazy.xml

- Revisar opciones (checkboxes) del modo "Pre-Reduction" en QL
- ver donde se está usando cosas como image[200:naxis1-200,200:naxis2-200] para que
no de problemas con subwindows !!
- $CAMHOME/scripts/QueueFiles: Considerar su posible uso para el QL, para la detección
de nuevos ficheros; por lo visto se llama después de que termina el "save". Ver
documentación GEIRS (3.3 Postprocessing) 
- Añadir un segundo fichero de NLC (LIR y RRR-MPIA) en fichero de configuración
y que PAPI lo use según el modo de lectura encontrado en la cabecera.
- ver como pueden afectar los NaN que crea NLC en PAPI (IRAF, Sextractor, ...)
- QL: no procesa secuencias de Flat con un tiempo Fijo y que no sean DOMEFLAT ???
- QL: en modo lazy, debaría procesar construir los Dark y FF maestros, pues si no 
no puede aplicar Dark y FF en la pre-reducción lazy !!

- En MEF:convertSimple2MEF, considerar la opción de cubos !!!
- Probar PAPI con subwindows (Dark subtraction, FF, etc ....)
- Instalar r720M y actualzar el fichero GENERIC
- Dejar muy claro en la documentación que tipo de ficheros son los mejores para
PAPI, es decir, MEF full-frame en modo NCOADDS=1 (NLC??), etc....
- Comprobar lectura correcta de nuevas keys : CAM_DETROT90 y CAM_DETXYFLIP en r719M.


- Ver y evaluar la posibilidad de usar Montage para coadd en lugar de dithercubemean
o SWARP (VTerrón lo está usando y está contento...)

(P) - Comporbar si la secuencia T-S-T-T-S-T-T-S-T-T-S ....la acepta bien PAPI !!! simular !!!

(P) - Actualizar TN de FITS headers:

   DET_ID = 'SGi'
   ...

- "Collapsar" los cubos de PANIC con un average + sigmaclip !!!
- Rutina para master_flat ala skyflats ! ==> OT=Fixed or Series; implemetar tb en QL !!!
- Modifico mainGUI:createMasterDark_slot() para que use processFiles() en lugar
de llamar directamente a calDark.py.
  ==>Esto habría que hacerlo para otras funciones _slot_ del QL !!!
- Parametrizar los paths del ds9 en display.py y añadir al fichero de configuracion
- Revisar lectura con QL de directorio con >5000 ficheros !!! muy lento !!!
- Rutina para copiar datos de varios directorios a un único directorio y renombrando
los ficheros de forma única (DATE+TIMESTAMP)!!

- Revisar GUI QL !!! y quitar lo que no sirva !!
- Second pass of sky-subtraction for extended objects
- Support for non-integrated frames as individual frames (not as cubes),ie. detection/grouping and coadd 
- Support for sub-windows (not tested, but probably does not work properly) 
- Non-linearity computation ( fac = a0 + a1*I + a2*I^2 )
- Method to empiricaly determine the geometric distortion based an auto-calibration 
approach analogous to the one described in Anderson et al. (2006, A&A, 454, 1029)
- Photometry: currently only 2MASS filters (J, H, Ks) supported. No color 
coefficients neither extinction taken into account.
- Data Quality Control (frames to reject, ...)
- Support for incomplete sequences (ie. aborted, corrupted, ...): a kind of 
fix method to update the headers in order to build a valid sequence for PAPI.

- Ver si merece la pena implementar el metodo crclean() de image.py
de http://www.astro.umd.edu/~msk/computing/python/src/mskpy1-1.7.0.tar.gz
para la eliminacion de CR. Esta basado en el algorimo LACOSMIC. Yo ahora estoy
usando en PAPI el original http://www.astro.yale.edu/dokkum/lacosmic/.

- Solucionar problemas en skyfilter para valores raros en las imágenes:
 Note: skyfilter could fail if corrected image has wrong values 
 (e.g.: negative mean, very big/small float values)
  De esto me di cuenta cuando estaba probando la NL correction.

- En calGainMap hay que quitar el bpm, pues no se usa para nada !!!
- Revisar/parametrizar todas la dependencias de PIX_SCALE para (2.2m y 3.5m).
- Migrar catalog_query.py para usar Astroquery (http://www.astropy.org/astroquery/)
- opción en PAPI para reducir sólo un detector/es
- Configurar sonidos (pulseaudio)
- Support for incomplete sequences
- Add some kind of Quality check 
- Actualizar TN de FITS con las ultimas novedades de RM (DATASEC, FILE_ID, ...)
- No se muestran bien en el QL las imágenes MEF, la primera bien, pero el resto mal !!!
El problema surge cuando se mezcan distintos tipos de formatos FITS (MEF, single, ...),
pues display.py tiene en cuenta eso, y además los Darks se muestran de forma distintan
según el instrumento (HAWK-I no tiene WCS en los Darks!)
--> problema reportado con DS9. RM modificará DATASEC al formato IRAF (DETSEC, ...) ver email
- Apply Gaussian Kernel to yield the final sky model to subtract !!! (see THELI paper, point 7.1 )
- Opcion en solveAstrometry para usar SExtractor en lugar de imagexy
- Fotometría con SCAMP !!! (ver THELI) ??? todavia no tengo claro si se puede hacer !!
- Quizás habría que añadir otro parametro para indicar si queremos que la
distorsión del campo se elimine antes del coadd (a nivel individual en cada imagen
del dithering) o bien despues del coadd final. Yo creo que se con hacerla al final
debería bastar, pues la diferencia de distorsión en cada uno de las imagenes
de dithering no debe ser grande, y por tanto el coadd no se verá afectado mucho.
- Probar bien solveAstrometry() con HAWK-I
 
- Comprender bien el valor (unidades) de ASTRRMS1 que da SCAMP, pues parece que 
son arcsec, pero me parecen valores muy pequeños (4.731352954E-05)
- cuando RM nos pase la r711M, probar los MEF integrador, los subwindows con MEF, etc , etc ...
- Estudiar/Probar el Algoritmo de registrado de imagenes ---> https://github.com/t-brandt/acorns-adi
- Comporbar si la secuencia T-S-T-T-S-T-T-S-T-T-S ....la acepta bien PAPI !!! simular !!!
- ¿ Qué hace PAPI con los FLAT_SER ??? (ver Calibration Series del OT)
- FOCUS --> valor de IMAGETYP  para Series de FOCO (añadir en documentación y comprobar en PAPI)
- Documento (TN) Data Grouping algorithms
- Documento instalación de PANIC-SW
- PANIC Tesis ala O2000 !!!

- Que hacer con las secuencias incompletas, por ejemplo, le falta el primero, 
el último, o algunos del medio, etc .... 
Debería haber alguna forma de poder reducirlos ?? en modo group_by='filter' si !!!
Alguna otra solución ???

- PAPI se queja si el fichero de entrada (files.txt) tiene una linea en blanco al final !!!
sin embargo, parece que calDark.py no se queja !
- doc. y script de instalación de PAPI --> (Distribute vs distutils)
- how to manage MEF calibration files ? (currently darks, flats are not splited !)
- implementar procesamiento (detección y suma) de 'individual images' en 
varios ficheros, en CUBOS en un solo fichero creo que si lo hace PAPI.
- Añadir "todos" los principales parametros del fich. de configuración al QL !
- como tratar en PAPI las imágenes de subwindows ??? -> _win.fits !!! mejor MEF !!
- mejorar interfaz de ETC en Web( Ejemplo--> http://www.cefca.es/jplusetc/etcjplus.cgi)
- eliminar del todo RS::self.out_file
- crear "bateria" de tests para lanzar de forma automatica con un conjunto de
datos fijo (Ok2, PANIC, HAWK-I) de forma que se prueben "todas" los modulos de PAPI !!!
- usar fit.polyfitr() en photometry 
- ver notas libreta sobre si se reduce o no HAWK-I-4
- ver notas libreta sobre si se reduce o no HAWK-I-5; 
en el portatil lo hace, pero el resultado no es muy bueno, 
incluso la astrometria no parece funcionar

- escribir al Chino sobre el dxtalk.py --> probar su sugerencia !!
- añadir sonidos con from PyQt4.phonon import Phonon (ver sound.py en tests)

BUGS
====
QL> Si seleccionamos varios science con distinto filtro y le decimos "reduce",
no lo hace pero no dice el porqué !
PAPI> NaN values in Numpy computations ! need to be checked previosuly as in
applyDarkFlat.py


Troubleshooting
===============
- Some black holes in single reduced images due to a poor skysubtraction or 
over-estimation of skybackground when no object masking is done (see skyfilter).
  Poor (over) sky-estimation in first pass (quick mode) is due median of stack for
  sky-estimation is 'contamined' by bright stars, so in principle, on the second
  pass of the sky-subtraction where an object mask is used, the sky-subtraction
  is much better.
  In addition and for crowded fields, we could set in the config file the    


Paper
=====
AUTOMATIC DATA REDUCTION ALGORITHMS FOR THE PANORAMIC NEAR INFRA-RED CAMERA (PANIC) INSTRUMENT

Abstract:
In this paper we describe the main algorithms of the software package for the
data reduction for the Panoramic near infra-red camera (PANIC) on 2.2m and 3.5m 
telescopes at the Calar Alto observatory, intended as a image processing pipeline.
PAPI takes as input raw images and does a detrending of them (dark,flat fielding,
sky subtraction). Then the software does a astrometric and photometric calibration
of the detrended images. The astrometric calibration of the output images is 
accurate to within 0.15" relative to external reference frames and 0.04" internally.
The photometric calibration is good to within 0.03 mag. The staked images and
catalogs derived from these images are available through the Calar Alto archive.


Things To Be Done on PAPI 
=========================


 (Known) Things To Be Done on GEIRS
 ==================================
 - fast readout mode 

Problemas/bugs detectados GEIRS
===============================


Problemas/bugs detectados en OT 
===============================
25-02-2014) La copia de OB no se hace bien, pues luego repite el número del OB 
y el orden de ejecución de los OBs se altera notablemente .... --> Fixed!
25-02-2014) S abre dialogo de grabar
25-02-2014) Telescope iterator con cycles=5 por defecto !!! debería ser =1 -->Fixed!

25-02-2014) Timeline nada preciso, o solucionar o quitar ! --> In progress
25-02-2014) PROG_ID en headers no se rellena; debería rellenarse con campo 
"Proposal ID" y/o quizás cambiarle el nombre a "Program ID" --> Fixed!

25-02-2014) En los OB, Nro. repetitions es "comun" para todos los OBs !
26-02-2014) Los subwindows con Detecto1-4 no están bien definidos en el OT. 
Lemando a AGS la definición correcta.
07-03-2014) Error por 'timeout' (creo, según log de GEIRS) que provoca la 
terminación prematura de un OB en el OT. --> Fixed
14-03-2014) Confirmado que el OT a veces se para tras un OB de forma inesperada,
sin continuar con los otros OBs. AGS ha visto que a él también le pasa. --> Fixed
18-03-2014) No se puede seleccionar el telescopio en el OT. AGS mirará a ver si
hay comando/modo de hacerlo ....
Por lo que he visto, sólo se puede cambiar en el script GENERIC, en la variable
TELESCOPE.



Problemas/bugs detectados en QL 
===============================
- En una imagen de un detector solo, si le decimos que calcule el background 
de esa imagen (ella sola), la imagen FITS de background que genera Sextractor
no cumple el standard FITS y es rechazada por PAPI. Lo compruebo con fitsverify 
y da error. Es un bug en Sextractor que habría que informar a E.Bertin.



